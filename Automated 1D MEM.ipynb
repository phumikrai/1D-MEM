{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support modules\n",
    "\n",
    "import glob, os, re, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import lasio # Las file reader module\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "source": [
    "## Import data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note = \"\"\"\n",
    "1.) This is for modeling based on isotropic homogeneous material without overpressure assumption using statistic decisions or machine learning techniques. \n",
    "\n",
    "2.) The working directory should contain the data for modeling as sub-directory. \n",
    "\n",
    "3.) All data for modeling include well logging files (.las), deviation files (.csv) and formation top (.csv) must be separated\n",
    "as sub-directory of the data directory. \n",
    "For example;\n",
    "- Working directory is \"Drive:/Working/\".\n",
    "- All data for modeling directory is \"Drive:/Working/Data/\".\n",
    "- Well logging file directory is \"Drive:/Working/Data/Well logging/\" as Sub-directory of the data directory.\n",
    "- Deviation file directory is \"Drive:/Working/Data/Deviation/\" as Sub-directory of the data directory.\n",
    "- Formation top file directory is \"Drive:/Working/Data/Formation top/\" as Sub-directory of the data directory.\n",
    "\n",
    "4.) Well name should be set as prefix for each file. Its name will cause file ordering and file pairing for each file of that well.\n",
    "For example;\n",
    "- Well name is \"Well-01\" (Noted: No underscore ('_') be contained in well name), so this name should be set as prefix followed by underscore ('_') for each modeling input file like this \"Well-01_(...Specific name for file type indication...)\"\n",
    "- Example; Well logging file name, Deviation file name and Formation top file name could be \"Well-01_las\", \"Well-01_dev\" and \"Well-01_top\" respectively.\n",
    "\n",
    "5.: Required data and file format;\n",
    "- Well logging files include all necessary curves for 1D MEM such caliper (CAL), bitsize (BS), gamma ray (GR), density (RHOB), neutron porosity (NPHI), deep resistivity (RT), shallow resistivity (MSFL), P-sonic (DTC) and S-sonic (DTS).\n",
    "- Deviation files include measured depth column named with 'MD', azimuth column named with 'AZIMUTH' and inclination or angle column named with 'ANGLE'.\n",
    "- Formation top files include formation name column named with 'Formations', top depth column named with 'Top' and bottom depth column named with 'Bottom'.\n",
    "\"\"\"\n",
    "print('Welcome to Automated 1D Mechanical Earth Modeling (Auto 1D MEM).')\n",
    "print('Please take note on this;')\n",
    "print(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data directory\n",
    "\n",
    "cwd_dir_list = ', '.join(os.listdir(os.getcwd()))\n",
    "confirm = 'no'\n",
    "\n",
    "print('According to your working directory,')\n",
    "print('%s\\nwhich one is your data directory?' %cwd_dir_list)\n",
    "\n",
    "while confirm.lower() == 'no':\n",
    "    data_folder = input('Please indicate the data directory name: ').strip()\n",
    "    data_path = os.path.join(os.getcwd(), data_folder)\n",
    "\n",
    "    if data_folder == '':\n",
    "        print('Please type the directory name!')\n",
    "        continue\n",
    "\n",
    "    elif os.path.isdir(data_path):\n",
    "        data_dir_list = ', '.join(os.listdir(data_path))\n",
    "        print('%s\\nThese sub-directories are found.' %data_dir_list)\n",
    "\n",
    "        while True:\n",
    "            print('Which one is your Well logging file directory?')\n",
    "            las_folder = input('Please indicate the well logging file directory name (.las): ').strip()\n",
    "            las_path = os.path.join(os.getcwd(), data_folder, las_folder)\n",
    "\n",
    "            if las_folder == '':\n",
    "                print('Please type the directory name!')\n",
    "                continue\n",
    "\n",
    "            elif os.path.isdir(las_path):\n",
    "                \n",
    "                while True:\n",
    "                    print('Which one is your deviation file directory?')\n",
    "                    dev_folder = input('Please indicate the deviation file directory name (.csv): ').strip()\n",
    "                    dev_path = os.path.join(os.getcwd(), data_folder, dev_folder)\n",
    "\n",
    "                    if dev_folder == '':\n",
    "                        print('Please type the directory name!')\n",
    "                        continue\n",
    "\n",
    "                    elif os.path.isdir(dev_path):\n",
    "\n",
    "                        while True:\n",
    "                            print('Which one is your formation top file directory?')\n",
    "                            top_folder = input('Please indicate the formation top file directory name (.csv): ').strip()\n",
    "                            top_path = os.path.join(os.getcwd(), data_folder, top_folder)\n",
    "\n",
    "                            if top_folder == '':\n",
    "                                print('Please type the directory name!')\n",
    "                                continue\n",
    "\n",
    "                            elif os.path.isdir(top_path):\n",
    "                                print('Gotcha!')\n",
    "                                print('Your well logging file directory is: %s.' %las_path)\n",
    "                                print('Your deviation file directory is: %s.' %dev_path)\n",
    "                                print('Your formation top file directory is: %s.' %top_path)\n",
    "\n",
    "                                while True:\n",
    "                                    confirm = input('Are these correct? [Yes/No]: ')\n",
    "\n",
    "                                    if confirm.lower() == 'yes':\n",
    "                                        break\n",
    "                                    \n",
    "                                    elif confirm.lower() == 'no':\n",
    "                                        break\n",
    "\n",
    "                                    else:\n",
    "                                        print('Please confirm again!')\n",
    "                                break\n",
    "\n",
    "                            else:\n",
    "                                print('Please try again, your directory \\'%s\\' is not found!' %top_folder)\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        print('Please try again, your directory \\'%s\\' is not found!' %dev_folder)\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                print('Please try again, your directory \\'%s\\' is not found!' %las_folder)\n",
    "\n",
    "    else:\n",
    "        print('Please try again, your directory \\'%s\\' is not found!' %data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for pairing the data and eliminating the incomplete\n",
    "\n",
    "def pairing_files(las_files_paths, dev_files_paths, top_files_paths):\n",
    "    \"\"\"\n",
    "    This function is going to pairing the data (las files, dev files and top files) and disable the incompleted one.\n",
    "    las_files_paths = list of las files with paths\n",
    "    dev_files_paths = list of deviation files with paths\n",
    "    top_files_paths = list of formation top files with paths\n",
    "    \"\"\"\n",
    "    paired_las_files_paths = []\n",
    "    paired_dev_files_paths = []\n",
    "    paired_top_files_paths = []\n",
    "\n",
    "    # pairing lAS file to deviation\n",
    "\n",
    "    for las in las_files_paths:\n",
    "        for dev in dev_files_paths:\n",
    "            for top in top_files_paths:\n",
    "\n",
    "                las_well_name = os.path.basename(las).split('_', 1)[0].lower()\n",
    "                dev_well_name = os.path.basename(dev).split('_', 1)[0].lower()\n",
    "                top_well_name = os.path.basename(top).split('_', 1)[0].lower()\n",
    "\n",
    "                if las_well_name == dev_well_name == top_well_name:\n",
    "                    paired_las_files_paths.append(las)\n",
    "                    paired_dev_files_paths.append(dev)\n",
    "                    paired_top_files_paths.append(top)\n",
    "\n",
    "    return paired_las_files_paths, paired_dev_files_paths, paired_top_files_paths\n",
    "\n",
    "# Generate file path\n",
    "\n",
    "las_files = glob.glob(os.path.join(las_path, '*.las'))\n",
    "dev_files = glob.glob(os.path.join(dev_path, '*.csv'))\n",
    "top_files = glob.glob(os.path.join(top_path, '*.csv'))\n",
    "\n",
    "# Pairing files lAS files, dev files and top files\n",
    "\n",
    "las_files, dev_files, top_files = pairing_files(las_files, dev_files, top_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lAS files, dev files and top files\n",
    "\n",
    "lases = [] # Storing well logging data\n",
    "df_lases = [] # Storing well logging data in panda data frame\n",
    "devs = [] # Storing deviation data in panda data frame\n",
    "tops = []# Storing formation top data in panda data frame\n",
    "\n",
    "for las_file, dev_file, top_file in zip(las_files, dev_files, top_files):\n",
    "\n",
    "    # Well logging data\n",
    "\n",
    "    las = lasio.read(las_file)\n",
    "    lases.append(las)\n",
    "\n",
    "    # Well logging data in panda data frame\n",
    "\n",
    "    df = las.df()\n",
    "    df = df.rename_axis('MD')\n",
    "    df_lases.append(df)\n",
    "\n",
    "    # Deviation data in panda data frame\n",
    "\n",
    "    dev = pd.read_csv(dev_file)\n",
    "    devs.append(dev)\n",
    "\n",
    "    # Fomation top data in panda data frame\n",
    "\n",
    "    top = pd.read_csv(top_file)\n",
    "    tops.append(top)\n",
    "\n",
    "# Set directory to save files\n",
    "\n",
    "sav_folder = 'LQC files'\n",
    "sav_path = os.path.join(data_path, sav_folder)\n",
    "\n",
    "if not os.path.isdir(sav_path):\n",
    "    os.makedirs(sav_path)\n",
    "\n",
    "# Well names\n",
    "\n",
    "well_names = []\n",
    "\n",
    "for las in lases:\n",
    "    well_names.append(las.well['WELL'].value)\n",
    "\n",
    "print('The number of wells is %d.' %len(well_names))\n",
    "print('Well names are %s.' %', '.join(well_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define field parameters to adjust (remove air gap) the well logging by oil field type in the next step\n",
    "\n",
    "air_gaps = []\n",
    "water_levels = [] # for offshore field only.\n",
    "\n",
    "while True:\n",
    "    field_type = input('What is this oil field type [Onshore/Offshore]: ').strip()\n",
    "\n",
    "    if field_type.lower() == 'onshore':\n",
    "        for name, df_las, dev in zip(well_names, df_lases, devs):\n",
    "            print('Please type basic information for well %s' %name)\n",
    "\n",
    "            kb = float(input('Kelly Bushing depth [Kelly bushing to sea level]: ').strip())\n",
    "            gl = float(input('Ground level elevetion [Ground surface to sea level]: ').strip())\n",
    "            gap = kb - gl\n",
    "            air_gaps.append(gap)\n",
    "            \n",
    "            print('Air gap is %f' %gap)\n",
    "        break\n",
    "    \n",
    "    elif field_type.lower() == 'offshore':\n",
    "        for name, df_las, dev in zip(well_names, df_lases, devs):\n",
    "            print('Please type basic information for well %s' %name)\n",
    "\n",
    "            kb = float(input('Kelly Bushing depth: ').strip())\n",
    "            wl = float(input('Water depth [Sea level to seafloor]: ').strip())\n",
    "            water_levels.append(wl)\n",
    "            air_gaps.append(kb)\n",
    "\n",
    "            print('Air gap is %f' %gap)\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        print('Please type only \\'Onshore\\' or \\'Offshore\\'')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking the curve completion of well\n",
    "\n",
    "def check_curves(las_file, alias, mem_curves):\n",
    "    \"\"\"\n",
    "    This function can check the curve completion of well.\n",
    "    las_file = las file read by lasio\n",
    "    alias = curve alias or alterative name of the curve\n",
    "    mem_curves = necessary curve names for modeling\n",
    "    \"\"\"\n",
    "    curves = [curve.mnemonic for curve in las_file.curves]\n",
    "    extracted = []\n",
    "\n",
    "    for curve in curves:\n",
    "        for key, values in alias.items():\n",
    "            if (curve.lower() in [value.lower() for value in values]) & (key in mem_curves):\n",
    "                extracted.append(key)\n",
    "\n",
    "    if set(extracted) == set(mem_curves):\n",
    "        print('All necessary curves in well %s are completed' %las_file.well['WELL'].value)\n",
    "\n",
    "    else:\n",
    "        print('All necessary curves in well %s are incompleted.' %las_file.well['WELL'].value)\n",
    "        \n",
    "        if len(set(extracted).difference(set(mem_curves))) == 1:\n",
    "            print('Curve %s is missing.' %', '.join([curve for curve in set(mem_curves) - set(extracted)]))\n",
    "\n",
    "        else:\n",
    "            print('Curves %s are missing.' %', '.join([curve for curve in set(mem_curves) - set(extracted)]))\n",
    "\n",
    "# Define standard curve alias for well process\n",
    "\n",
    "alias = {\n",
    "'BS' : ['BS', 'BIT'],\n",
    "'CAL' : ['CAL', 'CALI', 'CALS', 'CLDC'],\n",
    "'GR' : ['GR', 'GRGC', 'GAM'],\n",
    "'RHOB' : ['RHOB', 'DEN', 'DENS'],\n",
    "'NPHI' : ['NPHI', 'NPOR'],\n",
    "'MSFL' : ['MSFL', 'R20T', 'RSHAL', 'RESS'],\n",
    "'ILM' : ['ILM', 'R30T', 'R40T', 'R60T', 'RESM'],\n",
    "'RT' : ['RT', 'R85T', 'LLD', 'RESD'],\n",
    "'DTC' : ['DTC', 'DT35', 'DT'],\n",
    "'DTS' : ['DTS', 'DTSM', 'DTSRM', 'DTSXX_COL', 'DTSYY_COL'],\n",
    "'PEF' : ['PEF', 'PE', 'Pe', 'PDPE']\n",
    "}\n",
    "\n",
    "# Define curve name for modeling\n",
    "\n",
    "mem_curves = ['CAL', 'BS', 'GR', 'RHOB', 'NPHI', 'RT', 'MSFL', 'DTC', 'DTS']\n",
    "\n",
    "# Define based curve names\n",
    "\n",
    "based_curves = ['MD', 'AZIMUTH', 'ANGLE', 'BHF']\n",
    "\n",
    "# Define non affected curves and affected curves for synthetic stage\n",
    "\n",
    "non_affected = ['RT', 'MSFL', 'NORM_GR']\n",
    "affected = ['NPHI', 'RHOB', 'DTC', 'DTS'] # element index refers to synthetic ordering\n",
    "\n",
    "# Check available curves\n",
    "\n",
    "print('Available curves for each well;')\n",
    "\n",
    "for las, name in zip(lases, well_names):\n",
    "    print(name, 'curves are: \\n%s' %', '.join([curve.mnemonic for curve in las.curves]))\n",
    "    check_curves(las, alias, mem_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for ordering formations from all well data\n",
    "\n",
    "def merge_sequences(seq1,seq2):\n",
    "    sm = SequenceMatcher(a = seq1, b = seq2)\n",
    "    res = []\n",
    "    \n",
    "    for (op, start1, end1, start2, end2) in sm.get_opcodes():\n",
    "        if op == 'equal' or op == 'delete':\n",
    "            \n",
    "            #This range appears in both sequences, or only in the first one.\n",
    "            \n",
    "            res += seq1[start1:end1]\n",
    "        elif op == 'insert':\n",
    "            \n",
    "            #This range appears in only the second sequence.\n",
    "            \n",
    "            res += seq2[start2:end2]\n",
    "        elif op == 'replace':\n",
    "            \n",
    "            #There are different ranges in each sequence - add both.\n",
    "            \n",
    "            res += seq1[start1:end1]\n",
    "            res += seq2[start2:end2]\n",
    "    \n",
    "    return res\n",
    "\n",
    "# Apply function to ordering all formation\n",
    "\n",
    "all_forms = []\n",
    "\n",
    "for forms in tops:\n",
    "    only_forms = forms.dropna().Formations\n",
    "    if all_forms == []:\n",
    "        for form in only_forms:\n",
    "            all_forms.append(form)\n",
    "    else:\n",
    "        all_forms = merge_sequences(all_forms, list(only_forms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for arranging the formation following the reference one\n",
    " \n",
    "def forms_arr(ref_forms, app_forms):\n",
    "    \"\"\"\n",
    "    This function will arrange the order of the formation in list following the reference.\n",
    "    ref_forms = formation order will be arranged following this reference.\n",
    "    app_forms = list of the formations will be applied.\n",
    "    \"\"\"\n",
    "    for form in ref_forms:\n",
    "        if form.lower() in [form.lower() for form in app_forms]:\n",
    "            app_forms.pop([form.lower() for form in app_forms].index(form.lower()))\n",
    "            app_forms.append(form)\n",
    "    \n",
    "    return app_forms\n",
    "\n",
    "# Function for checking formation names of the input\n",
    "\n",
    "def check_forms(ref_forms, input_forms):\n",
    "    \"\"\"\n",
    "    This function will check the available formation following the reference and prepare the input for the next step.\n",
    "    ref_forms = available formation will be checked based on this reference.\n",
    "    input_names = names of the formation \n",
    "    \"\"\"\n",
    "    form_names = []\n",
    "\n",
    "    for form in ref_forms:\n",
    "        if form.lower() in [name.strip().lower() for name in input_forms.split(',')]:\n",
    "            form_names.append(form)\n",
    "    \n",
    "    return form_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding the formation to the selected formation list\n",
    "\n",
    "def add_forms(selected_forms, non_selected_forms):\n",
    "    \"\"\"\n",
    "    This function can add more formation to selected formation list.\n",
    "    selected_forms = the list of selected formations that will be added more by user.\n",
    "    non_selected_forms = the list of non-selected formations\n",
    "    *check_forms function is required.\n",
    "    \"\"\"\n",
    "    print('Which one do you want to add more?')\n",
    "\n",
    "    while True:\n",
    "        select = input('[Comma can be used for multi-input]: ').strip()\n",
    "        selected_form = check_forms(non_selected_forms, select)\n",
    "\n",
    "        if select == '':\n",
    "            print('Please type formation names!')\n",
    "            continue\n",
    "\n",
    "        elif selected_form == []:\n",
    "            print('Please try again!, formation \\'%s\\' is not found.' %select)\n",
    "            continue\n",
    "\n",
    "        elif set([form.lower() for form in selected_form]).issubset(set([form.lower() for form in non_selected_forms])):\n",
    "            for form in selected_form:\n",
    "                selected_forms.append(form)\n",
    "                non_selected_forms.pop([form.lower() for form in non_selected_forms].index(form.lower()))\n",
    "            break             \n",
    "                 \n",
    "    return selected_forms, non_selected_forms\n",
    "\n",
    "# Function for removing the formation in the selected formation list\n",
    "\n",
    "def remove_forms(selected_forms, non_selected_forms):\n",
    "    \"\"\"\n",
    "    This function can remove the seleted formation.\n",
    "    selected_forms = the list of selected formations that will be removed by user.\n",
    "    non_selected_forms = the list of non-selected formations\n",
    "    *check_forms function is required.\n",
    "    \"\"\"\n",
    "    print('Which one do you want to remove?')\n",
    "\n",
    "    while True:\n",
    "        delete = input('[Comma can be used for multi-input]: ').strip()\n",
    "        del_forms = check_forms(selected_forms, delete)\n",
    "\n",
    "        if delete == '':\n",
    "            print('Please type formation names!')\n",
    "            continue\n",
    "\n",
    "        elif del_forms == []:\n",
    "            print('Please try again!, formation \\'%s\\' is not found.' %delete)\n",
    "            continue       \n",
    "\n",
    "        elif set([form.lower() for form in del_forms]).issubset(set([form.lower() for form in selected_forms])):\n",
    "            for form in del_forms:\n",
    "                selected_forms.pop([form.lower() for form in selected_forms].index(form.lower()))\n",
    "                non_selected_forms.append(form)\n",
    "\n",
    "            if len(del_forms) == 1:\n",
    "                print('Formation %s is removed' %''.join(del_forms))\n",
    "            \n",
    "            else:\n",
    "                print('Formation %s are removed' %', '.join(del_forms))\n",
    "            break\n",
    "    \n",
    "    return selected_forms, non_selected_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all selectable formations\n",
    "\n",
    "print('All formations in this field are: %s.' %', '.join(all_forms))\n",
    "\n",
    "# Define selected formations in this project to focus\n",
    "\n",
    "selected_forms = []\n",
    "non_selected = all_forms.copy() # Be used only in this step\n",
    "\n",
    "while True:\n",
    "    print('Which one is your selected formation?')\n",
    "    select = input('[Comma can be used for multi-input]: ').strip()\n",
    "    selected_form = check_forms(all_forms, select)\n",
    "\n",
    "    if select == '':\n",
    "        print('Please type formation names!')\n",
    "        continue\n",
    "\n",
    "    elif selected_form == []:\n",
    "        print('Please try again!, formation \\'%s\\' is not found.' %select)\n",
    "        continue\n",
    "\n",
    "    elif set([form.lower() for form in selected_form]).issubset(set([form.lower() for form in all_forms])):\n",
    "        \n",
    "        for form in selected_form:\n",
    "            selected_forms.append(form)\n",
    "            non_selected.pop([form.lower() for form in non_selected].index(form.lower()))\n",
    "\n",
    "        while True:\n",
    "            selected_forms = forms_arr(all_forms, selected_forms)\n",
    "            non_selected = forms_arr(all_forms, non_selected)        \n",
    "\n",
    "            print('Now, only formation \\'%s\\' will be your selected formations' %', '.join(selected_forms))\n",
    "            confirm = input('Are you okay with this? [Ok/Not]: ').strip()\n",
    "            \n",
    "            if confirm.lower() == 'ok':\n",
    "                print('Got it, sir/ma\\'am!')\n",
    "                break\n",
    "            \n",
    "            elif confirm.lower() == 'not':\n",
    "                \n",
    "                while True:\n",
    "                    options = input('What do you want to do? add more or edit (remove)? [Add/Remove]: ').strip()\n",
    "\n",
    "                    if options.lower() == 'add':\n",
    "                        print('The other formation in this field are: %s.' %', '.join(non_selected))\n",
    "                        selected_forms, non_selected = add_forms(selected_forms, non_selected)\n",
    "                        break\n",
    "\n",
    "                    elif options.lower() == 'remove':\n",
    "                        selected_forms, non_selected = remove_forms(selected_forms, non_selected)\n",
    "\n",
    "                        if selected_forms == []:\n",
    "                            print('No formation is selected!, please select formation.')\n",
    "                            print('The available formation in this field are: %s.' %', '.join(all_forms))\n",
    "                            selected_forms, non_selected = add_forms(selected_forms, non_selected)\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        print('Please confirm again!')\n",
    "                        continue\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                print('Please confirm again!')\n",
    "                continue\n",
    "        break"
   ]
  },
  {
   "source": [
    "## Depth conversion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for TVD computation by minimum curvature method\n",
    "\n",
    "def tvd_mini_cuv(dev):\n",
    "    \"\"\"\n",
    "    TVD computation function using minimum curvature survey calculation method\n",
    "    dev = Deviation survey data in pandas data frame which contains:\n",
    "             1. Measured depth (MD) in column name \"MD\"\n",
    "             2. Azimuth direction (AZIMUTH) in column name \"AZIMUTH\"\n",
    "             3. Inclination angle (ANGLE) in column name \"ANGLE\"\n",
    "    \"\"\"\n",
    "    # setup parameters\n",
    "    \n",
    "    md = dev.MD\n",
    "    prev_md = md.shift(periods = 1, fill_value = 0)\n",
    "    diff_md = md - prev_md\n",
    "    \n",
    "    ang = dev.ANGLE\n",
    "    prev_ang = ang.shift(periods = 1, fill_value = 0)\n",
    "    diff_ang = ang - prev_ang\n",
    "    \n",
    "    azi = dev.AZIMUTH\n",
    "    prev_azi = azi.shift(periods = 1, fill_value = 0)\n",
    "    diff_azi = azi - prev_azi\n",
    "    \n",
    "    # computation\n",
    "    \n",
    "    cos_theta = np.cos(np.radians(diff_ang)) - (np.sin(np.radians(ang)) * np.sin(np.radians(prev_ang)) * (1 - np.cos(np.radians(diff_azi))))\n",
    "    theta = np.arccos(cos_theta)\n",
    "    \n",
    "    rf = ((2 / theta) * np.tan(theta/2)).fillna(0)\n",
    "    \n",
    "    dev['TVD'] = np.cumsum((diff_md / 2) * (np.cos(np.radians(ang)) + np.cos(np.radians(prev_ang))) * rf)\n",
    "    \n",
    "    return dev\n",
    "\n",
    "# Calculate TVD for all well deviations in deviation files\n",
    "\n",
    "devs = list(map(tvd_mini_cuv, devs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate function to convert MD to TVD in data with deviation survey data \n",
    "\n",
    "def tvd_interpolate(las, df_las, dev):\n",
    "    \"\"\"\n",
    "    MD to TVD interpolation using linear interpolation method and update las file\n",
    "    las = las file (.las) of the well data\n",
    "    df_las = las input in pandas data frame contains depth column in measured depth (MD)\n",
    "    dev = deviation survey data in pandas data frame contains depth columns in both measured depth (MD) and true vertical depth (TVD)\n",
    "    \"\"\"\n",
    "    # Merge deviation file with well data \n",
    "    \n",
    "    df_las = df_las.reset_index()\n",
    "    df_las = pd.concat([dev[['MD', 'AZIMUTH', 'ANGLE', 'TVD']], df_las]).sort_values(by = ['MD']).reset_index(drop = True)\n",
    "    \n",
    "    # Insert true vertical depth using linear interpolation\n",
    "    \n",
    "    for col in df_las[['AZIMUTH', 'ANGLE', 'TVD']].columns:\n",
    "        df_las[col] = df_las[col].interpolate(method = 'linear', limit_area = 'inside')\n",
    "        \n",
    "    # Set true vertical depth as file indices\n",
    "        \n",
    "    df_las = df_las.dropna(subset = ['TVD']).set_index('TVD')\n",
    "    df_las = df_las.drop(list(dev['TVD']))\n",
    "    \n",
    "    # Update las files\n",
    "\n",
    "    las.insert_curve(0, 'TVD', df_las.index, unit = 'm', descr = 'True Vertical Depth', value = '')\n",
    "    las.insert_curve(1, 'MD', df_las.index, unit = 'm', descr = 'Measured Depth', value = '')\n",
    "    las.insert_curve(2, 'AZIMUTH', df_las.index, unit = 'degree', descr = 'well Deviation in Azimuth', value = '')\n",
    "    las.insert_curve(3, 'ANGLE', df_las.index, unit = 'degree', descr = 'well Deviation in Angle', value = '')\n",
    "    del las.curves['DEPTH']\n",
    "\n",
    "    print('Measured depth (MD) is converted to True vertical depth (TVD) for well %s' %las.well['WELL'].value)\n",
    "    \n",
    "    return las, df_las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adjust true vertical depth of well logging data\n",
    "\n",
    "def remove_gap(tvd_las, gap):\n",
    "    \"\"\"\n",
    "    This function can remove air gap from the true vertical depth (TVD) for well logging data.\n",
    "    tvd_las = las input in pandas data frame contains depth column in true vertical depth (TVD)\n",
    "    gap = air gap value (onshore = kelly bushing - ground level, offshore = kelly bushing)\n",
    "    \"\"\"\n",
    "    tvd_las = tvd_las.reset_index()\n",
    "    tvd_las['TVD'] = tvd_las['TVD'] - gap\n",
    "    tvd_las['MD'] = tvd_las['MD'] - gap\n",
    "    tvd_las = tvd_las.set_index('TVD')\n",
    "\n",
    "    return tvd_las\n",
    "\n",
    "# Implement interpolation function\n",
    "\n",
    "tvd_lases = []\n",
    "\n",
    "for las, df_las, dev, gap in zip(lases, df_lases, devs, air_gaps):\n",
    "    las, tvd_las = tvd_interpolate(las, df_las, dev)\n",
    "    tvd_las = remove_gap(tvd_las, gap)\n",
    "    tvd_lases.append(tvd_las)"
   ]
  },
  {
   "source": [
    "## Bad Hole Flag (BHF)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for create Bad Hole flag\n",
    "\n",
    "def create_bhf(las, tvd_las, alias):\n",
    "    \"\"\"\n",
    "    This function can compute Bad Hole Flag using confidential interval (ci) and update las file\n",
    "    las = las file (.las) of the well data\n",
    "    tvd_las = well logging data in data frame (converted true vertical depth)\n",
    "    * Caliper and bitsize data are required.\n",
    "    \"\"\"\n",
    "    # ci = confidential interval factor (0.00-1.00, default = 0.75)\n",
    "    \n",
    "    ci = 0.75 # default\n",
    "\n",
    "    for col in tvd_las.columns:\n",
    "        if col in alias['CAL']:\n",
    "            caliper = col\n",
    "        elif col in alias['BS']:\n",
    "            bitsize = col\n",
    "\n",
    "    confirm = 'not'\n",
    "\n",
    "    while not confirm.lower() == 'ok':\n",
    "        diff = tvd_las[caliper] - tvd_las[bitsize]\n",
    "        interval = st.norm.interval(alpha = ci, loc = round(np.mean(diff), 2), scale = round(np.std(diff), 2))\n",
    "\n",
    "        tvd_las['BHF'] = (diff.dropna() > interval[0]) & (diff.dropna() < interval[1])\n",
    "        tvd_las['BHF'] = tvd_las['BHF']*1\n",
    "        tvd_las['BHF'] ^= 1\n",
    "\n",
    "        #create figure\n",
    "\n",
    "        fig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (6, 10))\n",
    "        fig.suptitle(las.well['WELL'].value, fontsize = 15, y = 1.0)\n",
    "\n",
    "        #General setting for all axis\n",
    "        \n",
    "        for ax in axis:\n",
    "            ax.set_ylim(tvd_las.index.min(), tvd_las.index.max())\n",
    "            ax.invert_yaxis()\n",
    "            ax.minorticks_on() #Scale axis\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.grid(which = 'major', linestyle = '-', linewidth = '0.5', color = 'green')\n",
    "            ax.grid(which = 'minor', linestyle = ':', linewidth = '0.5', color = 'black') \n",
    "\n",
    "        # caliper - bitsize plot\n",
    "        \n",
    "        ax11 = axis[0].twiny()\n",
    "        ax11.set_xlim(6,15)\n",
    "        ax11.plot(tvd_las[bitsize], tvd_las.index, color = 'black')\n",
    "        ax11.spines['top'].set_position(('outward',0))\n",
    "        ax11.set_xlabel('BS[in]',color = 'black')\n",
    "        ax11.tick_params(axis = 'x', colors = 'black')\n",
    "        \n",
    "        ax12 = axis[0].twiny()\n",
    "        ax12.set_xlim(6,15)\n",
    "        ax12.plot(tvd_las[caliper], tvd_las.index, color = 'grey' )\n",
    "        ax12.spines['top'].set_position(('outward',40))\n",
    "        ax12.set_xlabel('CAL[in]',color = 'grey')\n",
    "        ax12.tick_params(axis = 'x', colors = 'grey')\n",
    "\n",
    "        ax12.grid(True)\n",
    "\n",
    "        # Bad Hole Flag plot\n",
    "    \n",
    "        ax21 = axis[1].twiny()\n",
    "        ax21.plot(tvd_las['BHF'], tvd_las.index, color = 'red')\n",
    "        ax21.fill_betweenx(tvd_las.index, 0, tvd_las['BHF'], color = 'red', label = 'Bad hole')\n",
    "        ax21.spines['top'].set_position(('outward',0))\n",
    "        ax21.set_xlabel('BHF', color = 'red')\n",
    "        ax21.tick_params(axis = 'x', colors = 'red')\n",
    "        ax21.legend(loc = 'upper right')\n",
    "        \n",
    "        ax21.grid(True)\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        while True:\n",
    "            confirm = input('Are you ok with this created bad hole flag? [Ok/Not]: ').strip()   \n",
    "\n",
    "            if confirm.lower() == 'ok':\n",
    "                las.append_curve('BHF', tvd_las['BHF'], unit = 'unitless', descr = 'Bad Hole Flag', value = '')\n",
    "                break\n",
    "\n",
    "            elif confirm.lower() == 'not':\n",
    "                \n",
    "                while True:\n",
    "                    ci = float(input('Please type value between 0.00 - 1.00 (0.75 is default) to adjust: ').strip())\n",
    "                \n",
    "                    if 0 < ci < 1:\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        print('Input value is out of range!')\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                print('please confirm again!')\n",
    "\n",
    "    return las, tvd_las\n",
    "\n",
    "# Create Bad Hole flag for each well\n",
    "\n",
    "for las, tvd_las in zip(lases, tvd_lases):\n",
    "    las, tvd_las = create_bhf(las, tvd_las, alias)"
   ]
  },
  {
   "source": [
    "## Quality Control 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for initial plot for first inspection\n",
    "\n",
    "def initial_inspection(las, tvd_las, inspect_name):\n",
    "    \"\"\"\n",
    "    For all curve initial inspection\n",
    "    las = las file (.las) of the well data\n",
    "    tvd_las = well logging data in data frame (converted true vertical depth)\n",
    "    inspect_name = name of saved figure\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "\n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = len(tvd_las.columns), figsize = (30,20), sharey = True)\n",
    "    fig.suptitle(las.well['WELL'].value, fontsize = 30, y = 1.0)\n",
    "    \n",
    "    units = [curve.unit for curve in las.curves]\n",
    "    units.pop(0)\n",
    "\n",
    "    # Plot setting for all axis\n",
    "\n",
    "    for ax, col, unit in zip(axis, tvd_las.columns, units):\n",
    "        ax.set_ylim(tvd_las.index.min(), tvd_las.index.max())\n",
    "        ax.invert_yaxis()\n",
    "        ax.minorticks_on() #Scale axis\n",
    "        ax.grid(which = 'major', linestyle = '-', linewidth = '0.5', color = 'green')\n",
    "        ax.grid(which = 'minor', linestyle = ':', linewidth = '0.5', color = 'black')\n",
    "        ax.set_xlabel(col + '\\n(%s)' %unit, fontsize = 15)\n",
    "\n",
    "        if (col in alias['RT']) or (col in alias['ILM']) or (col in alias['MSFL']):\n",
    "            ax.plot(tvd_las[col], tvd_las.index)\n",
    "            ax.set_xscale('log')\n",
    "\n",
    "        elif col == 'BHF':\n",
    "            ax.plot(tvd_las[col], tvd_las.index)\n",
    "            ax.fill_betweenx(tvd_las.index, 0, tvd_las[col], label = 'Bad hole')\n",
    "        \n",
    "        else:\n",
    "            ax.plot(tvd_las[col], tvd_las.index)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save files\n",
    "\n",
    "    inspect_folder = 'LQC_Inspect'\n",
    "    inspect_path = os.path.join(sav_path, inspect_folder)\n",
    "\n",
    "    if not os.path.isdir(inspect_path):\n",
    "        os.makedirs(inspect_path)\n",
    "\n",
    "    plt.savefig(os.path.join(inspect_path, inspect_name), dpi = 200, format = 'png')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot available curves\n",
    "\n",
    "for las, tvd_las in zip(lases, tvd_lases):\n",
    "    inspect_name = 'LQC_' + las.well['WELL'].value + '_Inspect' + '.png'\n",
    "    initial_inspection(las, tvd_las, inspect_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for removing some zone.\n",
    "\n",
    "def eliminate_zone(tvd_las, alias, top_zone, bottom_zone, based_curves):\n",
    "    \"\"\"\n",
    "    This function is for data elimination within the interested zone. \n",
    "    All curves within that zone will be removed.\n",
    "    Except measured depth (MD), azimuth direction (AZIMUTH), angle or deviation (ANGLE), bitsize (BS), caliper (CAL) and bad hole flag (BHF).\n",
    "    tvd_las = well logging data in pandas data frame in TVD depth.\n",
    "    alias = curve alias or alterative name of the curve.\n",
    "    top_zone = Top TVD depth of the zone you want to remove.\n",
    "    bottom_zone = Bottom TVD depth of the zone you want to remove.\n",
    "    based_curves = list of based curve names\n",
    "    \"\"\"\n",
    "     # Set data columns for elimination\n",
    "\n",
    "    data_cols = tvd_las.columns\n",
    "    base_cols = based_curves.copy()\n",
    "    edit_cols = []\n",
    "\n",
    "    for bs in alias['BS']:\n",
    "        base_cols.append(bs)\n",
    "\n",
    "    for cal in alias['CAL']:\n",
    "        base_cols.append(cal)\n",
    "\n",
    "    for col in data_cols:\n",
    "        if col not in base_cols:\n",
    "            edit_cols.append(col)\n",
    "\n",
    "    # Eliminate the data within the assigned interval\n",
    "\n",
    "    tvd_las.loc[(tvd_las.index > float(top_zone)) & (tvd_las.index < float(bottom_zone)), edit_cols] = np.nan\n",
    "\n",
    "    return tvd_las\n",
    "\n",
    "# Define well and zone of interest\n",
    "\n",
    "while True:\n",
    "    print('Are there any depth interval you would like to remove or delete?')\n",
    "    answer = input('Please type Yes or No [Yes/No]: ').strip()\n",
    "\n",
    "    if answer.lower() == 'yes':\n",
    "\n",
    "        while True:\n",
    "            print('There are %d wells.' %len(well_names))\n",
    "            print('%s, Which one you want to edit?' %', '.join(well_names))\n",
    "            name = input('Please indicate the well name you want to edit: ').strip()         \n",
    "            \n",
    "            if name.lower() in [name.lower() for name in well_names]:\n",
    "                i = [name.lower() for name in well_names].index(name.lower())\n",
    "\n",
    "                while True:\n",
    "                    depth_min = tvd_lases[i].index.min()\n",
    "                    depth_max = tvd_lases[i].index.max()\n",
    "                    print('This well has data in depth from', round(depth_min, 2), 'to', round(depth_max, 2))\n",
    "                    top_zone = float(input('Please indicate top depth of the zone or interval you want to edit in TVD depth: ').strip())\n",
    "\n",
    "                    if (top_zone > depth_min) & (top_zone < depth_max):\n",
    "\n",
    "                        while True:\n",
    "                            bottom_zone = float(input('Please indicate bottom depth of the zone or interval you want to edit in TVD depth: ').strip())\n",
    "                            \n",
    "                            if (bottom_zone > top_zone) & (bottom_zone < depth_max):\n",
    "                                \n",
    "                                while True:\n",
    "                                    print('The data of well', lases[i].well['WELL'].value, 'in TVD depth from', top_zone, 'to', bottom_zone, 'will be eliminated.')\n",
    "                                    confirm = input('Are you sure? [Yes/No]: ').strip() \n",
    "                                    \n",
    "                                    if confirm.lower() == 'yes':\n",
    "                                        tvd_las = eliminate_zone(tvd_lases[i], alias, top_zone, bottom_zone, based_curves)\n",
    "                                        inspect_edited_name = 'LQC_' + lases[i].well['WELL'].value + '_Inspect_Edited' + '.png'\n",
    "                                        initial_inspection(lases[i], tvd_lases[i], inspect_edited_name)\n",
    "                                        print('The data has been eliminated.')\n",
    "                                        break\n",
    "                                        \n",
    "                                    elif confirm.lower() == 'no':\n",
    "                                        break\n",
    "\n",
    "                                    else:\n",
    "                                        print('Please comfirm again!')\n",
    "                                        continue\n",
    "                                break\n",
    "                                        \n",
    "                            else:\n",
    "                                print('Your bottom depth is out of range')\n",
    "                                continue\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        print('Your top depth is out of range')\n",
    "                        continue\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                print('Your well %s is not found., Please select again!' %name)\n",
    "                continue\n",
    "        continue\n",
    "\n",
    "    elif answer.lower() == 'no':\n",
    "        print('Noted, Sir/Ma\\'am!')\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        print('Please comfirm again!')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for standardizing or renaming based on alias\n",
    "\n",
    "def apply_alias(las, tvd_las, alias):\n",
    "    \"\"\"\n",
    "    This function is going to rename curves based on alias. The duplicates will be named followed by the number.\n",
    "    las = las file (.las) of the well data\n",
    "    tvd_las = well logging data in pandas data frame in TVD depth.\n",
    "    alias = curve alias or alterative name of the curve.\n",
    "    \"\"\"\n",
    "    # Get standard curve name from alias\n",
    "\n",
    "    new_cols = {}\n",
    "    seen = {}\n",
    "    dupes = []\n",
    "\n",
    "    for col in tvd_las.columns:\n",
    "        for key, values in alias.items():\n",
    "            \n",
    "            if col in values:\n",
    "                new_col = key\n",
    "\n",
    "                if key not in seen:\n",
    "                    seen[key] = 1\n",
    "                \n",
    "                else:\n",
    "                    if seen[key] == 1:\n",
    "                        dupes.append(key)\n",
    "\n",
    "                    seen[key] += 1\n",
    "                    new_col = \"{}_{}\".format(key, seen[key])\n",
    "\n",
    "                new_cols[col] = new_col\n",
    "\n",
    "    # Apply to tvd_las\n",
    "\n",
    "    tvd_las = tvd_las.rename(columns = new_cols)\n",
    "\n",
    "    # Apply to las\n",
    "\n",
    "    for key, value in new_cols.items():\n",
    "        las.curves[key].mnemonic = value\n",
    "\n",
    "    print('All curve names of well %s are standardized' %las.well['WELL'].value)\n",
    "    \n",
    "    return las, tvd_las, seen, dupes"
   ]
  },
  {
   "source": [
    "# Function for setting up the well logging data without the duplicate\n",
    "\n",
    "def setup_curve(las, well, seen, dupes, mem_curves, based_curves):\n",
    "    \"\"\"\n",
    "    This function will select and eliminate curve data for setting up modeling curve inputs.\n",
    "    las = las file (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    seen = dictionary contains the name and number of curve\n",
    "    dupes = list of duplicated curve name\n",
    "    mem_curves = necessary curve names for modeling\n",
    "    based_curves = list of based curve names\n",
    "    \"\"\"\n",
    "    # Select modeling curves\n",
    "\n",
    "    for col in well.columns:\n",
    "        if col.split('_')[0] not in (based_curves + mem_curves):\n",
    "            well = well.drop([col], axis=1)\n",
    "            del las.curves[col]\n",
    "\n",
    "    # Manage duplicate curves\n",
    "\n",
    "    new_col = {}\n",
    "    choices = []\n",
    "\n",
    "    for key, value in seen.items():\n",
    "        if (key in mem_curves) & (key in dupes):\n",
    "            print('%d curves of %s are found as duplicated curves for well %s' %(value, key, las.well['WELL'].value))\n",
    "\n",
    "            for num in range(value):\n",
    "                if num == 0:\n",
    "                    curve = las.curves[key]\n",
    "                    print('%s curve is %s' %(curve.mnemonic, curve.descr))\n",
    "                    choices.append(key)\n",
    "                else:\n",
    "                    curve = las.curves[key + '_' + str(num+1)]\n",
    "                    print('%s curve is %s' %(curve.mnemonic, curve.descr))\n",
    "                    choices.append(key + '_' + str(num+1))\n",
    "\n",
    "            while True:\n",
    "                select = input('Please select a curve for %s: ' %key).strip()\n",
    "\n",
    "                if select.lower() in [choice.lower() for choice in choices]:\n",
    "                    index = [choice.lower() for choice in choices].index(select.lower())\n",
    "                    new_col[choices[index]] = key\n",
    "                    choices.pop(index)\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    print('Please type again!, your curve %s is not found.' %select)\n",
    "                    continue\n",
    "            \n",
    "    # Eliminate duplicates\n",
    "\n",
    "    for col in choices:\n",
    "        well = well.drop([col], axis=1)\n",
    "        del las.curves[col]\n",
    "            \n",
    "    # Set curve name\n",
    "    \n",
    "    well = well.rename(columns = new_col)\n",
    "\n",
    "    for key, value in new_col.items():\n",
    "        las.curves[key].mnemonic = value\n",
    "\n",
    "    print('All curve data of well %s are setup already' %las.well['WELL'].value)\n",
    "\n",
    "    return las, well\n",
    "\n",
    "# Rename curve and setup curve for modeling\n",
    "\n",
    "wells = []\n",
    "\n",
    "print('The system is standardizing and setting up the curves.')\n",
    "\n",
    "for las, tvd_las in zip(lases, tvd_lases):\n",
    "    las, well, seen, dupes = apply_alias(las, tvd_las.copy(), alias)\n",
    "    las, well = setup_curve(las, well, seen, dupes, mem_curves, based_curves)\n",
    "    wells.append(well)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for controling the data by confidential interval (ci)\n",
    "\n",
    "def data_control(well):\n",
    "    \"\"\"\n",
    "    This function can limit exceeded value of the data by using confidential interval (ci)\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    \"\"\"\n",
    "    # ci = confidential interval factor (0.00-1.00, default = 0.95)\n",
    "\n",
    "    ci = 0.95\n",
    "\n",
    "    not_apply_cols = based_curves + ['BS', 'CAL']\n",
    "\n",
    "    for col in well.columns:\n",
    "        if col not in not_apply_cols:\n",
    "            interval = st.norm.interval(alpha = ci, loc = round(np.mean(well[col]), 2), scale = round(np.std(well[col]), 2))\n",
    "            well.loc[(well[col] < interval[0]) | (well[col] > interval[1]), col] = np.nan\n",
    "    \n",
    "    return well\n",
    "\n",
    "# Function for eliminating bad data using bad hole flag\n",
    "\n",
    "def bhf_control(well, affected):\n",
    "    \"\"\"\n",
    "    This function can eliminate the affected data within the bad zone including density (RHOB), neutron porosity (NPHI), P-sonic (DTC) and S-sonic (DTS).\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    affected = list of affected curve names.\n",
    "    *Bad hole flag must be created using create_bhf function\n",
    "    \"\"\"\n",
    "    # Eliminate the data based on bad hole flag\n",
    "\n",
    "    for col in affected:\n",
    "        well.loc[((well[col] * (well.BHF ^ 1)) == 0), [col]] = np.nan\n",
    "\n",
    "    return well\n",
    "\n",
    "# Apply the functions to limit and eliminate the data to be ready for synthetic stage\n",
    "\n",
    "for well in wells:\n",
    "    well = data_control(well)\n",
    "    well = bhf_control(well, affected)"
   ]
  },
  {
   "source": [
    "## Data synthetic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize gamma ray log for data synthetic\n",
    "\n",
    "def norm_gr(las, well):\n",
    "    \"\"\"\n",
    "    This function is used for min-max normalization calculation for well synthetic.\n",
    "    las = las file (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    \"\"\"\n",
    "    # Normolize gamma ray curve\n",
    "\n",
    "    well['NORM_GR'] = (well.GR - np.min(well.GR)) / (np.max(well.GR) - np.min(well.GR))\n",
    "\n",
    "    # Update las file\n",
    "\n",
    "    las.append_curve('NORM_GR', well.NORM_GR, unit = 'unitless', descr = 'Normalized Gamma Ray', value = '')\n",
    "\n",
    "    return las, well\n",
    "\n",
    "# Apply normalization\n",
    "\n",
    "for las, well in zip(lases, wells):\n",
    "    las, well = norm_gr(las, well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Checking normalized gamma ray\n",
    "\n",
    "def hist_norm_gr(wells, well_names, norm_name):\n",
    "    \"\"\"\n",
    "    This function can plot histogram of normalized gamma ray data from all well.\n",
    "    wells = list of well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    well_names = list of well name in this field\n",
    "    norm_name = name of saved figure\n",
    "    *Normalized Gamma Ray must be calculated using norm_gr function.\n",
    "    \"\"\"\n",
    "    # bins = a number of histogram bar (default = 150)\n",
    "\n",
    "    bins = 150\n",
    "\n",
    "    # Create figure\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (20,10), sharey = True)\n",
    "    fig.suptitle('histogram of Normalized Gamma Ray', fontsize= 15, y = 0.98)\n",
    "    \n",
    "    # Plot histrogram\n",
    "    for well, name in zip(wells, well_names):\n",
    "        ax[0].hist(well.GR, bins = bins, histtype = 'step', label = name)\n",
    "        ax[0].set_xlabel('Gamma Ray (API)')\n",
    "        ax[0].set_ylabel('Frequency')\n",
    "        ax[0].set_title('Before')\n",
    "        ax[0].legend(loc='upper left')\n",
    "        \n",
    "        ax[1].hist(well.NORM_GR, bins = bins, histtype = 'step', label = name)\n",
    "        ax[1].set_xlabel('Normalized Gamma Ray')\n",
    "        ax[1].set_ylabel('Frequency')\n",
    "        ax[1].set_title('After')\n",
    "        ax[1].set_xlim([0,1])\n",
    "        ax[1].legend(loc='upper left')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save files\n",
    "\n",
    "    synthetic_folder = 'LQC_Synthetic'\n",
    "    synthetic_path = os.path.join(sav_path, synthetic_folder)\n",
    "\n",
    "    if not os.path.isdir(synthetic_path):\n",
    "        os.makedirs(synthetic_path)\n",
    "\n",
    "    plt.savefig(os.path.join(synthetic_path, norm_name), dpi = 200, format = 'png')\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "# Check normalized gamma ray\n",
    "\n",
    "norm_name = 'LQC_Norm_GR.png'\n",
    "hist_norm_gr(wells, well_names, norm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating the data set of synthetic modeling\n",
    "\n",
    "def set_data(wells, non_affected, affected):\n",
    "    \"\"\"\n",
    "    This function can create the data set for model training and testing of synthetic function.\n",
    "    wells = list of well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    non_affected = list of non affected curve names for synthetic.\n",
    "    affected =  list of affected curve names for synthetic.\n",
    "    \"\"\"\n",
    "    # Indicate curves for data set\n",
    "\n",
    "    req_curves = non_affected.copy() + affected.copy()\n",
    "\n",
    "    # Build an empty data set and collect the data from each well\n",
    "    \n",
    "    data_set = pd.DataFrame()\n",
    "    \n",
    "    for well in wells:\n",
    "        data_set = pd.concat([data_set, well[req_curves]])\n",
    "            \n",
    "    data_set = data_set.dropna()\n",
    "            \n",
    "    return data_set\n",
    "\n",
    "# Generate the data set for synthetic stage\n",
    "\n",
    "data_set = set_data(wells, non_affected, affected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for curve synthetic (filled nan with mean)\n",
    "\n",
    "def well_syn(las, well, data_set, non_affected, affected):\n",
    "    \"\"\"\n",
    "    This function can synthesize bad data within bad zone indicated by bad hole flag.\n",
    "    This function is going to fix or synthetic the curve one at the time until all curve are fixed.\n",
    "    This function based on machine learning techniques (default = multilinear regression and random forest regression)\n",
    "    \n",
    "    RT, MSFL and NORM_GR are used as initial curves.\n",
    "    NPHI, RHOB, DTC and DTS will be synthesized respectively.\n",
    "\n",
    "    Neutron porosity synthesizing using;\n",
    "    1.) Deep resistivity (RT)\n",
    "    2.) Shallow resistivity (MSFL)\n",
    "    3.) Normalized gamma ray (NORM_GR)\n",
    "    \n",
    "    Density synthesizing using;\n",
    "    1.) Deep resistivity (RT)\n",
    "    2.) Shallow resistivity (MSFL)\n",
    "    3.) Normalized gamma ray (NORM_GR)\n",
    "    4.) Neutron porosity (NPHI)\n",
    "    \n",
    "    P-Sonic synthesizing using;\n",
    "    1.) Deep resistivity (RT)\n",
    "    2.) Shallow resistivity (MSFL)\n",
    "    3.) Normalized gamma ray (NORM_GR)\n",
    "    4.) Neutron porosity (NPHI)\n",
    "    5.) Density (RHOB)\n",
    "    \n",
    "    S-Sonic synthesizing using;\n",
    "    1.) Deep resistivity (RT)\n",
    "    2.) Shallow resistivity (MSFL)\n",
    "    3.) Normalized gamma ray (NORM_GR)\n",
    "    4.) Neutron porosity (NPHI)\n",
    "    5.) Density (RHOB)\n",
    "    6.) P-Sonic (DTC)\n",
    "    \n",
    "    las = las file (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    data_set = data set for model training and testing in pandas data frame.\n",
    "    *data_set can be created using set_data function.\n",
    "    non_affected = list of non affected curve names for synthetic.\n",
    "    affected =  list of affected curve names for synthetic. \n",
    "    *The element index of affected curve names will affect synthetic ordering.\n",
    "    \"\"\"\n",
    "    # test_size = size of test data for modeling (0.00 - 1.00, default = 0.3)\n",
    "    \n",
    "    test_size = 0.3\n",
    "\n",
    "    # n_tree = number of decision tree in random forest regression technique (default = 10)\n",
    "\n",
    "    n_tree = 10\n",
    "\n",
    "    # Set initial and synthesized data\n",
    "\n",
    "    initial = non_affected.copy()\n",
    "    syns = affected.copy()\n",
    "\n",
    "    cols = initial.copy()\n",
    "\n",
    "    print('System is synthesizing the data for well %s' %las.well['WELL'].value)\n",
    "\n",
    "    # Synthesize data one at the time\n",
    "\n",
    "    for syn in syns:\n",
    "\n",
    "        r2 = {}\n",
    "        \n",
    "        # Split the data\n",
    "        \n",
    "        input_training = data_set[initial]\n",
    "        output_traning = data_set[syn]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_training, output_traning, test_size = test_size, random_state = 0)\n",
    "\n",
    "        # Setup synthesizing input (Nan values are filled with mean column values)\n",
    "\n",
    "        syn_input = well[cols].fillna(well[cols].mean())\n",
    "        \n",
    "        # Multilinear regression modeling\n",
    "\n",
    "        mlr = LinearRegression()\n",
    "        mlr.fit(X_train, y_train)\n",
    "\n",
    "        mlr_r = mlr.score(X_test, y_test)\n",
    "        r2[mlr_r] = [mlr.predict(syn_input), 'Multilinear Regression', mlr_r]\n",
    "\n",
    "        # Random forest regression modeling\n",
    "\n",
    "        rfr = RandomForestRegressor(n_estimators = n_tree)\n",
    "        rfr.fit(X_train, y_train)\n",
    "\n",
    "        rfr_r = rfr.score(X_test, y_test)\n",
    "        r2[rfr_r] = [rfr.predict(syn_input), 'Random Forest Regression', rfr_r]\n",
    "\n",
    "        # Select the best regression\n",
    "\n",
    "        syn_output = best_r2(r2)[0]\n",
    "        print('%s is implemented for %s with R-squared value %f' %(best_r2(r2)[1], syn, best_r2(r2)[2]))\n",
    "\n",
    "        well['SYN_' + syn] = pd.DataFrame(syn_output, index = well[cols].index)\n",
    "        \n",
    "        # Merge curve where synthetic curve replace bad hole sections, and good original curve data remains in place\n",
    "        \n",
    "        well['MRG_' + syn] = well[syn].fillna(well['SYN_' + syn], inplace = False)\n",
    "                \n",
    "        # Iterate new syntheric curve with new initial curves\n",
    "        \n",
    "        initial.append(syn)\n",
    "        cols.append('MRG_' + syn)\n",
    "\n",
    "    # Update las file\n",
    "\n",
    "    las.append_curve('SYN_NPHI', well['SYN_NPHI'], unit = 'V/V', descr = 'Synthetic neutron porosity', value = '')\n",
    "    las.append_curve('MRG_NPHI', well['MRG_NPHI'], unit = 'V/V', descr = 'Merged neutron porosity', value = '')\n",
    "\n",
    "    las.append_curve('SYN_RHOB', well['SYN_RHOB'], unit = 'g/c3', descr = 'Synthetic density', value = '')\n",
    "    las.append_curve('MRG_RHOB', well['MRG_RHOB'], unit = 'g/c3', descr = 'Merged density', value = '')\n",
    "\n",
    "    las.append_curve('SYN_DTC', well['SYN_DTC'], unit = 'us/ft', descr = 'Synthetic P-sonic', value = '')\n",
    "    las.append_curve('MRG_DTC', well['MRG_DTC'], unit = 'us/ft', descr = 'Merged P-sonic', value = '')\n",
    "\n",
    "    las.append_curve('SYN_DTS', well['SYN_DTS'], unit = 'us/ft', descr = 'Synthetic S-sonic', value = '')\n",
    "    las.append_curve('MRG_DTS', well['MRG_DTS'], unit = 'us/ft', descr = 'Merged S-sonic', value = '')\n",
    "    \n",
    "    return las, well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for selecting the best value\n",
    "\n",
    "def best_r2(r2):\n",
    "    \"\"\"\n",
    "    This function can select the best element from dictionary by the highest r-squared value.\n",
    "    r2 = r-squared value with the elements in dictionary form.\n",
    "    \"\"\"\n",
    "    max = list(r2.keys())[0]\n",
    "\n",
    "    for x in r2: \n",
    "        if x > max : \n",
    "             max = x \n",
    "      \n",
    "    return r2[max]\n",
    "\n",
    "# Synthesize the data\n",
    "\n",
    "for las, well in zip(lases, wells):\n",
    "    las, well = well_syn(las, well, data_set, non_affected, affected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for ploting comparision between before and after synthesizing\n",
    "\n",
    "def syn_compare(las, well, syn_name):\n",
    "    \"\"\"\n",
    "    This function shows ploting between before and after synthesizing.\n",
    "    las = las file (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    syn_name = name of saved figure\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    \n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 5, figsize = (12,20), sharey = True)\n",
    "    fig.suptitle(las.well['WELL'].value, fontsize= 20, y = 1)\n",
    "    \n",
    "    #General setting for all axis\n",
    "    \n",
    "    for ax in axis:\n",
    "        ax.set_ylim(well.index.min(), well.index.max())\n",
    "        ax.invert_yaxis()\n",
    "        ax.minorticks_on() #Scale axis\n",
    "        ax.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "        ax.grid(which='minor', linestyle=':', linewidth='0.5', color='blue') \n",
    "    \n",
    "    # Neutron porosity plot\n",
    "    \n",
    "    axis[0].plot(well.SYN_NPHI, well.index, linewidth='0.8', color = 'red', label = 'SYN_NPHI')\n",
    "    axis[0].plot(well.NPHI, well.index, linewidth='0.8', color = 'blue', label = 'NPHI')\n",
    "    axis[0].plot(well.MRG_NPHI, well.index, linewidth='0.8', color = 'black', label = 'MRG_NPHI', linestyle = '--')\n",
    "    axis[0].set_xlim(-0.15, 0.45)\n",
    "    axis[0].set_xlabel('(V/V)' + '\\n' + 'Correlation : %.2f' %well.NPHI.corr(well.SYN_NPHI))    \n",
    "    axis[0].legend(loc = 'upper right')\n",
    "    \n",
    "    # Density plot\n",
    "    \n",
    "    axis[1].plot(well.SYN_RHOB, well.index, linewidth='0.8', color = 'red', label = 'SYN_RHOB')\n",
    "    axis[1].plot(well.RHOB, well.index, linewidth='0.8', color = 'blue', label = 'RHOB')\n",
    "    axis[1].plot(well.MRG_RHOB, well.index, linewidth='0.8', color = 'black', label = 'MRG_RHOB', linestyle = '--')\n",
    "    axis[1].set_xlim(1.95, 2.95)\n",
    "    axis[1].set_xlabel('(g/c3)' + '\\n' + 'Correlation : %.2f' %well.RHOB.corr(well.SYN_RHOB))    \n",
    "    axis[1].legend(loc = 'upper right')\n",
    "    \n",
    "    # P-sonic plot\n",
    "    \n",
    "    axis[2].plot(well.SYN_DTC, well.index, linewidth='0.8', color = 'red', label = 'SYN_DTC')\n",
    "    axis[2].plot(well.DTC, well.index, linewidth='0.8', color = 'blue', label = 'DTC')\n",
    "    axis[2].plot(well.MRG_DTC, well.index, linewidth='0.8', color = 'black', label = 'MRG_DTC', linestyle = '--')\n",
    "    axis[2].set_xlim(40, 140)\n",
    "    axis[2].set_xlabel('(us/ft)' + '\\n' + 'Correlation : %.2f' %well.DTC.corr(well.SYN_DTC))    \n",
    "    axis[2].legend(loc = 'upper right')\n",
    "    \n",
    "    # S-sonic plot\n",
    "    \n",
    "    axis[3].plot(well.SYN_DTS, well.index, linewidth='0.8', color = 'red', label = 'SYN_DTS')\n",
    "    axis[3].plot(well.DTS, well.index, linewidth='0.8', color = 'blue', label = 'DTS')\n",
    "    axis[3].plot(well.MRG_DTS, well.index, linewidth='0.5', color = 'black', label = 'MRG_DTS', linestyle = '--')\n",
    "    axis[3].set_xlim(40, 340)\n",
    "    axis[3].set_xlabel('(us/ft)' + '\\n' + 'Correlation : %.2f' %well.DTS.corr(well.SYN_DTS))\n",
    "    axis[3].legend(loc = 'upper right')\n",
    "\n",
    "    # Bad Hole Flag plot\n",
    "\n",
    "    axis[4].plot(well['BHF'], well.index, color = 'red')\n",
    "    axis[4].fill_betweenx(well.index, 0, well['BHF'], color = 'red', label = 'Bad hole')\n",
    "    axis[4].set_xlabel('BHF')\n",
    "    axis[4].legend(loc = 'upper right')\n",
    "        \n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save files\n",
    "\n",
    "    synthetic_folder = 'LQC_Synthetic'\n",
    "    synthetic_path = os.path.join(sav_path, synthetic_folder)\n",
    "\n",
    "    if not os.path.isdir(synthetic_path):\n",
    "        os.makedirs(synthetic_path)\n",
    "\n",
    "    plt.savefig(os.path.join(synthetic_path, syn_name), dpi = 200, format = 'png')\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "# Check the synthetic\n",
    "\n",
    "for las, well in zip(lases, wells):\n",
    "    syn_name = 'LQC_' + las.well['WELL'].value + '_Synthetic' + '.png'\n",
    "    syn_compare(las, well, syn_name)"
   ]
  },
  {
   "source": [
    "## Quality Control 2 by Boxplot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for check the quality of the input data for interested zone\n",
    "\n",
    "def qc_data(wells, tops, formation, well_names):\n",
    "    \"\"\"\n",
    "    This function will create the boxplot for checking the input data.\n",
    "    wells = completed well data in pandas dataframe (Merged data with the synthetics)\n",
    "    tops = formation top data in pandas data frame which contains:\n",
    "            1. Formation names in column name \"Formations\"\n",
    "            2. Top depth boundary of the formation in column name \"Top\"\n",
    "            3. Bottom depth boundary of the formation in column name \"Bottom\"\n",
    "    formation = input the name of the formation where the data can be compared\n",
    "    well_names = list of well names in this field\n",
    "    \"\"\"\n",
    "    # Set data for specific interval\n",
    "    \n",
    "    GR_plot = []\n",
    "    RHOB_plot = []\n",
    "    NPHI_plot = []\n",
    "    DTC_plot = []\n",
    "    DTS_plot = []\n",
    "    \n",
    "    well_labels = well_names\n",
    "    \n",
    "    curve_labels = ['GR', 'RHOB', 'NPHI', 'DTC', 'DTS']\n",
    "    \n",
    "    colo = [item for sublist in [(c, c) for c in colors] for item in sublist]\n",
    "    \n",
    "    for well, top, name in zip(wells, tops, well_names):\n",
    "        \n",
    "        # Check available data for selected formation\n",
    "        \n",
    "        if formation in list(top.Formations):\n",
    "            \n",
    "            # Set interval from each well for selected formation\n",
    "            \n",
    "            top = float(top.loc[top.Formations == formation].Top)\n",
    "            bottom = float(top.loc[top.Formations == formation].Bottom)\n",
    "            \n",
    "            # Select data from each well by interval\n",
    "        \n",
    "            GR = well.GR.loc[(well.MD > top) & (well.MD < bottom)].dropna()\n",
    "            RHOB = well.MRG_RHOB.loc[(well.MD > top) & (well.MD < bottom)].dropna()\n",
    "            NPHI = well.MRG_NPHI.loc[(well.MD > top) & (well.MD < bottom)].dropna()\n",
    "            DTC = well.MRG_DTC.loc[(well.MD > top) & (well.MD < bottom)].dropna()\n",
    "            DTS = well.MRG_DTS.loc[(well.MD > top) & (well.MD < bottom)].dropna()\n",
    "        \n",
    "            GR_plot.append(gamma)\n",
    "            RHOB_plot.append(density)\n",
    "            NPHI_plot.append(neutron)\n",
    "            DTC_plot.append(p_sonic)\n",
    "            DTS_plot.append(s_sonic)\n",
    "    \n",
    "    # Create figure\n",
    "    \n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 5, figsize = (20, 4), sharey = False)\n",
    "    fig.suptitle('Box Plot Quality Control of formation ' + '\\'' + formation + '\\'', fontsize= 12, y = 1.0)\n",
    "    \n",
    "    # Plot setting for all axis\n",
    "    \n",
    "    data_plots = [GR_plot, RHOB_plot, NPHI_plot, DTC_plot, DTS_plot]\n",
    "    \n",
    "    for data, label, ax in zip(data_plots, curve_labels, axis):\n",
    "        boxes = ax.boxplot(data, labels = well_labels, meanline = True, notch = True, showfliers = False, patch_artist = True)\n",
    "        \n",
    "        # set decoration\n",
    "        for patch, color in zip(boxes['boxes'], colors): \n",
    "            patch.set_facecolor(color) \n",
    "        \n",
    "        for box_wk, box_cap, color in zip(boxes['whiskers'], boxes['caps'], colo)\n",
    "            box_wk.set(color = color, linewidth = 1.5)\n",
    "            box_cap.set(color = color, linewidth = 3)\n",
    "        \n",
    "        for median in boxes['medians']:\n",
    "            median.set(color = 'red', linewidth = 3) \n",
    "            \n",
    "        ax.set_title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('datascience': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b61f485532fd957b3b7677005c02f3d01e1ee16a8128816521630bd941ac11ac"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Data Audit & 2.Framework Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support modules\n",
    "\n",
    "import glob, os, re, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.stats as st\n",
    "import lasio # Las file reader module\n",
    "from datetime import datetime\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "source": [
    "## Import data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note = \"\"\"\n",
    "1.) This is for modeling based on isotropic homogeneous material without overpressure assumption using statistic decisions or machine learning techniques. \n",
    "\n",
    "2.) The working directory should contain the data for modeling as sub-directory. \n",
    "\n",
    "3.) All data for modeling include well logging files (.las), deviation files (.csv) and formation top (.csv) must be separated\n",
    "as sub-directory of the data directory. \n",
    "For example;\n",
    "- Working directory is \"Drive:/Working/\".\n",
    "- All data for modeling directory is \"Drive:/Working/Data/\".\n",
    "- Well logging file directory is \"Drive:/Working/Data/Well logging/\" as Sub-directory of the data directory.\n",
    "- Deviation file directory is \"Drive:/Working/Data/Deviation/\" as Sub-directory of the data directory.\n",
    "- Formation top file directory is \"Drive:/Working/Data/Formation top/\" as Sub-directory of the data directory.\n",
    "\n",
    "4.) Well name should be set as prefix for each file. Its name will cause file ordering and file pairing for each file of that well.\n",
    "For example;\n",
    "- Well name is \"Well-01\" (Noted: No underscore ('_') be contained in well name), so this name should be set as prefix followed by underscore ('_') for each modeling input file like this \"Well-01_(...Specific name for file type indication...)\"\n",
    "- Example; Well logging file name, Deviation file name and Formation top file name could be \"Well-01_las\", \"Well-01_dev\" and \"Well-01_top\" respectively.\n",
    "\n",
    "5.: Required data and file format;\n",
    "- Well logging files include all necessary curves for 1D MEM such caliper (CAL), bitsize (BS), gamma ray (GR), density (RHOB), neutron porosity (NPHI), deep resistivity (RT), shallow resistivity (MSFL), P-sonic (DTC) and S-sonic (DTS).\n",
    "- Deviation files include measured depth column named with 'MD', azimuth column named with 'AZIMUTH' and inclination or angle column named with 'ANGLE'.\n",
    "- Formation top files include formation name column named with 'Formations', top depth column named with 'Top' and bottom depth column named with 'Bottom'.\n",
    "\"\"\"\n",
    "print('Welcome to Automated 1D Mechanical Earth Modeling (Auto 1D MEM).')\n",
    "print('Please take note on this;')\n",
    "print(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data directory\n",
    "\n",
    "cwd_dir_list = ', '.join(os.listdir(os.getcwd()))\n",
    "confirm = 'no'\n",
    "\n",
    "print('According to your working directory,')\n",
    "print('%s\\nwhich one is your data directory?' %cwd_dir_list)\n",
    "\n",
    "while confirm.lower() == 'no':\n",
    "    data_folder = input('Please indicate the data directory name: ').strip()\n",
    "    data_path = os.path.join(os.getcwd(), data_folder)\n",
    "\n",
    "    if data_folder == '':\n",
    "        print('Please type the directory name!')\n",
    "        continue\n",
    "\n",
    "    elif os.path.isdir(data_path):\n",
    "        data_dir_list = ', '.join(os.listdir(data_path))\n",
    "        print('%s\\nThese sub-directories are found.' %data_dir_list)\n",
    "\n",
    "        while True:\n",
    "            print('Which one is your Well logging file directory?')\n",
    "            las_folder = input('Please indicate the well logging file directory name (.las): ').strip()\n",
    "            las_path = os.path.join(os.getcwd(), data_folder, las_folder)\n",
    "\n",
    "            if las_folder == '':\n",
    "                print('Please type the directory name!')\n",
    "                continue\n",
    "\n",
    "            elif os.path.isdir(las_path):\n",
    "                \n",
    "                while True:\n",
    "                    print('Which one is your deviation file directory?')\n",
    "                    dev_folder = input('Please indicate the deviation file directory name (.csv): ').strip()\n",
    "                    dev_path = os.path.join(os.getcwd(), data_folder, dev_folder)\n",
    "\n",
    "                    if dev_folder == '':\n",
    "                        print('Please type the directory name!')\n",
    "                        continue\n",
    "\n",
    "                    elif os.path.isdir(dev_path):\n",
    "\n",
    "                        while True:\n",
    "                            print('Which one is your formation top file directory?')\n",
    "                            top_folder = input('Please indicate the formation top file directory name (.csv): ').strip()\n",
    "                            top_path = os.path.join(os.getcwd(), data_folder, top_folder)\n",
    "\n",
    "                            if top_folder == '':\n",
    "                                print('Please type the directory name!')\n",
    "                                continue\n",
    "\n",
    "                            elif os.path.isdir(top_path):\n",
    "                                print('Gotcha!')\n",
    "                                print('Your well logging file directory is: %s.' %las_path)\n",
    "                                print('Your deviation file directory is: %s.' %dev_path)\n",
    "                                print('Your formation top file directory is: %s.' %top_path)\n",
    "\n",
    "                                while True:\n",
    "                                    confirm = input('Are these correct? [Yes/No]: ')\n",
    "\n",
    "                                    if confirm.lower() == 'yes':\n",
    "                                        break\n",
    "                                    \n",
    "                                    elif confirm.lower() == 'no':\n",
    "                                        break\n",
    "\n",
    "                                    else:\n",
    "                                        print('Please confirm again!')\n",
    "                                break\n",
    "\n",
    "                            else:\n",
    "                                print('Please try again, your directory \\'%s\\' is not found!' %top_folder)\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        print('Please try again, your directory \\'%s\\' is not found!' %dev_folder)\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                print('Please try again, your directory \\'%s\\' is not found!' %las_folder)\n",
    "\n",
    "    else:\n",
    "        print('Please try again, your directory \\'%s\\' is not found!' %data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for pairing the data and eliminating the incomplete\n",
    "\n",
    "def pairing_files(las_files_paths, dev_files_paths, top_files_paths):\n",
    "    \"\"\"\n",
    "    This function is going to pairing the data (las files, dev files and top files) and disable the incompleted one.\n",
    "    las_files_paths = list of las files with paths\n",
    "    dev_files_paths = list of deviation files with paths\n",
    "    top_files_paths = list of formation top files with paths\n",
    "    \"\"\"\n",
    "    paired_las_files_paths = []\n",
    "    paired_dev_files_paths = []\n",
    "    paired_top_files_paths = []\n",
    "\n",
    "    # pairing lAS file to deviation\n",
    "\n",
    "    for las in las_files_paths:\n",
    "        for dev in dev_files_paths:\n",
    "            for top in top_files_paths:\n",
    "\n",
    "                las_well_name = os.path.basename(las).split('_', 1)[0].lower()\n",
    "                dev_well_name = os.path.basename(dev).split('_', 1)[0].lower()\n",
    "                top_well_name = os.path.basename(top).split('_', 1)[0].lower()\n",
    "\n",
    "                if las_well_name == dev_well_name == top_well_name:\n",
    "                    paired_las_files_paths.append(las)\n",
    "                    paired_dev_files_paths.append(dev)\n",
    "                    paired_top_files_paths.append(top)\n",
    "\n",
    "    return paired_las_files_paths, paired_dev_files_paths, paired_top_files_paths\n",
    "\n",
    "# Generate file path\n",
    "\n",
    "las_files = glob.glob(os.path.join(las_path, '*.las'))\n",
    "dev_files = glob.glob(os.path.join(dev_path, '*.csv'))\n",
    "top_files = glob.glob(os.path.join(top_path, '*.csv'))\n",
    "\n",
    "# Pairing files lAS files, dev files and top files\n",
    "\n",
    "las_files, dev_files, top_files = pairing_files(las_files, dev_files, top_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lAS files, dev files and top files\n",
    "\n",
    "lases = [] # Storing well logging data\n",
    "df_lases = [] # Storing well logging data in panda data frame\n",
    "devs = [] # Storing deviation data in panda data frame\n",
    "tops = []# Storing formation top data in panda data frame\n",
    "\n",
    "for las_file, dev_file, top_file in zip(las_files, dev_files, top_files):\n",
    "\n",
    "    # Well logging data\n",
    "\n",
    "    las = lasio.read(las_file)\n",
    "    lases.append(las)\n",
    "\n",
    "    # Well logging data in panda data frame\n",
    "\n",
    "    df = las.df()\n",
    "    df = df.rename_axis('MD')\n",
    "    df_lases.append(df)\n",
    "\n",
    "    # Deviation data in panda data frame\n",
    "\n",
    "    dev = pd.read_csv(dev_file)\n",
    "    devs.append(dev)\n",
    "\n",
    "    # Fomation top data in panda data frame\n",
    "\n",
    "    top = pd.read_csv(top_file)\n",
    "    tops.append(top)\n",
    "\n",
    "# Set directory to save files\n",
    "\n",
    "sav_folder = 'LQC files'\n",
    "sav_path = os.path.join(data_path, sav_folder)\n",
    "\n",
    "if not os.path.isdir(sav_path):\n",
    "    os.makedirs(sav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucnction for random bright color list (color map)\n",
    "\n",
    "def default_colors(n_color):\n",
    "    \"\"\"\n",
    "    This function can generate the list of color code (hex code) following 25 defaults.\n",
    "    n_color = a number of color\n",
    "    \"\"\"\n",
    "    defaults = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n",
    "                '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', \n",
    "                '#808080', '#FF0000', '#00FFFF', '#800000', '#008080', \n",
    "                '#FFFF00', '#FFBF00', '#0000FF', '#808000', '#000080',\n",
    "                '#00FF00', '#FF00FF', '#008000', '#800080', '#C0C0C0']\n",
    "\n",
    "    if int(n_color) > 25:\n",
    "        colors = defaults.copy()\n",
    "        \n",
    "        while len(colors) != int(n_color):\n",
    "            scrap_code = [''.join([random.choice('0123456789ABCDEF') for i in range(2)]), '00', 'FF']\n",
    "            random.shuffle(scrap_code)\n",
    "            color = '#' + ''.join(scrap_code)\n",
    "            \n",
    "            if color not in colors:\n",
    "                colors.append(color)\n",
    "\n",
    "    else:\n",
    "        colors = defaults[0:int(n_color)]\n",
    "\n",
    "    return colors\n",
    "\n",
    "# Setup well names with color identity\n",
    "\n",
    "well_names = {}\n",
    "\n",
    "for las, color in zip(lases, default_colors(len(lases))):\n",
    "    well_names[las.well['WELL'].value] = color\n",
    "\n",
    "print('The number of wells is %d.' %len(well_names))\n",
    "print('Well names are %s.' %', '.join(well_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking the curve completion of well\n",
    "\n",
    "def check_curves(las, alias, mem_curves):\n",
    "    \"\"\"\n",
    "    This function can check the curve completion of well.\n",
    "    las = las file read by lasio\n",
    "    alias = curve alias or alterative name of the curve\n",
    "    mem_curves = necessary curve names for modeling\n",
    "    \"\"\"\n",
    "    curves = [curve.mnemonic for curve in las.curves]\n",
    "    extracted = []\n",
    "\n",
    "    for curve in curves:\n",
    "        for key, values in alias.items():\n",
    "            if (curve.lower() in [value.lower() for value in values]) & (key in mem_curves):\n",
    "                extracted.append(key)\n",
    "\n",
    "    if set(extracted) == set(mem_curves):\n",
    "        print('All necessary curves in well %s are completed' %las.well['WELL'].value)\n",
    "\n",
    "    else:\n",
    "        print('All necessary curves in well %s are incompleted.' %las.well['WELL'].value)\n",
    "        \n",
    "        if len(set(extracted).difference(set(mem_curves))) == 1:\n",
    "            print('Curve %s is missing.' %', '.join([curve for curve in set(mem_curves) - set(extracted)]))\n",
    "\n",
    "        else:\n",
    "            print('Curves %s are missing.' %', '.join([curve for curve in set(mem_curves) - set(extracted)]))\n",
    "\n",
    "# Define standard curve alias for well process\n",
    "\n",
    "alias = {\n",
    "'BS' : ['BS', 'BIT'],\n",
    "'CAL' : ['CAL', 'CALI', 'CALS', 'CLDC'],\n",
    "'GR' : ['GR', 'GRGC', 'GAM'],\n",
    "'RHOB' : ['RHOB', 'DEN', 'DENS'],\n",
    "'NPHI' : ['NPHI', 'NPOR'],\n",
    "'MSFL' : ['MSFL', 'R20T', 'RSHAL', 'RESS'],\n",
    "'ILM' : ['ILM', 'R30T', 'R40T', 'R60T', 'RESM'],\n",
    "'RT' : ['RT', 'R85T', 'LLD', 'RESD'],\n",
    "'DTC' : ['DTC', 'DT35', 'DT'],\n",
    "'DTS' : ['DTS', 'DTSM', 'DTSRM', 'DTSXX_COL', 'DTSYY_COL'],\n",
    "'PEF' : ['PEF', 'PE', 'Pe', 'PDPE']\n",
    "}\n",
    "\n",
    "# Define curve name for modeling\n",
    "\n",
    "mem_curves = ['CAL', 'BS', 'GR', 'RHOB', 'NPHI', 'RT', 'MSFL', 'DTC', 'DTS']\n",
    "\n",
    "# Define based curve names\n",
    "\n",
    "based_curves = ['MD', 'AZIMUTH', 'ANGLE', 'BHF']\n",
    "\n",
    "# Define non affected curves and affected curves for synthetic stage\n",
    "\n",
    "non_affected = ['RT', 'MSFL', 'GR_NORM']\n",
    "affected = ['NPHI', 'RHOB', 'DTC', 'DTS'] # element index refers to synthetic ordering\n",
    "\n",
    "# Check available curves\n",
    "\n",
    "print('Available curves for each well;')\n",
    "\n",
    "for las, name in zip(lases, well_names):\n",
    "    print(name, 'curves are: \\n%s' %', '.join([curve.mnemonic for curve in las.curves]))\n",
    "    check_curves(las, alias, mem_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for ordering formations from all well data\n",
    "\n",
    "def merge_sequences(seq1,seq2):\n",
    "    sm = SequenceMatcher(a = seq1, b = seq2)\n",
    "    res = []\n",
    "    \n",
    "    for (op, start1, end1, start2, end2) in sm.get_opcodes():\n",
    "        if op == 'equal' or op == 'delete':\n",
    "            \n",
    "            #This range appears in both sequences, or only in the first one.\n",
    "            \n",
    "            res += seq1[start1:end1]\n",
    "        elif op == 'insert':\n",
    "            \n",
    "            #This range appears in only the second sequence.\n",
    "            \n",
    "            res += seq2[start2:end2]\n",
    "        elif op == 'replace':\n",
    "            \n",
    "            #There are different ranges in each sequence - add both.\n",
    "            \n",
    "            res += seq1[start1:end1]\n",
    "            res += seq2[start2:end2]\n",
    "    \n",
    "    return res\n",
    "\n",
    "# Apply function to ordering all formations\n",
    "\n",
    "forms = []\n",
    "\n",
    "for top in tops:\n",
    "    if forms == []:\n",
    "        for form in top.dropna().Formations:\n",
    "            forms.append(form)\n",
    "    else:\n",
    "        forms = merge_sequences(forms, list(top.dropna().Formations))\n",
    "\n",
    "# Setup all formations with color identity\n",
    "\n",
    "all_forms = {}\n",
    "\n",
    "for form, color in zip(forms, default_colors(len(forms))):\n",
    "    all_forms[form] = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking formation names of the input\n",
    "\n",
    "def check_forms(ref_forms, input_forms):\n",
    "    \"\"\"\n",
    "    This function will check the available formation following the reference and prepare the input for the next step.\n",
    "    ref_forms = available formation will be checked based on this reference.\n",
    "    input_names = names of the formation \n",
    "    \"\"\"\n",
    "    form_names = []\n",
    "\n",
    "    for form in ref_forms:\n",
    "        if form.lower() in [name.strip().lower() for name in input_forms.split(',')]:\n",
    "            form_names.append(form)\n",
    "    \n",
    "    return form_names\n",
    "\n",
    "# Function for arranging the formation following the reference one\n",
    " \n",
    "def forms_arr(ref_forms, app_forms):\n",
    "    \"\"\"\n",
    "    This function will arrange the order of the formation in list following the reference.\n",
    "    ref_forms = formation order will be arranged following this reference.\n",
    "    app_forms = list of the formations will be applied.\n",
    "    \"\"\"\n",
    "    for form in ref_forms:\n",
    "        if form.lower() in [form.lower() for form in app_forms]:\n",
    "            app_forms.pop([form.lower() for form in app_forms].index(form.lower()))\n",
    "            app_forms.append(form)\n",
    "    \n",
    "    return app_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding the formation to the selected formation list\n",
    "\n",
    "def add_forms(selected_forms, non_selected_forms):\n",
    "    \"\"\"\n",
    "    This function can add more formation to selected formation list.\n",
    "    selected_forms = the list of selected formations that will be added more by user.\n",
    "    non_selected_forms = the list of non-selected formations\n",
    "    *check_forms function is required.\n",
    "    \"\"\"\n",
    "    print('Which one do you want to add more?')\n",
    "\n",
    "    while True:\n",
    "        select = input('[Comma can be used for multi-input]: ').strip()\n",
    "        selected_form = check_forms(non_selected_forms, select)\n",
    "\n",
    "        if select == '':\n",
    "            print('Please type formation names!')\n",
    "            continue\n",
    "\n",
    "        elif selected_form == []:\n",
    "            print('Please try again!, formation \\'%s\\' is not found.' %select)\n",
    "            continue\n",
    "\n",
    "        elif set([form.lower() for form in selected_form]).issubset(set([form.lower() for form in non_selected_forms])):\n",
    "            for form in selected_form:\n",
    "                selected_forms.append(form)\n",
    "                non_selected_forms.pop([form.lower() for form in non_selected_forms].index(form.lower()))\n",
    "            break             \n",
    "                 \n",
    "    return selected_forms, non_selected_forms\n",
    "\n",
    "# Function for removing the formation in the selected formation list\n",
    "\n",
    "def remove_forms(selected_forms, non_selected_forms):\n",
    "    \"\"\"\n",
    "    This function can remove the seleted formation.\n",
    "    selected_forms = the list of selected formations that will be removed by user.\n",
    "    non_selected_forms = the list of non-selected formations\n",
    "    *check_forms function is required.\n",
    "    \"\"\"\n",
    "    print('Which one do you want to remove?')\n",
    "\n",
    "    while True:\n",
    "        delete = input('[Comma can be used for multi-input]: ').strip()\n",
    "        del_forms = check_forms(selected_forms, delete)\n",
    "\n",
    "        if delete == '':\n",
    "            print('Please type formation names!')\n",
    "            continue\n",
    "\n",
    "        elif del_forms == []:\n",
    "            print('Please try again!, formation \\'%s\\' is not found.' %delete)\n",
    "            continue       \n",
    "\n",
    "        elif set([form.lower() for form in del_forms]).issubset(set([form.lower() for form in selected_forms])):\n",
    "            for form in del_forms:\n",
    "                selected_forms.pop([form.lower() for form in selected_forms].index(form.lower()))\n",
    "                non_selected_forms.append(form)\n",
    "\n",
    "            if len(del_forms) == 1:\n",
    "                print('Formation %s is removed' %''.join(del_forms))\n",
    "            \n",
    "            else:\n",
    "                print('Formation %s are removed' %', '.join(del_forms))\n",
    "            break\n",
    "    \n",
    "    return selected_forms, non_selected_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all selectable formations\n",
    "\n",
    "print('All formations in this field are: %s.' %', '.join(all_forms))\n",
    "\n",
    "# Define selected formations in this project to focus\n",
    "\n",
    "selected = []\n",
    "non_selected = forms.copy() # Be used only in this step\n",
    "\n",
    "while True:\n",
    "    print('Which one is your selected formation?')\n",
    "    select = input('[Comma can be used for multi-input]: ').strip()\n",
    "    selected_form = check_forms(all_forms, select)\n",
    "\n",
    "    if select == '':\n",
    "        print('Please type formation names!')\n",
    "        continue\n",
    "\n",
    "    elif selected_form == []:\n",
    "        print('Please try again!, formation \\'%s\\' is not found.' %select)\n",
    "        continue\n",
    "\n",
    "    elif set([form.lower() for form in selected_form]).issubset(set([form.lower() for form in all_forms])):\n",
    "        \n",
    "        for form in selected_form:\n",
    "            selected.append(form)\n",
    "            non_selected.pop([form.lower() for form in non_selected].index(form.lower()))\n",
    "\n",
    "        while True:\n",
    "            selected = forms_arr(all_forms, selected)\n",
    "            non_selected = forms_arr(all_forms, non_selected)        \n",
    "\n",
    "            print('Now, only formation \\'%s\\' will be your selected formations' %', '.join(selected))\n",
    "            confirm = input('Are you okay with this? [Ok/Not]: ').strip()\n",
    "            \n",
    "            if confirm.lower() == 'ok':\n",
    "                print('Got it, sir/ma\\'am!')\n",
    "                break\n",
    "            \n",
    "            elif confirm.lower() == 'not':\n",
    "                \n",
    "                while True:\n",
    "                    options = input('What do you want to do? add more or edit (remove)? [Add/Remove]: ').strip()\n",
    "\n",
    "                    if options.lower() == 'add':\n",
    "                        print('The other formation in this field are: %s.' %', '.join(non_selected))\n",
    "                        selected, non_selected = add_forms(selected, non_selected)\n",
    "                        break\n",
    "\n",
    "                    elif options.lower() == 'remove':\n",
    "                        selected, non_selected = remove_forms(selected, non_selected)\n",
    "\n",
    "                        if selected == []:\n",
    "                            print('No formation is selected!, please select formation.')\n",
    "                            print('The available formation in this field are: %s.' %', '.join(all_forms))\n",
    "                            selected, non_selected = add_forms(selected, non_selected)\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        print('Please confirm again!')\n",
    "                        continue\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                print('Please confirm again!')\n",
    "                continue\n",
    "        break\n",
    "\n",
    "# setup selected formations with color identity\n",
    "\n",
    "selected_forms = {}\n",
    "\n",
    "for form in selected:\n",
    "    if form in all_forms:\n",
    "        selected_forms[form] = all_forms[form]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define field parameters to adjust (remove air gap) the well logging by oil field type in the next step\n",
    "\n",
    "confirm = 'no'\n",
    "\n",
    "while confirm == 'no':\n",
    "\n",
    "    ground_levels = [] # for onshore field only.\n",
    "    water_levels = [] # for offshore field only.\n",
    "    RHOmls = [] # mudline density or surface density for density extrapolation\n",
    "    air_gaps = []\n",
    "\n",
    "    field_type = input('What is this oil field type [Onshore/Offshore]: ').strip()\n",
    "\n",
    "    if field_type.lower() == 'onshore':\n",
    "        for name in well_names:\n",
    "            print('Please type basic information for well %s' %name)\n",
    "\n",
    "            kb = float(input('Kelly Bushing depth (KB level to sea level) [m]: ').strip())\n",
    "            gl = float(input('Ground elevetion (ground level to sea level) [m]: ').strip())\n",
    "            RHOml = float(input('Mudline density (density at ground level) [g/c3]: ').strip())\n",
    "            ground_levels.append(gl)\n",
    "            RHOmls.append(RHOml)\n",
    "            air_gaps.append(kb - gl)\n",
    "\n",
    "        print('Please confirm these; Field type = %s' %(field_type))\n",
    "        for name, gl, RHOml, ag in zip(well_names, ground_levels, RHOmls, air_gaps):\n",
    "            print('Well %s; Ground level = %f, Mudline density = %f, Air gap = %f' %(name, gl, RHOml, ag))\n",
    "        \n",
    "        while True:\n",
    "            confirm = input('Are these correct? [Yes/No]: ').strip()\n",
    "\n",
    "            if confirm.lower() == 'yes':\n",
    "                break\n",
    "            \n",
    "            elif confirm.lower() == 'no':\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                print('Please comfirm again.')\n",
    "    \n",
    "    elif field_type.lower() == 'offshore':\n",
    "        for name, df_las, dev in zip(well_names, df_lases, devs):\n",
    "            print('Please type basic information for well %s' %name)\n",
    "\n",
    "            kb = float(input('Kelly Bushing depth (KB level to sea level) [m]: ').strip())\n",
    "            wl = float(input('Water depth (sea level to seafloor level) [m]: ').strip())\n",
    "            RHOml = float(input('Mudline density (density at sea level) [g/c3]: ').strip())\n",
    "            water_levels.append(wl)\n",
    "            RHOmls.append(RHOml)\n",
    "            air_gaps.append(kb)\n",
    "\n",
    "        print('Please confirm these; Field type = %s' %(field_type))\n",
    "        for name, wl, RHOml, ag in zip(well_names, water_levels, RHOmls, air_gaps):\n",
    "            print('Well %s; Water level = %f, Mudline density = %f, Air gap = %f' %(name, wl, RHOml, ag))\n",
    "        \n",
    "        while True:\n",
    "            confirm = input('Are these correct? [Yes/No]: ').strip()\n",
    "\n",
    "            if confirm.lower() == 'yes':\n",
    "                break\n",
    "            \n",
    "            elif confirm.lower() == 'no':\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                print('Please comfirm again.')\n",
    "    \n",
    "    else:\n",
    "        print('Please type only \\'Onshore\\' or \\'Offshore\\'')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RHOmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops[0]"
   ]
  },
  {
   "source": [
    "## Depth conversion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for TVD computation by minimum curvature method\n",
    "\n",
    "def tvd_mini_cuv(dev):\n",
    "    \"\"\"\n",
    "    TVD computation function using minimum curvature survey calculation method\n",
    "    dev = Deviation survey data in pandas data frame which contains:\n",
    "             1. Measured depth (MD) in column name \"MD\"\n",
    "             2. Azimuth direction (AZIMUTH) in column name \"AZIMUTH\"\n",
    "             3. Inclination angle (ANGLE) in column name \"ANGLE\"\n",
    "    \"\"\"\n",
    "    # setup parameters\n",
    "    \n",
    "    md = dev.MD\n",
    "    prev_md = md.shift(periods = 1, fill_value = 0)\n",
    "    diff_md = md - prev_md\n",
    "    \n",
    "    ang = dev.ANGLE\n",
    "    prev_ang = ang.shift(periods = 1, fill_value = 0)\n",
    "    diff_ang = ang - prev_ang\n",
    "    \n",
    "    azi = dev.AZIMUTH\n",
    "    prev_azi = azi.shift(periods = 1, fill_value = 0)\n",
    "    diff_azi = azi - prev_azi\n",
    "    \n",
    "    # computation\n",
    "    \n",
    "    cos_theta = np.cos(np.radians(diff_ang)) - (np.sin(np.radians(ang)) * np.sin(np.radians(prev_ang)) * (1 - np.cos(np.radians(diff_azi))))\n",
    "    theta = np.arccos(cos_theta)\n",
    "    \n",
    "    rf = ((2 / theta) * np.tan(theta/2)).fillna(0)\n",
    "    \n",
    "    dev['TVD'] = np.cumsum((diff_md / 2) * (np.cos(np.radians(ang)) + np.cos(np.radians(prev_ang))) * rf)\n",
    "    \n",
    "    return dev\n",
    "\n",
    "# Calculate TVD for all well deviations in deviation files\n",
    "\n",
    "devs = list(map(tvd_mini_cuv, devs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate function to convert MD to TVD in data with deviation survey data \n",
    "\n",
    "def tvd_inter(las, df_las, dev):\n",
    "    \"\"\"\n",
    "    MD to TVD interpolation using linear interpolation method and update las file\n",
    "    las = las file (.las) of the well data\n",
    "    df_las = las input in pandas data frame contains depth column in measured depth (MD)\n",
    "    dev = deviation survey data in pandas data frame contains depth columns in both measured depth (MD) and true vertical depth (TVD)\n",
    "    \"\"\"\n",
    "    # Merge deviation file with well data\n",
    "    \n",
    "    df_las = df_las.reset_index()\n",
    "    df_las = pd.concat([dev[['MD', 'AZIMUTH', 'ANGLE', 'TVD']], df_las]).sort_values(by = ['MD']).reset_index(drop = True)\n",
    "    \n",
    "    # Insert true vertical depth using linear interpolation\n",
    "    \n",
    "    for col in df_las[['AZIMUTH', 'ANGLE', 'TVD']].columns:\n",
    "        df_las[col] = df_las[col].interpolate(method = 'linear', limit_area = 'inside')\n",
    "        \n",
    "    # Set true vertical depth as file indices\n",
    "        \n",
    "    df_las = df_las.dropna(subset = ['TVD']).set_index('TVD')\n",
    "    df_las = df_las.drop(list(dev['TVD']))\n",
    "    \n",
    "    # Update las files\n",
    "\n",
    "    las.insert_curve(0, 'TVD', df_las.index, unit = 'm', descr = 'True Vertical Depth', value = '')\n",
    "    las.insert_curve(1, 'MD', df_las.index, unit = 'm', descr = 'Measured Depth', value = '')\n",
    "    las.insert_curve(2, 'AZIMUTH', df_las.index, unit = 'degree', descr = 'well Deviation in Azimuth', value = '')\n",
    "    las.insert_curve(3, 'ANGLE', df_las.index, unit = 'degree', descr = 'well Deviation in Angle', value = '')\n",
    "    del las.curves['DEPTH']\n",
    "\n",
    "    print('Measured depth (MD) is converted to True vertical depth (TVD) for well %s' %las.well['WELL'].value)\n",
    "    \n",
    "    return las, df_las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate function to convert MD to TVD in data with deviation survey data \n",
    "\n",
    "def tvd_inter_tops(top, dev):\n",
    "    \"\"\"\n",
    "    Formation top and bottom depth in MD to TVD interpolation using linear interpolation method and update top file\n",
    "    top = formation top file contains Formation name (Formations), Top depth (Top) and bottom depth (Bottom).\n",
    "    dev = deviation survey data in pandas data frame contains depth columns in both measured depth (MD) and true vertical depth (TVD)\n",
    "    \"\"\"\n",
    "    columns = {'Top':'Top_TVD', 'Bottom':'Bottom_TVD'}\n",
    "\n",
    "    for col in columns:\n",
    "        top['MD'] = top[col]\n",
    "        top = pd.concat([dev[['MD', 'TVD']], top]).sort_values(by = ['MD']).reset_index(drop = True)\n",
    "        top['TVD'] = top['TVD'].interpolate(method = 'linear', limit_area = 'inside')\n",
    "        top = top.dropna(subset = ['Formations']).reset_index(drop = True)\n",
    "        top = top.drop(columns = ['MD', col]).rename(columns = {'TVD':columns[col]})\n",
    "\n",
    "        cols = top.columns.tolist()\n",
    "        cols = cols[1:] + cols[:1]\n",
    "\n",
    "        top = top[cols]\n",
    "\n",
    "    top['Bottom_TVD'] = top['Bottom_TVD'].fillna(dev['TVD'].max())\n",
    "        \n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adjust true vertical depth of well logging data\n",
    "\n",
    "def remove_gap(tvd_las, dev, tvd_top, gap):\n",
    "    \"\"\"\n",
    "    This function can remove air gap from the true vertical depth (TVD) for well logging data.\n",
    "    tvd_las = las input in pandas data frame contains depth column in true vertical depth (TVD)\n",
    "    gap = air gap value (onshore = kelly bushing - ground level, offshore = kelly bushing)\n",
    "    \"\"\"\n",
    "    tvd_las = tvd_las.reset_index()\n",
    "    tvd_las['TVD'] = tvd_las['TVD'] - gap\n",
    "    tvd_las['MD'] = tvd_las['MD'] - gap\n",
    "    tvd_las = tvd_las.set_index('TVD')\n",
    "\n",
    "    dev['TVD'] = dev['TVD'] - gap\n",
    "    dev['MD'] = dev['MD'] - gap\n",
    "\n",
    "    tvd_top['Top_TVD'] = tvd_top['Top_TVD'] - gap\n",
    "    tvd_top['Bottom_TVD'] = tvd_top['Bottom_TVD'] - gap\n",
    "\n",
    "    return tvd_las, dev, top\n",
    "\n",
    "# Implement interpolation function\n",
    "\n",
    "tvd_lases = []\n",
    "tvd_tops = []\n",
    "\n",
    "for las, df_las, dev, top, gap in zip(lases, df_lases, devs, tops, air_gaps):\n",
    "    las, df_las = tvd_inter(las, df_las, dev)\n",
    "    top = tvd_inter_tops(top.copy(), dev)\n",
    "    \n",
    "    tvd_las, dev, tvd_top = remove_gap(df_las, dev, top, gap)\n",
    "    \n",
    "    tvd_lases.append(tvd_las)\n",
    "    tvd_tops.append(tvd_top)"
   ]
  },
  {
   "source": [
    "## Bad Hole Flag (BHF)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for create Bad Hole flag\n",
    "\n",
    "def create_bhf(las, tvd_las, alias):\n",
    "    \"\"\"\n",
    "    This function can compute Bad Hole Flag using confidential interval (ci) and update las file\n",
    "    las = las file (.las) of the well data\n",
    "    tvd_las = well logging data in data frame (converted true vertical depth)\n",
    "    * Caliper and bitsize data are required.\n",
    "    \"\"\"\n",
    "    # ci = confidential interval factor (0.00-1.00, default = 0.75)\n",
    "    \n",
    "    ci = 0.75 # default\n",
    "\n",
    "    for col in tvd_las.columns:\n",
    "        if col in alias['CAL']:\n",
    "            caliper = col\n",
    "        elif col in alias['BS']:\n",
    "            bitsize = col\n",
    "\n",
    "    confirm = 'not'\n",
    "\n",
    "    while not confirm.lower() == 'ok':\n",
    "        diff = tvd_las[caliper] - tvd_las[bitsize]\n",
    "        interval = st.norm.interval(alpha = ci, loc = round(np.mean(diff), 2), scale = round(np.std(diff), 2))\n",
    "        print(interval[0])\n",
    "        print(interval[1])\n",
    "\n",
    "        # tvd_las['BHF'] = (diff.dropna() > interval[0]) & (diff.dropna() < interval[1])\n",
    "        tvd_las['BHF'] = (diff.dropna() > -0.15) & (diff.dropna() < 0.15)\n",
    "        tvd_las['BHF'] = tvd_las['BHF']*1\n",
    "        tvd_las['BHF'] ^= 1\n",
    "\n",
    "        #create figure\n",
    "\n",
    "        fig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (6, 10))\n",
    "        fig.suptitle(las.well['WELL'].value, fontsize = 15, y = 1.0)\n",
    "\n",
    "        #General setting for all axis\n",
    "        \n",
    "        for ax in axis:\n",
    "            ax.set_ylim(tvd_las.index.min(), tvd_las.index.max())\n",
    "            ax.invert_yaxis()\n",
    "            ax.minorticks_on() #Scale axis\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.grid(which = 'major', linestyle = '-', linewidth = '0.5', color = 'green')\n",
    "            ax.grid(which = 'minor', linestyle = ':', linewidth = '0.5', color = 'black') \n",
    "\n",
    "        # caliper - bitsize plot\n",
    "        \n",
    "        ax11 = axis[0].twiny()\n",
    "        ax11.set_xlim(6,15)\n",
    "        ax11.plot(tvd_las[bitsize], tvd_las.index, color = 'black')\n",
    "        ax11.spines['top'].set_position(('outward',0))\n",
    "        ax11.set_xlabel('BS[in]',color = 'black')\n",
    "        ax11.tick_params(axis = 'x', colors = 'black')\n",
    "        \n",
    "        ax12 = axis[0].twiny()\n",
    "        ax12.set_xlim(6,15)\n",
    "        ax12.plot(tvd_las[caliper], tvd_las.index, color = 'grey' )\n",
    "        ax12.spines['top'].set_position(('outward',40))\n",
    "        ax12.set_xlabel('CAL[in]',color = 'grey')\n",
    "        ax12.tick_params(axis = 'x', colors = 'grey')\n",
    "\n",
    "        ax12.grid(True)\n",
    "\n",
    "        # Bad Hole Flag plot\n",
    "    \n",
    "        ax21 = axis[1].twiny()\n",
    "        ax21.plot(tvd_las['BHF'], tvd_las.index, color = 'red')\n",
    "        ax21.fill_betweenx(tvd_las.index, 0, tvd_las['BHF'], color = 'red', label = 'Bad hole')\n",
    "        ax21.spines['top'].set_position(('outward',0))\n",
    "        ax21.set_xlabel('BHF', color = 'red')\n",
    "        ax21.tick_params(axis = 'x', colors = 'red')\n",
    "        ax21.set_xticks([0, 1])\n",
    "        ax21.set_xticklabels(['GOOD', 'BAD'])\n",
    "        ax21.legend(loc = 'upper right')\n",
    "        \n",
    "        ax21.grid(True)\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        while True:\n",
    "            confirm = input('Are you ok with this created bad hole flag? [Ok/Not]: ').strip()   \n",
    "\n",
    "            if confirm.lower() == 'ok':\n",
    "                # las.append_curve('BHF', tvd_las['BHF'], unit = 'unitless', descr = 'Bad Hole Flag', value = '')\n",
    "                break\n",
    "\n",
    "            elif confirm.lower() == 'not':\n",
    "                \n",
    "                while True:\n",
    "                    ci = float(input('Please type value between 0.00 - 1.00 (0.75 is default) to adjust: ').strip())\n",
    "                \n",
    "                    if 0 < ci < 1:\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        print('Input value is out of range!')\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                print('please confirm again!')\n",
    "\n",
    "    return las, tvd_las\n",
    "\n",
    "# Create Bad Hole flag for each well\n",
    "\n",
    "for las, tvd_las in zip(lases, tvd_lases):\n",
    "    las, tvd_las = create_bhf(las, tvd_las, alias)"
   ]
  },
  {
   "source": [
    "## Quality Control 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for initial plot for first inspection\n",
    "\n",
    "def initial_inspection(las, tvd_las, inspect_name):\n",
    "    \"\"\"\n",
    "    For all curve initial inspection\n",
    "    las = las file (.las) of the well data\n",
    "    tvd_las = well logging data in data frame (converted true vertical depth)\n",
    "    inspect_name = name of saved figure\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "\n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = len(tvd_las.columns), figsize = (30,20), sharey = True)\n",
    "    fig.suptitle(las.well['WELL'].value, fontsize = 30, y = 1.0)\n",
    "    \n",
    "    units = [curve.unit for curve in las.curves]\n",
    "    units.pop(0)\n",
    "\n",
    "    # Plot setting for all axis\n",
    "\n",
    "    for ax, col, unit in zip(axis, tvd_las.columns, units):\n",
    "        ax.set_ylim(tvd_las.index.min(), tvd_las.index.max())\n",
    "        ax.invert_yaxis()\n",
    "        ax.minorticks_on() #Scale axis\n",
    "        ax.grid(which = 'major', linestyle = '-', linewidth = '0.5', color = 'green')\n",
    "        ax.grid(which = 'minor', linestyle = ':', linewidth = '0.5', color = 'black')\n",
    "        ax.set_xlabel(col + '\\n(%s)' %unit, fontsize = 15)\n",
    "\n",
    "        if (col in alias['RT']) or (col in alias['ILM']) or (col in alias['MSFL']):\n",
    "            ax.plot(tvd_las[col], tvd_las.index)\n",
    "            ax.set_xscale('log')\n",
    "\n",
    "        elif col == 'BHF':\n",
    "            ax.plot(tvd_las[col], tvd_las.index)\n",
    "            ax.fill_betweenx(tvd_las.index, 0, tvd_las[col], label = 'Bad hole')\n",
    "        \n",
    "        else:\n",
    "            ax.plot(tvd_las[col], tvd_las.index)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save files\n",
    "\n",
    "    inspect_folder = 'LQC_Inspect'\n",
    "    inspect_path = os.path.join(sav_path, inspect_folder)\n",
    "\n",
    "    if not os.path.isdir(inspect_path):\n",
    "        os.makedirs(inspect_path)\n",
    "\n",
    "    plt.savefig(os.path.join(inspect_path, inspect_name), dpi = 200, format = 'png', bbox_inches = \"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot available curves\n",
    "\n",
    "for las, tvd_las in zip(lases, tvd_lases):\n",
    "    inspect_name = 'LQC_' + las.well['WELL'].value + '_Inspect' + '.png'\n",
    "    initial_inspection(las, tvd_las, inspect_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for removing some zone.\n",
    "\n",
    "def eliminate_zone(tvd_las, alias, top_zone, bottom_zone, based_curves):\n",
    "    \"\"\"\n",
    "    This function is for data elimination within the interested zone. \n",
    "    All curves within that zone will be removed.\n",
    "    Except measured depth (MD), azimuth direction (AZIMUTH), angle or deviation (ANGLE), bitsize (BS), caliper (CAL) and bad hole flag (BHF).\n",
    "    tvd_las = well logging data in pandas data frame in TVD depth.\n",
    "    alias = curve alias or alterative name of the curve.\n",
    "    top_zone = Top TVD depth of the zone you want to remove.\n",
    "    bottom_zone = Bottom TVD depth of the zone you want to remove.\n",
    "    based_curves = list of based curve names\n",
    "    \"\"\"\n",
    "     # Set data columns for elimination\n",
    "\n",
    "    data_cols = tvd_las.columns\n",
    "    base_cols = based_curves.copy()\n",
    "    edit_cols = []\n",
    "\n",
    "    for bs in alias['BS']:\n",
    "        base_cols.append(bs)\n",
    "\n",
    "    for cal in alias['CAL']:\n",
    "        base_cols.append(cal)\n",
    "\n",
    "    for col in data_cols:\n",
    "        if col not in base_cols:\n",
    "            edit_cols.append(col)\n",
    "\n",
    "    # Eliminate the data within the assigned interval\n",
    "\n",
    "    tvd_las.loc[(tvd_las.index > float(top_zone)) & (tvd_las.index < float(bottom_zone)), edit_cols] = np.nan\n",
    "\n",
    "    return tvd_las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define starting point of the accepted data\n",
    "\n",
    "starting_points = []\n",
    "\n",
    "for las, tvd_las in zip(lases, tvd_lases):\n",
    "    depth_min = tvd_las.index.min() \n",
    "    depth_max = tvd_las.index.max()\n",
    "    print('For well %s, it has logging data between depth %.2f to %.2f.' %(las.well['WELL'].value, depth_min, depth_max))\n",
    "\n",
    "    while True:\n",
    "        starting_point = float(input('Please indicate a starting point of the accepted logging data depth.').strip())\n",
    "\n",
    "        if (starting_point >= depth_min) & (starting_point < depth_max):\n",
    "            tvd_las = eliminate_zone(tvd_las, alias, (depth_min - las.well['STEP'].value), starting_point, based_curves)\n",
    "            inspect_edited_name = 'LQC_' + las.well['WELL'].value + '_Inspect_Edited.png'\n",
    "            initial_inspection(las, tvd_las, inspect_edited_name)\n",
    "            starting_points.append(starting_point)\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            print('Your input is out of range')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define well and zone of messy data\n",
    "\n",
    "eliminated_zones = []\n",
    "\n",
    "while True:\n",
    "    print('Are there any depth interval you would like to remove or delete?')\n",
    "    answer = input('Please type Yes or No [Yes/No]: ').strip()\n",
    "\n",
    "    if answer.lower() == 'yes':\n",
    "\n",
    "        while True:\n",
    "            print('There are %d wells.' %len(well_names))\n",
    "            print('%s, Which one you want to edit?' %', '.join(well_names))\n",
    "            name = input('Please indicate the well name you want to edit: ').strip()         \n",
    "            \n",
    "            if name.lower() in [name.lower() for name in well_names]:\n",
    "                i = [name.lower() for name in well_names].index(name.lower())\n",
    "\n",
    "                while True:\n",
    "                    depth_min = tvd_lases[i].index.min()\n",
    "                    depth_max = tvd_lases[i].index.max()\n",
    "                    print('This well has logging data between depth %.2f to %.2f.' %(depth_min, depth_max))\n",
    "                    top_zone = float(input('Please indicate top depth of the zone or interval you want to edit in TVD depth: ').strip())\n",
    "\n",
    "                    if (top_zone >= depth_min) & (top_zone < depth_max):\n",
    "\n",
    "                        while True:\n",
    "                            bottom_zone = float(input('Please indicate bottom depth of the zone or interval you want to edit in TVD depth: ').strip())\n",
    "                            \n",
    "                            if (bottom_zone > top_zone) & (bottom_zone <= depth_max):\n",
    "                                \n",
    "                                while True:\n",
    "                                    print('The data of well', lases[i].well['WELL'].value, 'in TVD depth from', top_zone, 'to', bottom_zone, 'will be eliminated.')\n",
    "                                    confirm = input('Are you sure? [Yes/No]: ').strip() \n",
    "                                    \n",
    "                                    if confirm.lower() == 'yes':\n",
    "                                        tvd_lases[i] = eliminate_zone(tvd_lases[i], alias, top_zone, bottom_zone, based_curves)\n",
    "                                        inspect_edited_name = 'LQC_' + lases[i].well['WELL'].value + '_Inspect_Edited.png'\n",
    "                                        initial_inspection(lases[i], tvd_lases[i], inspect_edited_name)\n",
    "\n",
    "                                        zone = {}\n",
    "                                        zone[i] = '%f, %f' %(top_zone, bottom_zone)\n",
    "                                        eliminated_zones.append(zone)\n",
    "\n",
    "                                        print('The data has been eliminated.')\n",
    "                                        break\n",
    "                                        \n",
    "                                    elif confirm.lower() == 'no':\n",
    "                                        break\n",
    "\n",
    "                                    else:\n",
    "                                        print('Please comfirm again!')\n",
    "                                        continue\n",
    "                                break\n",
    "                                        \n",
    "                            else:\n",
    "                                print('Your bottom depth is out of range')\n",
    "                                continue\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        print('Your top depth is out of range')\n",
    "                        continue\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                print('Your well %s is not found., Please select again!' %name)\n",
    "                continue\n",
    "        continue\n",
    "\n",
    "    elif answer.lower() == 'no':\n",
    "        print('Noted, Sir/Ma\\'am!')\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        print('Please comfirm again!')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for standardizing or renaming based on alias\n",
    "\n",
    "def apply_alias(las, tvd_las, alias):\n",
    "    \"\"\"\n",
    "    This function is going to rename curves based on alias. The duplicates will be named followed by the number.\n",
    "    las = las file (.las) of the well data\n",
    "    tvd_las = well logging data in pandas data frame in TVD depth.\n",
    "    alias = curve alias or alterative name of the curve.\n",
    "    \"\"\"\n",
    "    # Get standard curve name from alias\n",
    "\n",
    "    new_cols = {}\n",
    "    seen = {}\n",
    "    dupes = []\n",
    "\n",
    "    for col in tvd_las.columns:\n",
    "        for key, values in alias.items():\n",
    "            \n",
    "            if col in values:\n",
    "                new_col = key\n",
    "\n",
    "                if key not in seen:\n",
    "                    seen[key] = 1\n",
    "                \n",
    "                else:\n",
    "                    if seen[key] == 1:\n",
    "                        dupes.append(key)\n",
    "\n",
    "                    seen[key] += 1\n",
    "                    new_col = \"{}_{}\".format(key, seen[key])\n",
    "\n",
    "                new_cols[col] = new_col\n",
    "\n",
    "    # Apply to tvd_las\n",
    "\n",
    "    tvd_las = tvd_las.rename(columns = new_cols)\n",
    "\n",
    "    # Apply to las\n",
    "\n",
    "    for key, value in new_cols.items():\n",
    "        las.curves[key].mnemonic = value\n",
    "\n",
    "    print('All curve names of well %s are standardized' %las.well['WELL'].value)\n",
    "    \n",
    "    return las, tvd_las, seen, dupes"
   ]
  },
  {
   "source": [
    "# Function for setting up the well logging data without the duplicate\n",
    "\n",
    "def setup_curve(las, well, seen, dupes, mem_curves, based_curves):\n",
    "    \"\"\"\n",
    "    This function will select and eliminate curve data for setting up modeling curve inputs.\n",
    "    las = las file (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    seen = dictionary contains the name and number of curve\n",
    "    dupes = list of duplicated curve name\n",
    "    mem_curves = necessary curve names for modeling\n",
    "    based_curves = list of based curve names\n",
    "    \"\"\"\n",
    "    # Select modeling curves\n",
    "\n",
    "    for col in well.columns:\n",
    "        if col.split('_')[0] not in (based_curves + mem_curves):\n",
    "            well = well.drop([col], axis=1)\n",
    "            del las.curves[col]\n",
    "\n",
    "    # Manage duplicate curves\n",
    "\n",
    "    new_col = {}\n",
    "    choices = []\n",
    "\n",
    "    for key, value in seen.items():\n",
    "        if (key in mem_curves) & (key in dupes):\n",
    "            print('%d curves of %s are found as duplicated curves for well %s' %(value, key, las.well['WELL'].value))\n",
    "\n",
    "            for num in range(value):\n",
    "                if num == 0:\n",
    "                    curve = las.curves[key]\n",
    "                    print('%s curve is %s' %(curve.mnemonic, curve.descr))\n",
    "                    choices.append(key)\n",
    "                else:\n",
    "                    curve = las.curves[key + '_' + str(num+1)]\n",
    "                    print('%s curve is %s' %(curve.mnemonic, curve.descr))\n",
    "                    choices.append(key + '_' + str(num+1))\n",
    "\n",
    "            while True:\n",
    "                select = input('Please select a representative curve for %s: ' %key).strip()\n",
    "\n",
    "                if select.lower() in [choice.lower() for choice in choices]:\n",
    "                    index = [choice.lower() for choice in choices].index(select.lower())\n",
    "                    new_col[choices[index]] = key\n",
    "                    choices.pop(index)\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    print('Please type again!, your curve %s is not found.' %select)\n",
    "                    continue\n",
    "            \n",
    "    # Eliminate duplicates\n",
    "\n",
    "    for col in choices:\n",
    "        well = well.drop([col], axis=1)\n",
    "        del las.curves[col]\n",
    "            \n",
    "    # Set curve name\n",
    "    \n",
    "    well = well.rename(columns = new_col)\n",
    "\n",
    "    for key, value in new_col.items():\n",
    "        las.curves[key].mnemonic = value\n",
    "\n",
    "    print('All curve data of well %s are setup already' %las.well['WELL'].value)\n",
    "\n",
    "    return las, well\n",
    "\n",
    "# Rename curve and setup curve for modeling\n",
    "\n",
    "wells = []\n",
    "\n",
    "print('The system is standardizing and setting up the curves.')\n",
    "\n",
    "for las, tvd_las in zip(lases, tvd_lases):\n",
    "    las, well, seen, dupes = apply_alias(las, tvd_las.copy(), alias)\n",
    "    las, well = setup_curve(las, well, seen, dupes, mem_curves, based_curves)\n",
    "    wells.append(well)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for controling the data by confidential interval (ci)\n",
    "\n",
    "def data_control(well):\n",
    "    \"\"\"\n",
    "    This function can limit exceeded value of the data by using confidential interval (ci)\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    \"\"\"\n",
    "    # ci = confidential interval factor (0.00-1.00, default = 0.95)\n",
    "\n",
    "    ci = 0.95\n",
    "\n",
    "    not_apply_cols = based_curves + ['BS', 'CAL']\n",
    "\n",
    "    for col in well.columns:\n",
    "        if col not in not_apply_cols:\n",
    "            interval = st.norm.interval(alpha = ci, loc = round(np.mean(well[col]), 2), scale = round(np.std(well[col]), 2))\n",
    "            well.loc[(well[col] < interval[0]) | (well[col] > interval[1]), col] = np.nan\n",
    "    \n",
    "    return well\n",
    "\n",
    "# Function for eliminating bad data using bad hole flag\n",
    "\n",
    "def bhf_control(well, affected):\n",
    "    \"\"\"\n",
    "    This function can eliminate the affected data within the bad zone including density (RHOB), neutron porosity (NPHI), P-sonic (DTC) and S-sonic (DTS).\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    affected = list of affected curve names.\n",
    "    *Bad hole flag must be created using create_bhf function\n",
    "    \"\"\"\n",
    "    # Eliminate the data based on bad hole flag\n",
    "\n",
    "    for col in affected:\n",
    "        well.loc[((well[col] * (well.BHF ^ 1)) == 0), [col]] = np.nan\n",
    "\n",
    "    return well\n",
    "\n",
    "# Apply the functions to limit and eliminate the data to be ready for synthetic stage\n",
    "\n",
    "for well in wells:\n",
    "    well = data_control(well)\n",
    "    well = bhf_control(well, affected)"
   ]
  },
  {
   "source": [
    "## Data synthetic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize gamma ray log for data synthetic\n",
    "\n",
    "def norm_gr(las, well):\n",
    "    \"\"\"\n",
    "    This function is used for min-max normalization calculation for well synthetic.\n",
    "    las = las file (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    \"\"\"\n",
    "    # Normolize gamma ray curve\n",
    "\n",
    "    well['GR_NORM'] = (well.GR - np.min(well.GR)) / (np.max(well.GR) - np.min(well.GR))\n",
    "\n",
    "    # Update las file\n",
    "\n",
    "    las.append_curve('GR_NORM', well.GR_NORM, unit = 'unitless', descr = 'Normalized Gamma Ray', value = '')\n",
    "\n",
    "    return las, well\n",
    "\n",
    "# Apply normalization\n",
    "\n",
    "for las, well in zip(lases, wells):\n",
    "    las, well = norm_gr(las, well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Checking normalized gamma ray\n",
    "\n",
    "def hist_norm_gr(wells, well_names, norm_name):\n",
    "    \"\"\"\n",
    "    This function can plot histogram of normalized gamma ray data from all well.\n",
    "    wells = list of well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    well_names = list of well name in this field\n",
    "    norm_name = name of saved figure\n",
    "    *Normalized Gamma Ray must be calculated using norm_gr function.\n",
    "    \"\"\"\n",
    "    # bins = a number of histogram bar (default = 150)\n",
    "\n",
    "    bins = 150\n",
    "\n",
    "    # Create figure\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (20,10), sharey = True)\n",
    "    fig.suptitle('Histogram of Normalized Gamma Ray', fontsize= 15, y = 0.98)\n",
    "    \n",
    "    # Plot histrogram\n",
    "    for well, name in zip(wells, well_names):\n",
    "        ax[0].hist(well.GR, bins = bins, histtype = 'step', label = name, color = well_names[name])\n",
    "        ax[0].set_xlabel('Gamma Ray (API)')\n",
    "        ax[0].set_ylabel('Frequency')\n",
    "        ax[0].set_title('Before')\n",
    "        ax[0].legend(loc='upper left')\n",
    "        \n",
    "        ax[1].hist(well.GR_NORM, bins = bins, histtype = 'step', label = name, color = well_names[name])\n",
    "        ax[1].set_xlabel('Normalized Gamma Ray')\n",
    "        ax[1].set_ylabel('Frequency')\n",
    "        ax[1].set_title('After')\n",
    "        ax[1].set_xlim([0,1])\n",
    "        ax[1].legend(loc='upper left')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save files\n",
    "\n",
    "    synthetic_folder = 'LQC_Synthetic'\n",
    "    synthetic_path = os.path.join(sav_path, synthetic_folder)\n",
    "\n",
    "    if not os.path.isdir(synthetic_path):\n",
    "        os.makedirs(synthetic_path)\n",
    "\n",
    "    plt.savefig(os.path.join(synthetic_path, norm_name), dpi = 200, format = 'png', bbox_inches = \"tight\")\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "# Check normalized gamma ray\n",
    "\n",
    "norm_name = 'LQC_Norm_GR.png'\n",
    "hist_norm_gr(wells, well_names, norm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating the data set of synthetic modeling\n",
    "\n",
    "def set_data(wells, non_affected, affected):\n",
    "    \"\"\"\n",
    "    This function can create the data set for model training and testing of synthetic function.\n",
    "    wells = list of well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    non_affected = list of non affected curve names for synthetic.\n",
    "    affected =  list of affected curve names for synthetic.\n",
    "    \"\"\"\n",
    "    # Indicate curves for data set\n",
    "\n",
    "    req_curves = non_affected.copy() + affected.copy()\n",
    "\n",
    "    # Build an empty data set and collect the data from each well\n",
    "    \n",
    "    data_set = pd.DataFrame()\n",
    "    \n",
    "    for well in wells:\n",
    "        data_set = pd.concat([data_set, well[req_curves]])\n",
    "            \n",
    "    data_set = data_set.dropna()\n",
    "            \n",
    "    return data_set\n",
    "\n",
    "# Generate the data set for synthetic stage\n",
    "\n",
    "data_set = set_data(wells, non_affected, affected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for curve synthetic (filled nan with mean)\n",
    "\n",
    "def well_syn(las, well, data_set, non_affected, affected):\n",
    "    \"\"\"\n",
    "    This function can synthesize bad data within bad zone indicated by bad hole flag.\n",
    "    This function is going to fix or synthetic the curve one at the time until all curve are fixed.\n",
    "    This function based on machine learning techniques (default = multilinear regression and random forest regression)\n",
    "    \n",
    "    RT, MSFL and GR_NORM are used as initial curves.\n",
    "    NPHI, RHOB, DTC and DTS will be synthesized respectively.\n",
    "\n",
    "    Neutron porosity synthesizing using;\n",
    "    1.) Deep resistivity (RT)\n",
    "    2.) Shallow resistivity (MSFL)\n",
    "    3.) Normalized gamma ray (GR_NORM)\n",
    "    \n",
    "    Density synthesizing using;\n",
    "    1.) Deep resistivity (RT)\n",
    "    2.) Shallow resistivity (MSFL)\n",
    "    3.) Normalized gamma ray (GR_NORM)\n",
    "    4.) Neutron porosity (NPHI)\n",
    "    \n",
    "    P-Sonic synthesizing using;\n",
    "    1.) Deep resistivity (RT)\n",
    "    2.) Shallow resistivity (MSFL)\n",
    "    3.) Normalized gamma ray (GR_NORM)\n",
    "    4.) Neutron porosity (NPHI)\n",
    "    5.) Density (RHOB)\n",
    "    \n",
    "    S-Sonic synthesizing using;\n",
    "    1.) Deep resistivity (RT)\n",
    "    2.) Shallow resistivity (MSFL)\n",
    "    3.) Normalized gamma ray (GR_NORM)\n",
    "    4.) Neutron porosity (NPHI)\n",
    "    5.) Density (RHOB)\n",
    "    6.) P-Sonic (DTC)\n",
    "    \n",
    "    las = las file (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    data_set = data set for model training and testing in pandas data frame.\n",
    "    *data_set can be created using set_data function.\n",
    "    non_affected = list of non affected curve names for synthetic.\n",
    "    affected =  list of affected curve names for synthetic. \n",
    "    *The element index of affected curve names will affect synthetic ordering.\n",
    "    \"\"\"\n",
    "    # test_size = size of test data for modeling (0.00 - 1.00, default = 0.3)\n",
    "    \n",
    "    test_size = 0.3\n",
    "\n",
    "    # n_tree = number of decision tree in random forest regression technique (default = 10)\n",
    "\n",
    "    n_tree = 10\n",
    "\n",
    "    # Set initial and synthesized data\n",
    "\n",
    "    initial = non_affected.copy()\n",
    "    syns = affected.copy()\n",
    "\n",
    "    cols = initial.copy()\n",
    "\n",
    "    print('System is synthesizing the data for well %s' %las.well['WELL'].value)\n",
    "\n",
    "    # Synthesize data one at the time\n",
    "\n",
    "    for syn in syns:\n",
    "\n",
    "        r2 = {}\n",
    "        \n",
    "        # Split the data\n",
    "        \n",
    "        input_training = data_set[initial]\n",
    "        output_traning = data_set[syn]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_training, output_traning, test_size = test_size, random_state = 0)\n",
    "\n",
    "        # Setup synthesizing input (Nan values are filled with mean column values)\n",
    "\n",
    "        syn_input = well[cols].fillna(well[cols].mean())\n",
    "        \n",
    "        # Multilinear regression modeling\n",
    "\n",
    "        mlr = LinearRegression()\n",
    "        mlr.fit(X_train, y_train)\n",
    "\n",
    "        mlr_r = mlr.score(X_test, y_test)\n",
    "        r2[mlr_r] = [mlr.predict(syn_input), 'Multilinear Regression', mlr_r]\n",
    "\n",
    "        # Random forest regression modeling\n",
    "\n",
    "        rfr = RandomForestRegressor(n_estimators = n_tree)\n",
    "        rfr.fit(X_train, y_train)\n",
    "\n",
    "        rfr_r = rfr.score(X_test, y_test)\n",
    "        r2[rfr_r] = [rfr.predict(syn_input), 'Random Forest Regression', rfr_r]\n",
    "\n",
    "        # Select the best regression\n",
    "\n",
    "        syn_output = best_r2(r2)[0]\n",
    "        print('%s is implemented for %s with R-squared value %f' %(best_r2(r2)[1], syn, best_r2(r2)[2]))\n",
    "\n",
    "        well[syn + '_SYN'] = pd.DataFrame(syn_output, index = well[cols].index)\n",
    "        \n",
    "        # Merge curve where synthetic curve replace bad hole sections, and good original curve data remains in place\n",
    "        \n",
    "        well[syn + '_MRG'] = well[syn].fillna(well[syn + '_SYN'], inplace = False)\n",
    "                \n",
    "        # Iterate new syntheric curve with new initial curves\n",
    "        \n",
    "        initial.append(syn)\n",
    "        cols.append(syn + '_SYN')\n",
    "\n",
    "    # Update las file\n",
    "\n",
    "    las.append_curve('NPHI_SYN', well['NPHI_SYN'], unit = las.curves['NPHI'].unit, descr = 'Synthetic neutron porosity', value = '')\n",
    "    las.append_curve('NPHI_MRG', well['NPHI_MRG'], unit = las.curves['NPHI'].unit, descr = 'Merged neutron porosity', value = '')\n",
    "\n",
    "    las.append_curve('RHOB_SYN', well['RHOB_SYN'], unit = las.curves['RHOB'].unit, descr = 'Synthetic density', value = '')\n",
    "    las.append_curve('RHOB_MRG', well['RHOB_MRG'], unit = las.curves['RHOB'].unit, descr = 'Merged density', value = '')\n",
    "\n",
    "    las.append_curve('DTC_SYN', well['DTC_SYN'], unit = las.curves['DTC'].unit, descr = 'Synthetic P-sonic', value = '')\n",
    "    las.append_curve('DTC_MRG', well['DTC_MRG'], unit = las.curves['DTC'].unit, descr = 'Merged P-sonic', value = '')\n",
    "\n",
    "    las.append_curve('DTS_SYN', well['DTS_SYN'], unit = las.curves['DTS'].unit, descr = 'Synthetic S-sonic', value = '')\n",
    "    las.append_curve('DTS_MRG', well['DTS_MRG'], unit = las.curves['DTS'].unit, descr = 'Merged S-sonic', value = '')\n",
    "    \n",
    "    return las, well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for selecting the best value\n",
    "\n",
    "def best_r2(r2):\n",
    "    \"\"\"\n",
    "    This function can select the best element from dictionary by the highest r-squared value.\n",
    "    r2 = r-squared value with the elements in dictionary form.\n",
    "    \"\"\"\n",
    "    max = list(r2.keys())[0]\n",
    "\n",
    "    for x in r2: \n",
    "        if x > max : \n",
    "             max = x \n",
    "      \n",
    "    return r2[max]\n",
    "\n",
    "# Synthesize the data\n",
    "\n",
    "for las, well, point in zip(lases, wells, starting_points):\n",
    "    las, well = well_syn(las, well, data_set, non_affected, affected)\n",
    "    well = eliminate_zone(well, alias, (well.index.min() - las.well['STEP'].value), point, based_curves)\n",
    "\n",
    "for zone in eliminated_zones:\n",
    "    for key, value in zone.items():\n",
    "        top = zone[key].split(', ')[0]\n",
    "        bottom = zone[key].split(', ')[1]\n",
    "        wells[key] = eliminate_zone(wells[key], alias, top, bottom, based_curves)\n",
    "\n",
    "print('Data synthesizing is done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for ploting comparision between before and after synthesizing\n",
    "\n",
    "def syn_compare(las, well, syn_name):\n",
    "    \"\"\"\n",
    "    This function shows ploting between before and after synthesizing.\n",
    "    las = las file (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    syn_name = name of saved figure\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    \n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 5, figsize = (12,20), sharey = True)\n",
    "    fig.suptitle(las.well['WELL'].value, fontsize= 20, y = 1)\n",
    "    \n",
    "    #General setting for all axis\n",
    "    \n",
    "    for ax in axis:\n",
    "        ax.set_ylim(well.index.min(), well.index.max())\n",
    "        ax.invert_yaxis()\n",
    "        ax.minorticks_on() #Scale axis\n",
    "        ax.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "        ax.grid(which='minor', linestyle=':', linewidth='0.5', color='blue') \n",
    "    \n",
    "    # Neutron porosity plot\n",
    "    \n",
    "    axis[0].plot(well.NPHI_SYN, well.index, linewidth='0.8', color = 'red', label = 'NPHI_SYN')\n",
    "    axis[0].plot(well.NPHI, well.index, linewidth='0.8', color = 'blue', label = 'NPHI')\n",
    "    axis[0].plot(well.NPHI_MRG, well.index, linewidth='0.8', color = 'black', label = 'NPHI_MRG', linestyle = '--')\n",
    "    axis[0].set_xlim(-0.15, 0.45)\n",
    "    axis[0].set_xlabel('(%s)\\nCorrelation : %.2f' %(las.curves['NPHI'].unit, well.NPHI.corr(well.NPHI_SYN)))    \n",
    "    axis[0].legend(loc = 'upper left')\n",
    "    \n",
    "    # Density plot\n",
    "    \n",
    "    axis[1].plot(well.RHOB_SYN, well.index, linewidth='0.8', color = 'red', label = 'RHOB_SYN')\n",
    "    axis[1].plot(well.RHOB, well.index, linewidth='0.8', color = 'blue', label = 'RHOB')\n",
    "    axis[1].plot(well.RHOB_MRG, well.index, linewidth='0.8', color = 'black', label = 'RHOB_MRG', linestyle = '--')\n",
    "    axis[1].set_xlim(1.95, 2.95)\n",
    "    axis[1].set_xlabel('(%s)\\nCorrelation : %.2f' %(las.curves['RHOB'].unit, well.RHOB.corr(well.RHOB_SYN)))    \n",
    "    axis[1].legend(loc = 'upper left')\n",
    "    \n",
    "    # P-sonic plot\n",
    "    \n",
    "    axis[2].plot(well.DTC_SYN, well.index, linewidth='0.8', color = 'red', label = 'DTC_SYN')\n",
    "    axis[2].plot(well.DTC, well.index, linewidth='0.8', color = 'blue', label = 'DTC')\n",
    "    axis[2].plot(well.DTC_MRG, well.index, linewidth='0.8', color = 'black', label = 'DTC_MRG', linestyle = '--')\n",
    "    axis[2].set_xlim(40, 140)\n",
    "    axis[2].set_xlabel('(%s)\\nCorrelation : %.2f' %(las.curves['DTC'].unit, well.DTC.corr(well.DTC_SYN)))    \n",
    "    axis[2].legend(loc = 'upper left')\n",
    "    \n",
    "    # S-sonic plot\n",
    "    \n",
    "    axis[3].plot(well.DTS_SYN, well.index, linewidth='0.8', color = 'red', label = 'DTS_SYN')\n",
    "    axis[3].plot(well.DTS, well.index, linewidth='0.8', color = 'blue', label = 'DTS')\n",
    "    axis[3].plot(well.DTS_MRG, well.index, linewidth='0.5', color = 'black', label = 'DTS_MRG', linestyle = '--')\n",
    "    axis[3].set_xlim(40, 340)\n",
    "    axis[3].set_xlabel('(%s)\\nCorrelation : %.2f' %(las.curves['DTS'].unit, well.DTS.corr(well.DTS_SYN)))\n",
    "    axis[3].legend(loc = 'upper left')\n",
    "\n",
    "    # Bad Hole Flag plot\n",
    "\n",
    "    axis[4].plot(well['BHF'], well.index, color = 'red')\n",
    "    axis[4].fill_betweenx(well.index, 0, well['BHF'], color = 'red', label = 'Bad hole')\n",
    "    axis[4].set_xlabel('BHF')\n",
    "    axis[4].legend(loc = 'upper left')\n",
    "        \n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save files\n",
    "\n",
    "    synthetic_folder = 'LQC_Synthetic'\n",
    "    synthetic_path = os.path.join(sav_path, synthetic_folder)\n",
    "\n",
    "    if not os.path.isdir(synthetic_path):\n",
    "        os.makedirs(synthetic_path)\n",
    "\n",
    "    plt.savefig(os.path.join(synthetic_path, syn_name), dpi = 200, format = 'png', bbox_inches = \"tight\")\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "# Check the synthetic\n",
    "\n",
    "for las, well in zip(lases, wells):\n",
    "    syn_name = 'LQC_' + las.well['WELL'].value + '_Synthetic' + '.png'\n",
    "    syn_compare(las, well, syn_name)"
   ]
  },
  {
   "source": [
    "## Quality Control 2 by Boxplot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for check the quality of the input data for interested zone\n",
    "\n",
    "def qc_data(wells, tvd_tops, formation, well_names):\n",
    "    \"\"\"\n",
    "    This function will create the boxplot for checking the input data.\n",
    "    wells = completed well data in pandas dataframe (Merged data with the synthetics)\n",
    "    tvd_top = formation top data in pandas data frame (MD depth is converted to TVD.) which contains:\n",
    "            1. Formation names in column name \"Formations\"\n",
    "            2. Top depth boundary of the formation in column name \"Top_TVD\"\n",
    "            3. Bottom depth boundary of the formation in column name \"Bottom_TVD\"\n",
    "    formation = input the name of the formation where the data can be compared\n",
    "    well_names = list of well names with color code in dictionary format\n",
    "    \"\"\"\n",
    "    # Set data for specific interval\n",
    "    \n",
    "    GR_plot = []\n",
    "    RHOB_plot = []\n",
    "    NPHI_plot = []\n",
    "    DTC_plot = []\n",
    "    DTS_plot = []\n",
    "\n",
    "    well_labels = []\n",
    "    \n",
    "    curve_labels = ['GR', 'RHOB', 'NPHI', 'DTC', 'DTS']\n",
    "    \n",
    "    for well, tvd_top, name in zip(wells, tvd_tops, well_names):\n",
    "        \n",
    "        # Check available data for selected formation\n",
    "        \n",
    "        if formation in list(tvd_top.Formations):\n",
    "            \n",
    "            # Set interval from each well for selected formation\n",
    "            \n",
    "            top_depth = float(tvd_top.loc[tvd_top.Formations == formation].Top_TVD)\n",
    "            bottom_depth = float(tvd_top.loc[tvd_top.Formations == formation].Bottom_TVD)\n",
    "\n",
    "            well_labels.append(name)\n",
    "            \n",
    "            # Select data from each well by interval\n",
    "        \n",
    "            GR = well.GR.loc[(well.index > top_depth) & (well.index < bottom_depth)].dropna()\n",
    "            RHOB = well.RHOB_MRG.loc[(well.index > top_depth) & (well.index < bottom_depth)].dropna()\n",
    "            NPHI = well.NPHI_MRG.loc[(well.index > top_depth) & (well.index < bottom_depth)].dropna()\n",
    "            DTC = well.DTC_MRG.loc[(well.index > top_depth) & (well.index < bottom_depth)].dropna()\n",
    "            DTS = well.DTS_MRG.loc[(well.index > top_depth) & (well.index < bottom_depth)].dropna()\n",
    "        \n",
    "            GR_plot.append(GR)\n",
    "            RHOB_plot.append(RHOB)\n",
    "            NPHI_plot.append(NPHI)\n",
    "            DTC_plot.append(DTC)\n",
    "            DTS_plot.append(DTS)\n",
    "\n",
    "    # Setup well colors for plotting\n",
    "\n",
    "    well_colors = []\n",
    "\n",
    "    for name in well_labels:\n",
    "        well_colors.append(well_names[name])\n",
    "\n",
    "    well_colo = [item for sublist in [(c, c) for c in well_colors] for item in sublist]\n",
    "    \n",
    "    # Create figure\n",
    "    \n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 5, figsize = (22, 5), sharey = False)\n",
    "    fig.suptitle('Box Plot Quality Control of formation ' + '\\'' + formation + '\\'', fontsize= 12, y = 1.0)\n",
    "    \n",
    "    # Plot setting for all axis\n",
    "    \n",
    "    data_plots = [GR_plot, RHOB_plot, NPHI_plot, DTC_plot, DTS_plot]\n",
    "    \n",
    "    for data, label, ax in zip(data_plots, curve_labels, axis):\n",
    "        boxes = ax.boxplot(data, labels = well_labels, meanline = True, notch = True, showfliers = False, patch_artist = True)\n",
    "        \n",
    "        # set decoration\n",
    "        for patch, color in zip(boxes['boxes'], well_colors): \n",
    "            patch.set_facecolor(color) \n",
    "        \n",
    "        for box_wk, box_cap, color in zip(boxes['whiskers'], boxes['caps'], well_colo):\n",
    "            box_wk.set(color = color, linewidth = 1.5)\n",
    "            box_cap.set(color = color, linewidth = 3)\n",
    "        \n",
    "        for median in boxes['medians']:\n",
    "            median.set(color = 'black', linewidth = 3) \n",
    "            \n",
    "        ax.set_title(label)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save files\n",
    "\n",
    "    qc_folder = 'LQC_Boxplot'\n",
    "    qc_path = os.path.join(sav_path, qc_folder)\n",
    "\n",
    "    if not os.path.isdir(qc_path):\n",
    "        os.makedirs(qc_path)\n",
    "\n",
    "    plt.savefig(os.path.join(qc_path, qc_name), dpi = 200, format = 'png', bbox_inches = \"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot boxplot for quality comtrol each selected formation\n",
    "\n",
    "for form in selected_forms:\n",
    "    qc_name = 'LQC_' + form + '.png'\n",
    "    qc_data(wells, tvd_tops, form, well_names)"
   ]
  },
  {
   "source": [
    "## Data visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for well data visualization in composite log plots\n",
    "\n",
    "def composite_logs(las, well, tvd_top, all_forms, logs_name):\n",
    "    \"\"\"\n",
    "    Plot the curves in composite logs\n",
    "    las = las file (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    tvd_top = formation top data in pandas data frame (MD depth is converted to TVD.)\n",
    "    all_forms = list of all formation names with color code in dictionary format\n",
    "    logs_name = name of saved figure.\n",
    "    \"\"\"\n",
    "    # Create figure and subplots\n",
    "    \n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 6, figsize = (15,20), sharey = True)\n",
    "    fig.suptitle(las.well['WELL'].value, fontsize= 20, y = 1.0)\n",
    "    \n",
    "    # General setting for all axis\n",
    "    \n",
    "    for ax in axis:\n",
    "        ax.set_ylim(well.index.min(), well.index.max())\n",
    "        ax.invert_yaxis()\n",
    "        ax.minorticks_on() #Scale axis\n",
    "        ax.get_xaxis().set_visible(False) \n",
    "        ax.grid(which = 'major', linestyle = '-', linewidth = '0.5', color = 'green')\n",
    "        ax.grid(which = 'minor', linestyle = ':', linewidth = '0.5', color = 'blue')\n",
    "        \n",
    "        # Plot formations\n",
    "        \n",
    "        for top, form in zip(tvd_top.Top_TVD, tvd_top.Formations):\n",
    "            if ((top >= well.index.min()) and (top <= well.index.max())):\n",
    "                ax.axhline(y = top, linewidth = 1.5, color = all_forms[form])\n",
    "                ax.text(0.1, top , form, horizontalalignment = 'center', verticalalignment = 'bottom', color = all_forms[form], fontsize = 10)\n",
    "    \n",
    "    # Azimuth and angle plots\n",
    "    \n",
    "    ax11 = axis[0].twiny()\n",
    "    ax11.plot(well.AZIMUTH, well.index, color = 'blue')\n",
    "    ax11.spines['top'].set_position(('outward', 0))\n",
    "    ax11.set_xlim(0, 360)\n",
    "    ax11.set_xlabel('AZIMUTH[%s]' %las.curves['AZIMUTH'].unit, color = 'blue')    \n",
    "    ax11.tick_params(axis = 'x', colors = 'blue')\n",
    "    ax11.set_xticks(np.arange(0, 361, 90))\n",
    "    ax11.set_xticklabels(['0', '', '180', '', '360'])\n",
    "    \n",
    "    ax11.grid(True)\n",
    "\n",
    "    ax12 = axis[0].twiny()\n",
    "    ax12.plot(well.ANGLE, well.index, color = 'red')\n",
    "    ax12.spines['top'].set_position(('outward', 40))   \n",
    "    ax12.set_xlim(0, 90)\n",
    "    ax12.set_xlabel('ANGLE[%s]' %las.curves['ANGLE'].unit, color = 'red')    \n",
    "    ax12.tick_params(axis = 'x', colors = 'red')\n",
    "    ax12.set_xticks(np.arange(0, 91, 45))\n",
    "    ax12.set_xticklabels(['0', '45', '90'])\n",
    " \n",
    "    # Gamma ray plot\n",
    "    \n",
    "    ax21 = axis[1].twiny()\n",
    "    ax21.plot(well.GR, well.index, color = 'green')\n",
    "    ax21.spines['top'].set_position(('outward', 0)) \n",
    "    ax21.set_xlim(0, 150)\n",
    "    ax21.set_xlabel('GR[%s]' %las.curves['GR'].unit, color = 'green')    \n",
    "    ax21.tick_params(axis = 'x', colors = 'green')\n",
    "    ax21.set_xticks(np.arange(0, 151, 30))\n",
    "    ax21.set_xticklabels(['0', '', '', '', '','150'])\n",
    "    \n",
    "    ax21.grid(True)\n",
    "    \n",
    "    # Resisitivity plots\n",
    "    \n",
    "    ax31 = axis[2].twiny()\n",
    "    ax31.set_xscale('log')\n",
    "    ax31.plot(well.RT, well.index, color = 'red')\n",
    "    ax31.spines['top'].set_position(('outward', 0))\n",
    "    ax31.set_xlim(0.2, 2000)\n",
    "    ax31.set_xlabel('RT[%s]' %las.curves['RT'].unit, color = 'red')    \n",
    "    ax31.tick_params(axis = 'x', colors = 'red')\n",
    "    ax31.set_xticks([0.2, 2, 20, 200, 2000])\n",
    "    ax31.set_xticklabels(['0.2', '', '', '', '2000'])\n",
    "    \n",
    "    ax31.grid(True)\n",
    "\n",
    "    ax32 = axis[2].twiny()\n",
    "    ax32.set_xscale('log')\n",
    "    ax32.plot(well.MSFL, well.index, color = 'black')\n",
    "    ax32.spines['top'].set_position(('outward', 40))   \n",
    "    ax32.set_xlim(0.2, 2000)\n",
    "    ax32.set_xlabel('MSFL[%s]' %las.curves['MSFL'].unit, color = 'black')    \n",
    "    ax32.tick_params(axis = 'x', colors = 'black')\n",
    "    ax32.set_xticks([0.2, 2, 20, 200, 2000])\n",
    "    ax32.set_xticklabels(['0.2', '', '', '', '2000'])\n",
    "    \n",
    "    # Density and neutron porosity plots\n",
    "    \n",
    "    ax41 = axis[3].twiny()\n",
    "    ax41.plot(well.RHOB_MRG, well.index, color = 'red')\n",
    "    ax41.spines['top'].set_position(('outward', 0))\n",
    "    ax41.set_xlim(1.95, 2.95)\n",
    "    ax41.set_xlabel('RHOB_MRG[%s]' %las.curves['RHOB_MRG'].unit, color = 'red')    \n",
    "    ax41.tick_params(axis = 'x', colors = 'red')\n",
    "    ax41.set_xticks(np.arange(1.95, 2.96, 0.2))\n",
    "    ax41.set_xticklabels(['1.95', '', '', '', '', '2.95'])\n",
    "    \n",
    "    ax41.grid(True)\n",
    "\n",
    "    ax42 = axis[3].twiny()\n",
    "    ax42.plot(well.NPHI_MRG, well.index, color = 'blue')\n",
    "    ax42.spines['top'].set_position(('outward', 40))   \n",
    "    ax42.set_xlim(0.45, -0.15)\n",
    "    ax42.set_xlabel('NPHI_MRG[%s]' %las.curves['NPHI_MRG'].unit, color = 'blue')    \n",
    "    ax42.tick_params(axis = 'x', colors = 'blue')\n",
    "    ax42.set_xticks(np.arange(0.45, -0.16, -0.12))\n",
    "    ax42.set_xticklabels(['0.45', '', '', '', '', '-0.15'])\n",
    "    \n",
    "    # P_Sonic and S_Sonic plots\n",
    "    \n",
    "    ax51 = axis[4].twiny()\n",
    "    ax51.plot(well.DTC_MRG, well.index, color = 'blue')\n",
    "    ax51.spines['top'].set_position(('outward', 0))\n",
    "    ax51.set_xlim(140, 40)\n",
    "    ax51.set_xlabel('DTC_MRG[%s]' %las.curves['DTC_MRG'].unit, color = 'blue')    \n",
    "    ax51.tick_params(axis = 'x', colors = 'blue')\n",
    "    ax51.set_xticks(np.arange(140, 39, -20))\n",
    "    ax51.set_xticklabels(['140', '', '', '', '', '40'])\n",
    "\n",
    "    \n",
    "    ax51.grid(True)\n",
    "\n",
    "    ax52 = axis[4].twiny()\n",
    "    ax52.plot(well.DTS_MRG, well.index, color = 'red')\n",
    "    ax52.spines['top'].set_position(('outward', 40))   \n",
    "    ax52.set_xlim(340, 40)\n",
    "    ax52.set_xlabel('DTS_MRG[%s]' %las.curves['DTS_MRG'].unit, color = 'red')    \n",
    "    ax52.tick_params(axis = 'x', colors = 'red')\n",
    "    ax52.set_xticks(np.arange(340, 39, -60))\n",
    "    ax52.set_xticklabels(['340', '', '', '', '', '40'])\n",
    "\n",
    "    \n",
    "    # Bad hole flag plots\n",
    "    \n",
    "    ax61 = axis[5].twiny()\n",
    "    ax61.plot(well.BHF, well.index, color = 'red')\n",
    "    ax61.fill_betweenx(well.index, 0, well.BHF, color = 'red', label = 'Bad hole')\n",
    "    ax61.spines['top'].set_position(('outward', 0))\n",
    "    ax61.set_xlabel('BHF', color = 'red')    \n",
    "    ax61.tick_params(axis = 'x', colors = 'red')\n",
    "    ax61.set_xticks([0, 1])\n",
    "    ax61.set_xticklabels(['GOOD', 'BAD'])\n",
    "    \n",
    "    ax61.grid(True)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save files\n",
    "\n",
    "    logs_folder = 'LQC_Composite_Logs'\n",
    "    logs_path = os.path.join(sav_path, logs_folder)\n",
    "\n",
    "    if not os.path.isdir(logs_path):\n",
    "        os.makedirs(logs_path)\n",
    "\n",
    "    plt.savefig(os.path.join(logs_path, logs_name), dpi = 200, format = 'png', bbox_inches = \"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot available curves\n",
    "\n",
    "for las, well, tvd_top in zip(lases, wells, tvd_tops):\n",
    "    logs_name = 'LQC_' + las.well['WELL'].value + '_Composite_Logs.png'\n",
    "    composite_logs(las, well, tvd_top, all_forms, logs_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for all well data visualization in composite log plots \n",
    "\n",
    "def all_composite_logs(lases, wells, tvd_tops, all_forms, all_logs_name):\n",
    "    \"\"\"\n",
    "    Plot the curves from all wells in composite logs\n",
    "    lases = las files (.las) of the well data\n",
    "    wells = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    tvd_tops = formation top data in pandas data frame (MD depth is converted to TVD.)\n",
    "    all_forms = list of all formation names with color code in dictionary format\n",
    "    all_logs_name = name of saved figure.\n",
    "    \"\"\"\n",
    "    # Create figure and subplots\n",
    "    \n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 6*len(wells), figsize = (50,20), sharey = True)\n",
    "\n",
    "    top_depth = max([well.index.min() for well in wells])\n",
    "    bottom_depth = max([well.index.max() for well in wells])\n",
    "\n",
    "    axis_groups = [list(group) for group in np.array_split(axis, len(wells))]\n",
    "\n",
    "    for las, well, tvd_top, axis_group in zip(lases, wells, tvd_tops, axis_groups):\n",
    "\n",
    "        # General setting for all axis\n",
    "        \n",
    "        for ax in axis_group:\n",
    "            ax.set_ylim(top_depth, bottom_depth)\n",
    "            ax.invert_yaxis()\n",
    "            ax.minorticks_on() #Scale axis\n",
    "            ax.get_xaxis().set_visible(False) \n",
    "            ax.grid(which = 'major', linestyle = '-', linewidth = '0.5', color = 'green')\n",
    "            ax.grid(which = 'minor', linestyle = ':', linewidth = '0.5', color = 'blue')\n",
    "            \n",
    "            # Plot formations\n",
    "\n",
    "            for top, form in zip(tvd_top.Top_TVD, tvd_top.Formations):\n",
    "                if ((top >= well.index.min()) and (top <= well.index.max())):\n",
    "                    ax.axhline(y = top, linewidth = 1.5, color = all_forms[form])\n",
    "                    ax.text(0.1, top , form, horizontalalignment = 'center', verticalalignment = 'bottom', color = all_forms[form], fontsize = 10)\n",
    "        \n",
    "        # Azimuth and angle plots\n",
    "        \n",
    "        ax11 = axis_group[0].twiny()\n",
    "        ax11.plot(well.AZIMUTH, well.index, color = 'blue')\n",
    "        ax11.spines['top'].set_position(('outward', 0))\n",
    "        ax11.set_xlim(0, 360)\n",
    "        ax11.set_xlabel('AZIMUTH[%s]' %las.curves['AZIMUTH'].unit, color = 'blue')    \n",
    "        ax11.tick_params(axis = 'x', colors = 'blue')\n",
    "        ax11.set_xticks(np.arange(0, 361, 90))\n",
    "        ax11.set_xticklabels(['0', '', '180', '', '360'])\n",
    "        \n",
    "        ax11.grid(True)\n",
    "\n",
    "        ax12 = axis_group[0].twiny()\n",
    "        ax12.plot(well.ANGLE, well.index, color = 'red')\n",
    "        ax12.spines['top'].set_position(('outward', 40))   \n",
    "        ax12.set_xlim(0, 90)\n",
    "        ax12.set_xlabel('ANGLE[%s]' %las.curves['ANGLE'].unit, color = 'red')    \n",
    "        ax12.tick_params(axis = 'x', colors = 'red')\n",
    "        ax12.set_xticks(np.arange(0, 91, 45))\n",
    "        ax12.set_xticklabels(['0', '45', '90'])\n",
    "    \n",
    "        # Gamma ray plot\n",
    "        \n",
    "        ax21 = axis_group[1].twiny()\n",
    "        ax21.plot(well.GR, well.index, color = 'green')\n",
    "        ax21.spines['top'].set_position(('outward', 0)) \n",
    "        ax21.set_xlim(0, 150)\n",
    "        ax21.set_xlabel('GR[%s]' %las.curves['GR'].unit, color = 'green')    \n",
    "        ax21.tick_params(axis = 'x', colors = 'green')\n",
    "        ax21.set_xticks(np.arange(0, 151, 30))\n",
    "        ax21.set_xticklabels(['0', '', '', '', '','150'])\n",
    "        \n",
    "        ax21.grid(True)\n",
    "        \n",
    "        # Resisitivity plots\n",
    "        \n",
    "        ax31 = axis_group[2].twiny()\n",
    "        ax31.set_xscale('log')\n",
    "        ax31.plot(well.RT, well.index, color = 'red')\n",
    "        ax31.spines['top'].set_position(('outward', 0))\n",
    "        ax31.set_xlim(0.2, 2000)\n",
    "        ax31.set_xlabel('RT[%s]' %las.curves['RT'].unit, color = 'red')    \n",
    "        ax31.tick_params(axis = 'x', colors = 'red')\n",
    "        ax31.set_xticks([0.2, 2, 20, 200, 2000])\n",
    "        ax31.set_xticklabels(['0.2', '', '', '', '2000'])\n",
    "        \n",
    "        ax31.grid(True)\n",
    "        ax31.set_title(las.well['WELL'].value, fontsize = 20, y = 1.06)\n",
    "\n",
    "        ax32 = axis_group[2].twiny()\n",
    "        ax32.set_xscale('log')\n",
    "        ax32.plot(well.MSFL, well.index, color = 'black')\n",
    "        ax32.spines['top'].set_position(('outward', 40))   \n",
    "        ax32.set_xlim(0.2, 2000)\n",
    "        ax32.set_xlabel('MSFL[%s]' %las.curves['MSFL'].unit, color = 'black')    \n",
    "        ax32.tick_params(axis = 'x', colors = 'black')\n",
    "        ax32.set_xticks([0.2, 2, 20, 200, 2000])\n",
    "        ax32.set_xticklabels(['0.2', '', '', '', '2000'])\n",
    "        \n",
    "        # Density and neutron porosity plots\n",
    "        \n",
    "        ax41 = axis_group[3].twiny()\n",
    "        ax41.plot(well.RHOB_MRG, well.index, color = 'red')\n",
    "        ax41.spines['top'].set_position(('outward', 0))\n",
    "        ax41.set_xlim(1.95, 2.95)\n",
    "        ax41.set_xlabel('RHOB_MRG[%s]' %las.curves['RHOB_MRG'].unit, color = 'red')    \n",
    "        ax41.tick_params(axis = 'x', colors = 'red')\n",
    "        ax41.set_xticks(np.arange(1.95, 2.96, 0.2))\n",
    "        ax41.set_xticklabels(['1.95', '', '', '', '', '2.95'])\n",
    "        \n",
    "        ax41.grid(True)\n",
    "\n",
    "        ax42 = axis_group[3].twiny()\n",
    "        ax42.plot(well.NPHI_MRG, well.index, color = 'blue')\n",
    "        ax42.spines['top'].set_position(('outward', 40))   \n",
    "        ax42.set_xlim(0.45, -0.15)\n",
    "        ax42.set_xlabel('NPHI_MRG[%s]' %las.curves['NPHI_MRG'].unit, color = 'blue')    \n",
    "        ax42.tick_params(axis = 'x', colors = 'blue')\n",
    "        ax42.set_xticks(np.arange(0.45, -0.16, -0.12))\n",
    "        ax42.set_xticklabels(['0.45', '', '', '', '', '-0.15'])\n",
    "        \n",
    "        # P_Sonic and S_Sonic plots\n",
    "        \n",
    "        ax51 = axis_group[4].twiny()\n",
    "        ax51.plot(well.DTC_MRG, well.index, color = 'blue')\n",
    "        ax51.spines['top'].set_position(('outward', 0))\n",
    "        ax51.set_xlim(140, 40)\n",
    "        ax51.set_xlabel('DTC_MRG[%s]' %las.curves['DTC_MRG'].unit, color = 'blue')    \n",
    "        ax51.tick_params(axis = 'x', colors = 'blue')\n",
    "        ax51.set_xticks(np.arange(140, 39, -20))\n",
    "        ax51.set_xticklabels(['140', '', '', '', '', '40'])\n",
    "\n",
    "        \n",
    "        ax51.grid(True)\n",
    "\n",
    "        ax52 = axis_group[4].twiny()\n",
    "        ax52.plot(well.DTS_MRG, well.index, color = 'red')\n",
    "        ax52.spines['top'].set_position(('outward', 40))   \n",
    "        ax52.set_xlim(340, 40)\n",
    "        ax52.set_xlabel('DTS_MRG[%s]' %las.curves['DTS_MRG'].unit, color = 'red')    \n",
    "        ax52.tick_params(axis = 'x', colors = 'red')\n",
    "        ax52.set_xticks(np.arange(340, 39, -60))\n",
    "        ax52.set_xticklabels(['340', '', '', '', '', '40'])\n",
    "\n",
    "        \n",
    "        # Bad hole flag plots\n",
    "        \n",
    "        ax61 = axis_group[5].twiny()\n",
    "        ax61.plot(well.BHF, well.index, color = 'red')\n",
    "        ax61.fill_betweenx(well.index, 0, well.BHF, color = 'red', label = 'Bad hole')\n",
    "        ax61.spines['top'].set_position(('outward', 0))\n",
    "        ax61.set_xlabel('BHF', color = 'red')    \n",
    "        ax61.tick_params(axis = 'x', colors = 'red')\n",
    "        ax61.set_xticks([0, 1])\n",
    "        ax61.set_xticklabels(['GOOD', 'BAD'])\n",
    "        \n",
    "        ax61.grid(True)\n",
    "        \n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save files\n",
    "\n",
    "    logs_folder = 'LQC_Composite_Logs'\n",
    "    logs_path = os.path.join(sav_path, logs_folder)\n",
    "\n",
    "    if not os.path.isdir(logs_path):\n",
    "        os.makedirs(logs_path)\n",
    "\n",
    "    plt.savefig(os.path.join(logs_path, all_logs_name), dpi = 200, format = 'png', bbox_inches = \"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot available curves\n",
    "\n",
    "all_logs_name = 'LQC_All_Composite_Logs.png'\n",
    "all_composite_logs(lases, wells, tvd_tops, all_forms, all_logs_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for export the data to new las file (.las) and comma-separated values file (.csv)\n",
    "\n",
    "def export_well(las, well, las_name, csv_name):\n",
    "    \"\"\"\n",
    "    This function can export data to new las file (.las) and comma-separated values file (.csv)\n",
    "    las = las files (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    \"\"\"\n",
    "    # create a new empty las file\n",
    "\n",
    "    las_file = lasio.LASFile()\n",
    "\n",
    "    # export well data (data frame format) to empty las file\n",
    "\n",
    "    las_file.set_data(well)\n",
    "\n",
    "    # update curve unit and description\n",
    "    \n",
    "    for curve_1, curve_2 in zip(las_file.curves, las.curves):\n",
    "        if curve_1.mnemonic == curve_2.mnemonic:\n",
    "            curve_1.unit = curve_2.unit\n",
    "            curve_1.descr = curve_2.descr\n",
    "\n",
    "    # update las file header\n",
    "\n",
    "    las_file.well = las.well\n",
    "\n",
    "    # update special note for las file\n",
    "    las_file.other = 'This file was written by python code in %s' %datetime.today().strftime('%m-%d-%Y %H:%M:%S')\n",
    "\n",
    "    # Save las files\n",
    "\n",
    "    LQC_las_folder = 'LQC_LAS_files'\n",
    "    LQC_las_path = os.path.join(sav_path, LQC_las_folder)\n",
    "\n",
    "    if not os.path.isdir(LQC_las_path):\n",
    "        os.makedirs(LQC_las_path)\n",
    "    \n",
    "    las_file.write(os.path.join(LQC_las_path, las_name), version = 2.0)\n",
    "\n",
    "    # setup header for csv file\n",
    "\n",
    "    headers = []\n",
    "\n",
    "    for curve in las.curves:\n",
    "        header = '%s[%s]' %(curve.mnemonic, curve.unit)\n",
    "        headers.append(header)\n",
    "\n",
    "    index = headers.pop(0)\n",
    "\n",
    "    # Save csv files\n",
    "\n",
    "    LQC_csv_folder = 'LQC_CSV_files'\n",
    "    LQC_csv_path = os.path.join(sav_path, LQC_csv_folder)\n",
    "\n",
    "    if not os.path.isdir(LQC_csv_path):\n",
    "        os.makedirs(LQC_csv_path)\n",
    "\n",
    "    well.rename_axis(index).to_csv(os.path.join(LQC_csv_path, csv_name), header = headers)\n",
    "\n",
    "# Export las and csv files\n",
    "\n",
    "for las, well in zip(lases, wells):\n",
    "    las_name = 'LQC_%s_Input.las' %las.well['WELL'].value\n",
    "    csv_name = 'LQC_%s_Input.csv' %las.well['WELL'].value\n",
    "    export_well(las, well, las_name, csv_name)\n",
    "    print('Well data of %s is exported to las and csv files already.' %las.well['WELL'].value)"
   ]
  },
  {
   "source": [
    "# 3.Mechanical Stratigraphy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for defining the lithology (sand/shale) using normalized gamma ray log\n",
    "\n",
    "def litho_gr(las, well):\n",
    "    \"\"\"\n",
    "    This function can calculate density porosity (DPHI)\n",
    "    las = las files (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    \"\"\"\n",
    "    # define sand-shale cut off from normalized gamma ray log\n",
    "\n",
    "    cutoff = 0.4\n",
    "\n",
    "    well['LITHO'] = pd.cut(well.GR_NORM, bins = [0, cutoff, 1], labels = ['SAND', 'SHALE'])\n",
    "\n",
    "    well['liplot'] = 1\n",
    "    well['liplot'].loc[well.LITHO == 'SHALE'] = 0\n",
    "    well['liplot'].loc[well.LITHO.isna()] = np.nan\n",
    "\n",
    "    #create figure\n",
    "\n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 2, figsize = (6, 15))\n",
    "    fig.suptitle(las.well['WELL'].value, fontsize = 15, y = 1.0)\n",
    "\n",
    "    # General setting for all axis\n",
    "    \n",
    "    for ax in axis:\n",
    "        ax.set_ylim(well.index.min(), well.index.max())\n",
    "        ax.invert_yaxis()\n",
    "        ax.minorticks_on() #Scale axis\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.grid(which = 'major', linestyle = '-', linewidth = '0.5', color = 'green')\n",
    "        ax.grid(which = 'minor', linestyle = ':', linewidth = '0.5', color = 'black') \n",
    "\n",
    "    # Gamma ray plot\n",
    "\n",
    "    ax1 = axis[0].twiny()\n",
    "    ax1.plot(well.GR, well.index, color = 'green')\n",
    "    ax1.spines['top'].set_position(('outward', 0)) \n",
    "    ax1.set_xlim(0, 150)\n",
    "    ax1.set_xlabel('GR[%s]' %las.curves['GR'].unit, color = 'green')    \n",
    "    ax1.tick_params(axis = 'x', colors = 'green')\n",
    "    ax1.set_xticks(np.arange(0, 151, 30))\n",
    "    ax1.set_xticklabels(['0', '', '', '', '','150'])\n",
    "\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Bad Hole Flag plot\n",
    "\n",
    "    ax2 = axis[1].twiny()\n",
    "    ax2.fill_betweenx(well.index, well.liplot, 1, color = 'SaddleBrown', capstyle = 'butt', linewidth = 0.01, label = 'SHALE')\n",
    "    ax2.fill_betweenx(well.index, 0, well.liplot, color = 'yellow', capstyle = 'butt', linewidth = 0.01, label = 'SAND')\n",
    "    ax2.spines['top'].set_position(('outward', 0))\n",
    "    ax2.set_xlim(0, 1)\n",
    "    ax2.set_xlabel('LITHOLOGY', color = 'gray')\n",
    "    ax2.tick_params(axis = 'x', colors = 'gray')\n",
    "    ax2.set_xticks([0, 1])\n",
    "    ax2.legend(loc = 'upper left')\n",
    "    \n",
    "    ax2.grid(True)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    well.drop(columns = ['liplot'], inplace = True)\n",
    "\n",
    "    # update las file\n",
    "\n",
    "    las.append_curve('LITHO', well['LITHO'], unit = 'unitless', descr = 'Lithology', value = '')\n",
    "\n",
    "    return las, well\n",
    "\n",
    "# generate sand-shale lithology\n",
    "\n",
    "for las, well in zip(lases, wells):\n",
    "    las, well = litho_gr(las, well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating volume of clay\n",
    "\n",
    "def vcl_cal(las, well):\n",
    "    \"\"\"\n",
    "    This function is for calculating the volume of clay (VCL) using two methods;\n",
    "    - Neutron-Density based on N-D crossplot for shaly sand formation excluding gas bearing formation (low density with low neutron porosity ).\n",
    "    - Linear Gamma Ray for gas bearing formation (overestimation of Vcl is possible for high uranium shale)\n",
    "    las = las files (.las) of the well data.\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    \"\"\"\n",
    "    # input parameters\n",
    "\n",
    "    RHOB = well.RHOB_MRG.dropna()\n",
    "    NPHI = well.NPHI_MRG.dropna()\n",
    "\n",
    "    # matrix and fluid parameters\n",
    "\n",
    "    RHOBm, NPHIm = 2.65, 0\n",
    "    RHOBf, NPHIf = 1.9, 0.45\n",
    "\n",
    "    # shale parameters\n",
    "\n",
    "    RHOBsh = well.RHOB_MRG.max()\n",
    "    NPHIsh = well.NPHI_MRG.max()\n",
    "\n",
    "    # volume of clay computation from Neutron-Density crossplot equation (Bhuyan and Passey, 1994)\n",
    "\n",
    "    term1 = (RHOBm-RHOBf)*(NPHI-NPHIf) - (RHOB-RHOBf)*(NPHIm-NPHIf)\n",
    "    term2 = (RHOBm-RHOBf)*(NPHIsh-NPHIf) - (RHOBsh-RHOBf)*(NPHIm-NPHIf)\n",
    "    well['VCL'] = term1/term2\n",
    "\n",
    "    # volume of clay from GR\n",
    "\n",
    "    VCLgr = well.GR_NORM\n",
    "\n",
    "    # replace volume of clay from GR in gas bearing formation (VCL < 0)\n",
    "\n",
    "    well.loc[well.VCL < 0, 'VCL'] = VCLgr\n",
    "\n",
    "    # limit exceeding volume of clay (VCL > 1) to maximum value (VCL = 1)\n",
    "\n",
    "    well.VCL = well.VCL.clip(0, 1)\n",
    "\n",
    "    # update las file\n",
    "\n",
    "    las.append_curve('VCL', well['VCL'], unit = 'V/V', descr = 'Volume of clay', value = '')\n",
    "\n",
    "    return las, well\n",
    "\n",
    "# calculate volume of clay\n",
    "\n",
    "for las, well in zip(lases, wells):\n",
    "    las, well = vcl_cal(las, well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating effective porosity \n",
    "\n",
    "def phie_cal(las, well):\n",
    "    \"\"\"\n",
    "    This function is for calculating the effective porosity (PHIE) using neutron-density conbination;\n",
    "    las = las files (.las) of the well data.\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    \"\"\"\n",
    "    # input parameters\n",
    "\n",
    "    RHOB = well.RHOB_MRG.dropna()\n",
    "    NPHI = well.NPHI_MRG.dropna()\n",
    "\n",
    "    # matrix and water parameters\n",
    "\n",
    "    RHOBm, RHOBw = 2.65, 1.0\n",
    "\n",
    "    # shale parameters\n",
    "\n",
    "    RHOBsh = well.RHOB_MRG.max()\n",
    "    NPHIsh = well.NPHI_MRG.max()\n",
    "\n",
    "    # density porosity computation with shale correction\n",
    "\n",
    "    DPHI = (RHOBm - well.RHOB_MRG) / (RHOBm - RHOBw)\n",
    "    DPHIsh = (RHOBm - RHOBsh) / (RHOBm - RHOBw)\n",
    "    DPHIshcor = DPHI - (well.VCL * DPHIsh)\n",
    "\n",
    "    # neutron porosity with shale correction\n",
    "\n",
    "    NPHIshcor = NPHI - (well.VCL * NPHIsh)\n",
    "\n",
    "    # total porosity\n",
    "\n",
    "    POR = np.sqrt(((NPHIshcor**2) + (DPHIshcor**2)) / 2)\n",
    "\n",
    "    # effective porosity\n",
    "\n",
    "    well['PHIE'] = POR * (1 - well.VCL)\n",
    "\n",
    "    # update las file\n",
    "\n",
    "    las.append_curve('PHIE', well['PHIE'], unit = 'V/V', descr = 'Effective Porosity', value = '')\n",
    "\n",
    "    return las, well\n",
    "\n",
    "# calculate volume of clay\n",
    "\n",
    "for las, well in zip(lases, wells):\n",
    "    las, well = phie_cal(las, well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for neutron-density crossplot\n",
    "\n",
    "def ndplot(las, well, ndplot_name):\n",
    "    \"\"\"\n",
    "    This function is able to built a crossplot of density and neutron porosity.\n",
    "    las = las files (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    ndplot_name = the name of saved figure\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "    gs = gridspec.GridSpec(ncols = 2, nrows = 1, width_ratios = [3, 1])\n",
    "    axis1 = fig.add_subplot(gs[0])\n",
    "    axis2 = fig.add_subplot(gs[1])\n",
    "    \n",
    "    # plot neutron porosity and density\n",
    "\n",
    "    cmap = mpl.cm.jet\n",
    "\n",
    "    im = axis1.scatter(well.NPHI_MRG, well.RHOB_MRG, c = well.GR_NORM, marker = '.', cmap = cmap)\n",
    "\n",
    "    # axis1.plot([0, 2.65], [0.45, 1.9], color = 'black')\n",
    "\n",
    "    axis1.set_xlabel('NPHI[%s]' %las.curves['NPHI_MRG'].unit)\n",
    "    axis1.set_ylabel('RHOB[%s]' %las.curves['RHOB_MRG'].unit)\n",
    "    axis1.set_xlim(-.05, .50)\n",
    "    axis1.set_ylim(3, 1.8)\n",
    "    axis1.grid(True)\n",
    "    \n",
    "    cbar = fig.colorbar(im, ax = axis1)\n",
    "    cbar.set_label('NORMALIZED GAMMA RAY')\n",
    "\n",
    "    axis1.set_title('Neutron-Density Crossplot of %s' %las.well['WELL'].value, fontsize = 15, y = 1.02)\n",
    "\n",
    "    # general setting for log plot\n",
    "\n",
    "    axis2.set_ylim(well.index.min(), well.index.max())\n",
    "    axis2.invert_yaxis()\n",
    "    axis2.minorticks_on() #Scale axis\n",
    "    axis2.get_xaxis().set_visible(False)\n",
    "    axis2.grid(which = 'major', linestyle = '-', linewidth = '0.5', color = 'lightgreen')\n",
    "    axis2.grid(which = 'minor', linestyle = ':', linewidth = '0.5', color = 'black') \n",
    "\n",
    "    # plot effective porosity, rock matrix, volume of clay\n",
    "\n",
    "    ax1 = axis2.twiny()\n",
    "    ax1.plot(well.VCL, well.index, color = 'lightgreen')\n",
    "    ax1.spines['top'].set_position(('outward', 0))\n",
    "    ax1.set_xlim(0, 1)\n",
    "    ax1.set_xlabel('VCL[%s]' %las.curves['VCL'].unit, color = 'lightgreen')   \n",
    "    ax1.tick_params(axis = 'x', colors = 'lightgreen')\n",
    "    ax1.set_xticks(np.arange(0, 1.1, 0.2))\n",
    "    ax1.set_xticklabels(['0', '', '', '', '','1'])\n",
    "\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = axis2.twiny()\n",
    "    ax2.plot(well.PHIE, well.index, color = 'lightgray')\n",
    "    ax2.spines['top'].set_position(('outward', 40))\n",
    "    ax2.set_xlim(1, 0)\n",
    "    ax2.set_xlabel('PHIE[%s]' %las.curves['PHIE'].unit, color = 'gray')   \n",
    "    ax2.tick_params(axis = 'x', colors = 'gray')\n",
    "    ax2.set_xticks(np.arange(1.0, -0.1, -0.2))\n",
    "    ax2.set_xticklabels(['1', '', '', '', '','0'])\n",
    "\n",
    "    ax2.grid(True)\n",
    "\n",
    "    ax3 = axis2.twiny()\n",
    "    ax3.set_xlim(0, 1)\n",
    "    ax3.spines['top'].set_position(('outward',0))\n",
    "    ax3.fill_betweenx(well.index, 0, well.VCL, color='lightgreen', capstyle = 'butt', linewidth = 0.5, label = 'VCLAY')\n",
    "    ax3.fill_betweenx(well.index, well.VCL, (1 - well.PHIE), color='orange', capstyle = 'butt', linewidth = 0.5, label = 'MATRIX')\n",
    "    ax3.fill_betweenx(well.index, (1 - well.PHIE), 1, color='lightgray', capstyle = 'butt', linewidth = 0.5, label = 'POROSITY')\n",
    "    ax3.set_xticks([0, 1])\n",
    "    ax3.set_xticklabels(['', ''])\n",
    "    ax3.legend(loc = 'upper left')\n",
    "\n",
    "    ax3.grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save files\n",
    "\n",
    "    ndplot_folder = 'LQC_NDplot'\n",
    "    ndplot_path = os.path.join(sav_path, ndplot_folder)\n",
    "\n",
    "    if not os.path.isdir(ndplot_path):\n",
    "        os.makedirs(ndplot_path)\n",
    "\n",
    "    plt.savefig(os.path.join(ndplot_path, ndplot_name), dpi = 200, format = 'png', bbox_inches = \"tight\")\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "# generate neutron-density crossplot\n",
    "\n",
    "for las, well in zip(lases, wells):\n",
    "    ndplot_name = 'LQC_' + las.well['WELL'].value + '_NDplot.png'\n",
    "    ndplot(las, well, ndplot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for multiwell neutron-density crossplot\n",
    "\n",
    "def multi_ndplot(lases, wells, well_names, multi_ndplot_name):\n",
    "    \"\"\"\n",
    "    This function is able to built a crossplot of density and neutron porosity.\n",
    "    las = las files (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    well_names = list of well name and its color identity\n",
    "    multi_ndplot_name = the name of saved figure\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (10,10))\n",
    "    fig.suptitle('Neutron-Density Crossplot', fontsize= 15, y = 0.98)\n",
    "    \n",
    "    # plot neutron porosity and density\n",
    "\n",
    "    cmap = mpl.cm.jet\n",
    "\n",
    "    for well, name in zip(wells, well_names):\n",
    "        NPHI_sand = well.loc[well.LITHO == 'SAND', 'NPHI_MRG']\n",
    "        RHOB_sand = well.loc[well.LITHO == 'SAND', 'RHOB_MRG']\n",
    "        NPHI_shale = well.loc[well.LITHO == 'SHALE', 'NPHI_MRG']\n",
    "        RHOB_shale = well.loc[well.LITHO == 'SHALE', 'RHOB_MRG']\n",
    "\n",
    "        ax.scatter(NPHI_sand, RHOB_sand, c = well_names[name], alpha = 0.5, marker = '.', label = 'SAND of %s' %name)\n",
    "        ax.scatter(NPHI_shale, RHOB_shale, c = well_names[name], alpha = 0.5, marker = '+', label = 'SHALE of %s' %name)\n",
    "\n",
    "    ax.set_xlabel('NPHI[%s]' %las.curves['NPHI_MRG'].unit)\n",
    "    ax.set_ylabel('RHOB[%s]' %las.curves['RHOB_MRG'].unit)\n",
    "    ax.set_xlim(-.05, .50)\n",
    "    ax.set_ylim(3, 1.8)\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc = 'upper left')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save files\n",
    "\n",
    "    ndplot_folder = 'LQC_NDplot'\n",
    "    ndplot_path = os.path.join(sav_path, ndplot_folder)\n",
    "\n",
    "    if not os.path.isdir(ndplot_path):\n",
    "        os.makedirs(ndplot_path)\n",
    "\n",
    "    plt.savefig(os.path.join(ndplot_path, multi_ndplot_name), dpi = 200, format = 'png', bbox_inches = \"tight\")\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "# generate neutron-density crossplot for all wells\n",
    "\n",
    "multi_ndplot_name = 'LQC_NDcrossplot.png'\n",
    "multi_ndplot(lases, wells, well_names, multi_ndplot_name)"
   ]
  },
  {
   "source": [
    "# 4.Overburden Stress"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for density extrapolation\n",
    "\n",
    "def den_extra_eq(X, A0, alpha):\n",
    "    \"\"\"\n",
    "    This function is density extrapolation equation.\n",
    "    RHOml = density at ground level or sea floor\n",
    "    TVD = true vertival depth (air gap was removed)\n",
    "    A0 = fitting parameter 1\n",
    "    alpha = fitting parameter 2\n",
    "    \"\"\"\n",
    "    # independent variables\n",
    "\n",
    "    RHOml, TVD = X\n",
    "\n",
    "    # density extrapolation equation\n",
    "\n",
    "    RHOex = RHOml + (A0 * (TVD**alpha))\n",
    "\n",
    "    return RHOex\n",
    "\n",
    "# Function for fitting a density extrapolation curve\n",
    "\n",
    "def den_extra(las, well, RHOml, point, surface):\n",
    "    \"\"\"\n",
    "    This function is able to fit a density extrapolation curve and create a extrapolated density.\n",
    "    las = las files (.las) of the well data\n",
    "    well = well logging data in pandas data frame in TVD depth with alias applied.\n",
    "    RHOml = density at ground level or sea floor\n",
    "    surface = position of ground or sea floor\n",
    "    \"\"\"\n",
    "    # input parameters\n",
    "\n",
    "    RHOB = well.loc[well.index > point, 'RHOB_MRG']\n",
    "\n",
    "    A = (RHOml, surface)\n",
    "    B = (RHOB.iloc[0], RHOB.index[0])\n",
    "    C = (RHOB.iloc[-1], RHOB.index[-1])\n",
    "\n",
    "    RHOBex = (A[0], B[0], C[0])\n",
    "    TVDs = (A[1], B[1], C[1])\n",
    "    RHOs = (RHOml, RHOml, RHOml)\n",
    "    X = (RHOs, TVDs)\n",
    "\n",
    "    popt, pcov = curve_fit(den_extra_eq, X, RHOBex)\n",
    "\n",
    "    well['RHOB_EX'] = RHOml + (popt[0] * (well.index**popt[1]))\n",
    "\n",
    "    # update las file\n",
    "\n",
    "    las.append_curve('RHOB_EX', well['RHOB_EX'], unit = las.curves['RHOB_MRG'].unit, descr = 'Extrapolated density', value = '')\n",
    "\n",
    "    #create figure\n",
    "\n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 1, figsize = (4, 10))\n",
    "    fig.suptitle(las.well['WELL'].value, fontsize = 15, y = 1.0)\n",
    "\n",
    "    # General setting for all axis\n",
    "    \n",
    "    axis.set_ylim(well.index.min(), well.index.max())\n",
    "    axis.invert_yaxis()\n",
    "    axis.minorticks_on() #Scale axis\n",
    "    axis.get_xaxis().set_visible(False)\n",
    "    axis.grid(which = 'major', linestyle = '-', linewidth = '0.5', color = 'green')\n",
    "    axis.grid(which = 'minor', linestyle = ':', linewidth = '0.5', color = 'black')\n",
    "\n",
    "    # Density and extrapolated density\n",
    "\n",
    "    ax1 = axis.twiny()\n",
    "    ax1.plot(well.RHOB_MRG, well.index, color = 'red')\n",
    "    ax1.spines['top'].set_position(('outward', 0))\n",
    "    ax1.set_xlim(1.95, 2.95)\n",
    "    ax1.set_xlabel('RHOB[%s]' %las.curves['RHOB_MRG'].unit, color = 'red')    \n",
    "    ax1.tick_params(axis = 'x', colors = 'red')\n",
    "    ax1.set_xticks(np.arange(1.95, 2.96, 0.2))\n",
    "    ax1.set_xticklabels(['1.95', '', '', '', '', '2.95'])\n",
    "\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = axis.twiny()\n",
    "    ax2.plot(well.RHOB_EX, well.index, color = 'black')\n",
    "    ax2.spines['top'].set_position(('outward', 40))\n",
    "    ax2.set_xlim(1.95, 2.95)\n",
    "    ax2.set_xlabel('RHOB_EX[%s]' %las.curves['RHOB_EX'].unit, color = 'black')    \n",
    "    ax2.tick_params(axis = 'x', colors = 'black')\n",
    "    ax2.set_xticks(np.arange(1.95, 2.96, 0.2))\n",
    "    ax2.set_xticklabels(['1.95', '', '', '', '', '2.95'])\n",
    "    \n",
    "    ax2.grid(True)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    return las, well\n",
    "\n",
    "# generate extrapolated density curve\n",
    "\n",
    "for las, well, RHOml, point in zip(lases, wells, RHOmls, starting_points):\n",
    "\n",
    "    surface = 0\n",
    "\n",
    "    las, well = den_extra(las, well, RHOml, point, surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lases[2].curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for las in lases:\n",
    "    del las.curves['RHOB_EX']\n",
    "\n",
    "for well in wells:\n",
    "    well.drop(columns = ['RHOB_EX'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.arange(0, 920, 0.191))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = wells[0].loc[wells[0].index > starting_points[0], 'RHOB_MRG']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TVDex = pd.DataFrame(np.arange(0, welltest.index.min(), 0.191), columns = ['TVD'])\n",
    "TVDex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "welltest.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "851.672385 - 851.669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TVD = pd.Series(test.index)\n",
    "TVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([TVDex, TVD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Merge deviation file with well data\n",
    "    \n",
    "    df_las = df_las.reset_index()\n",
    "    df_las = pd.concat([dev[['MD', 'AZIMUTH', 'ANGLE', 'TVD']], df_las]).sort_values(by = ['MD']).reset_index(drop = True)\n",
    "    \n",
    "    # Insert true vertical depth using linear interpolation\n",
    "    \n",
    "    for col in df_las[['AZIMUTH', 'ANGLE', 'TVD']].columns:\n",
    "        df_las[col] = df_las[col].interpolate(method = 'linear', limit_area = 'inside')\n",
    "        \n",
    "    # Set true vertical depth as file indices\n",
    "        \n",
    "    df_las = df_las.dropna(subset = ['TVD']).set_index('TVD')\n",
    "    df_las = df_las.drop(list(dev['TVD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "welltest = wells[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "welltest.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "welltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "welltest = pd.concat([TVDex, welltest]).sort_values(by = ['TVD']).reset_index(drop = True)\n",
    "welltest.set_index('TVD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "26921 + 4460 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('datascience': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b61f485532fd957b3b7677005c02f3d01e1ee16a8128816521630bd941ac11ac"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
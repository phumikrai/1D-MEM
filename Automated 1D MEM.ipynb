{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support modules\n",
    "\n",
    "import glob, os, re, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import lasio # Las file reader module\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "source": [
    "## Import data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Welcome to Automated 1D Mechanical Earth Modeling (Auto 1D MEM).\nPlease take note on this;\n\n1.) The working directory should contain the data for modeling as sub-directory. \n\n2.) All data for modeling include well logging files (.las), deviation files (.csv) and formation top (.csv) must be separated\nas sub-directory of the data directory. \nFor example;\n- Working directory is \"Drive:/Working/\".\n- All data for modeling directory is \"Drive:/Working/Data/\".\n- Well logging file directory is \"Drive:/Working/Data/Well logging/\" as Sub-directory of the data directory.\n- Deviation file directory is \"Drive:/Working/Data/Deviation/\" as Sub-directory of the data directory.\n- Formation top file directory is \"Drive:/Working/Data/Formation top/\" as Sub-directory of the data directory.\n\n3.) Well name should be set as prefix for each file. Its name will cause file ordering and file pairing for each file of that well.\nFor example;\n- Well name is \"Well-01\" (Noted: No underscore ('_') be contained in well name), so this name should be set as prefix followed by underscore ('_') for each modeling input file like this \"Well-01_(...Specific name for file type indication...)\"\n- Example; Well logging file name, Deviation file name and Formation top file name could be \"Well-01_las\", \"Well-01_dev\" and \"Well-01_top\" respectively.\n\n4.: Required data and file format;\n- Well logging files include all necessary curves for 1D MEM such caliper (CAL), bitsize (BS), gamma ray (GR), density (RHOB), neutron porosity (NPHI), deep resistivity (RT), shallow resistivity (MSFL), P-sonic (DTC), S-sonic (DTS) and photoelectric factor (PEF).\n- Deviation files include measured depth column named with 'MD', azimuth column named with 'AZIMUTH' and inclination or angle column named with 'ANGLE'.\n- Formation top files include formation name column named with 'Formations' and top depth column named with 'Top'.\n\n"
     ]
    }
   ],
   "source": [
    "note = \"\"\"\n",
    "1.) The working directory should contain the data for modeling as sub-directory. \n",
    "\n",
    "2.) All data for modeling include well logging files (.las), deviation files (.csv) and formation top (.csv) must be separated\n",
    "as sub-directory of the data directory. \n",
    "For example;\n",
    "- Working directory is \"Drive:/Working/\".\n",
    "- All data for modeling directory is \"Drive:/Working/Data/\".\n",
    "- Well logging file directory is \"Drive:/Working/Data/Well logging/\" as Sub-directory of the data directory.\n",
    "- Deviation file directory is \"Drive:/Working/Data/Deviation/\" as Sub-directory of the data directory.\n",
    "- Formation top file directory is \"Drive:/Working/Data/Formation top/\" as Sub-directory of the data directory.\n",
    "\n",
    "3.) Well name should be set as prefix for each file. Its name will cause file ordering and file pairing for each file of that well.\n",
    "For example;\n",
    "- Well name is \"Well-01\" (Noted: No underscore ('_') be contained in well name), so this name should be set as prefix followed by underscore ('_') for each modeling input file like this \"Well-01_(...Specific name for file type indication...)\"\n",
    "- Example; Well logging file name, Deviation file name and Formation top file name could be \"Well-01_las\", \"Well-01_dev\" and \"Well-01_top\" respectively.\n",
    "\n",
    "4.: Required data and file format;\n",
    "- Well logging files include all necessary curves for 1D MEM such caliper (CAL), bitsize (BS), gamma ray (GR), density (RHOB), neutron porosity (NPHI), deep resistivity (RT), shallow resistivity (MSFL), P-sonic (DTC), S-sonic (DTS) and photoelectric factor (PEF).\n",
    "- Deviation files include measured depth column named with 'MD', azimuth column named with 'AZIMUTH' and inclination or angle column named with 'ANGLE'.\n",
    "- Formation top files include formation name column named with 'Formations' and top depth column named with 'Top'.\n",
    "\"\"\"\n",
    "print('Welcome to Automated 1D Mechanical Earth Modeling (Auto 1D MEM).')\n",
    "print('Please take note on this;')\n",
    "print(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "According to your working directory, \n",
      ".git\n",
      ".vscode\n",
      "1. Data Audit.ipynb\n",
      "Automated 1D MEM.ipynb\n",
      "README.md\n",
      "Sirikit field\n",
      "which one is your data directory?\n",
      "\n",
      "Deviations, Formation tops, Las files, Saved files\n",
      "These sub-directories are found.\n",
      "\n",
      "\n",
      "Which one is your Well logging file directory?\n",
      "Which one is your deviation file directory?\n",
      "Which one is your formation top file directory?\n",
      "\n",
      "\n",
      "Gotcha!\n",
      "Your well logging file directory is: d:\\Github\\1D MEM\\sirikit field\\las files.\n",
      "Your deviation file directory is: d:\\Github\\1D MEM\\sirikit field\\deviations.\n",
      "Your formation top file directory is: d:\\Github\\1D MEM\\sirikit field\\formation tops.\n"
     ]
    }
   ],
   "source": [
    "# Setup data directory\n",
    "\n",
    "cwd_dir_list = '\\n'.join(os.listdir(os.getcwd()))\n",
    "\n",
    "confirm = 'no'\n",
    "\n",
    "print('According to your working directory, \\n%s\\nwhich one is your data directory?' %cwd_dir_list)\n",
    "\n",
    "while confirm.lower() == 'no':\n",
    "    data_folder = input('Please indicate the data directory name: ').strip()\n",
    "    data_path = os.path.join(os.getcwd(), data_folder)\n",
    "\n",
    "    if data_folder == '':\n",
    "        print('\\n')\n",
    "        print('Please type the directory name!')\n",
    "        continue\n",
    "\n",
    "    elif os.path.isdir(data_path):\n",
    "        data_dir_list = ', '.join(os.listdir(data_path))\n",
    "        print('\\n%s\\nThese sub-directories are found.' %data_dir_list)\n",
    "        print('\\n')\n",
    "\n",
    "        while True:\n",
    "            print('Which one is your Well logging file directory?')\n",
    "            las_folder = input('Please indicate the well logging file directory name (.las) or \\'cancel\\' to select a new data directory: ').strip()\n",
    "            las_path = os.path.join(os.getcwd(), data_folder, las_folder)\n",
    "\n",
    "            if las_folder == '':\n",
    "                print('\\n')\n",
    "                print('Please type the directory name!')\n",
    "                continue\n",
    "\n",
    "            elif las_folder.lower() == 'cancel':\n",
    "                break\n",
    "\n",
    "            elif os.path.isdir(las_path):\n",
    "                \n",
    "                while True:\n",
    "                    print('Which one is your deviation file directory?')\n",
    "                    dev_folder = input('Please indicate the deviation file directory name (.csv) or \\'cancel\\' to select a new data directory: ').strip()\n",
    "                    dev_path = os.path.join(os.getcwd(), data_folder, dev_folder)\n",
    "\n",
    "                    if dev_folder == '':\n",
    "                        print('\\n')\n",
    "                        print('Please type the directory name!')\n",
    "                        continue\n",
    "\n",
    "                    elif dev_folder.lower() == 'cancel':\n",
    "                        break\n",
    "\n",
    "                    elif os.path.isdir(dev_path):\n",
    "\n",
    "                        while True:\n",
    "                            print('Which one is your formation top file directory?')\n",
    "                            top_folder = input('Please indicate the formation top file directory name (.csv) or \\'cancel\\' to select a new data directory: ').strip()\n",
    "                            top_path = os.path.join(os.getcwd(), data_folder, top_folder)\n",
    "\n",
    "                            if top_folder == '':\n",
    "                                print('\\n')\n",
    "                                print('Please type the directory name!')\n",
    "                                continue\n",
    "\n",
    "                            elif top_folder.lower() == 'cancel':\n",
    "                                break\n",
    "\n",
    "                            elif os.path.isdir(top_path):\n",
    "                                print('\\n')\n",
    "                                print('Gotcha!')\n",
    "                                print('Your well logging file directory is: %s.' %las_path)\n",
    "                                print('Your deviation file directory is: %s.' %dev_path)\n",
    "                                print('Your formation top file directory is: %s.' %top_path)\n",
    "\n",
    "                                while True:\n",
    "                                    confirm = input('Are these correct? [Yes/No]: ')\n",
    "\n",
    "                                    if confirm.lower() == 'yes':\n",
    "                                        break\n",
    "                                    \n",
    "                                    elif confirm.lower() == 'no':\n",
    "                                        break\n",
    "\n",
    "                                    else:\n",
    "                                        print('\\n')\n",
    "                                        print('Please confirm again!')\n",
    "                                break\n",
    "\n",
    "                            else:\n",
    "                                print('\\n')\n",
    "                                print('Please try again, your directory \\'%s\\' is not found!' %top_folder)\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        print('\\n')\n",
    "                        print('Please try again, your directory \\'%s\\' is not found!' %dev_folder)\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                print('\\n')\n",
    "                print('Please try again, your directory \\'%s\\' is not found!' %las_folder)\n",
    "\n",
    "    else:\n",
    "        print('\\n')\n",
    "        print('Please try again, your directory \\'%s\\' is not found!' %data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for pairing the data and eliminating the incompleted\n",
    "\n",
    "def pairing_files(las_files_paths, dev_files_paths, top_files_paths):\n",
    "    \"\"\"\n",
    "    This function is going to pairing the data (las files, dev files and top files) and disable the incompleted one.\n",
    "    las_files_paths = list of las files with paths\n",
    "    dev_files_paths = list of deviation files with paths\n",
    "    top_files_paths = list of formation top files with paths\n",
    "    \"\"\"\n",
    "\n",
    "    paired_las_files_paths = []\n",
    "    paired_dev_files_paths = []\n",
    "    paired_top_files_paths = []\n",
    "\n",
    "    # pairing lAS file to deviation\n",
    "\n",
    "    for las in las_files_paths:\n",
    "        for dev in dev_files_paths:\n",
    "            for top in top_files_paths:\n",
    "\n",
    "                las_well_name = os.path.basename(las).split('_', 1)[0].lower()\n",
    "                dev_well_name = os.path.basename(dev).split('_', 1)[0].lower()\n",
    "                top_well_name = os.path.basename(top).split('_', 1)[0].lower()\n",
    "\n",
    "                if las_well_name == dev_well_name == top_well_name:\n",
    "                    paired_las_files_paths.append(las)\n",
    "                    paired_dev_files_paths.append(dev)\n",
    "                    paired_top_files_paths.append(top)\n",
    "\n",
    "    return paired_las_files_paths, paired_dev_files_paths, paired_top_files_paths\n",
    "\n",
    "# Generate file path\n",
    "\n",
    "las_files = glob.glob(os.path.join(las_path, '*.las'))\n",
    "dev_files = glob.glob(os.path.join(dev_path, '*.csv'))\n",
    "top_files = glob.glob(os.path.join(top_path, '*.csv'))\n",
    "\n",
    "# Pairing files lAS files, dev files and top files\n",
    "\n",
    "las_files, dev_files, top_files = pairing_files(las_files, dev_files, top_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The number of wells is 3.\nWell names are NMM-B06(BF), NMM-B07(BI), NMM-B08(BJ).\n"
     ]
    }
   ],
   "source": [
    "# Import lAS files, dev files and top files\n",
    "\n",
    "lases = [] # Storing well logging data\n",
    "df_lases = [] # Storing well logging data in panda data frame\n",
    "devs = [] # Storing deviation data in panda data frame\n",
    "tops = []# Storing formation top data in panda data frame\n",
    "\n",
    "for las_file, dev_file, top_file in zip(las_files, dev_files, top_files):\n",
    "\n",
    "    # Well logging data\n",
    "\n",
    "    las = lasio.read(las_file)\n",
    "    lases.append(las)\n",
    "\n",
    "    # Well logging data in panda data frame\n",
    "\n",
    "    df = las.df()\n",
    "    df = df.rename_axis('MD')\n",
    "    df_lases.append(df)\n",
    "\n",
    "    # Deviation data in panda data frame\n",
    "\n",
    "    dev = pd.read_csv(dev_file)\n",
    "    devs.append(dev)\n",
    "\n",
    "    # Fomation top data in panda data frame\n",
    "\n",
    "    top = pd.read_csv(top_file)\n",
    "    tops.append(top)\n",
    "\n",
    "# Set directory to save files\n",
    "\n",
    "sav_folder = 'Saved files'\n",
    "sav_path = os.path.join(os.getcwd(), data_folder, sav_folder)\n",
    "\n",
    "if not os.path.isdir(sav_path):\n",
    "    os.makedirs(sav_path)\n",
    "\n",
    "# Well names\n",
    "\n",
    "well_names = []\n",
    "\n",
    "for las in lases:\n",
    "    well_names.append(las.well['WELL'].value)\n",
    "\n",
    "print('The number of wells is %d.' %len(well_names))\n",
    "print('Well names are %s.' %', '.join(well_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n"
     ]
    }
   ],
   "source": [
    "# Function for adjust well logging and deviation depth\n",
    "\n",
    "def remove_gap(df_las, dev, gap)\n",
    "    \"\"\"\n",
    "    This function can remove air gap from the total depth (MD) for both well logging and deviation data.\n",
    "    df_las = las input in pandas data frame contains depth column in measured depth (MD)\n",
    "    dev = Deviation survey data in pandas data frame which contains:\n",
    "            1. Measured depth (MD) in column name \"MD\"\n",
    "            2. Azimuth direction (AZIMUTH) in column name \"AZIMUTH\"\n",
    "            3. Inclination angle (ANGLE) in column name \"ANGLE\"\n",
    "    gap = air gap value (onshore = kelly bushing - ground level, offshore = kelly bushing)\n",
    "    \"\"\"\n",
    "\n",
    "    # remove gap from df_las\n",
    "\n",
    "    df_las = df_las.reset_index()\n",
    "    df_las['MD'] = df_las['MD'] - gap\n",
    "    df_las = df_las.set_index('MD')\n",
    "\n",
    "    # remove gap from dev\n",
    "\n",
    "    dev['MD'] = dev['MD'] - gap\n",
    "\n",
    "    return df_las, dev\n",
    "\n",
    "# Define field parameters to adjust (remove air gap) the well logging and deviation depth by oil field type\n",
    "\n",
    "while True:\n",
    "    field_type = input('What is this oil field type [Onshore/Offshore]: ').strip()\n",
    "\n",
    "\n",
    "    if field_type.lower() == 'onshore':\n",
    "        for name, df_las, dev in zip(well_names, df_lases, devs):\n",
    "            print('Please type basic information for well %s' %name)\n",
    "\n",
    "            kb = float(input('Kelly Bushing depth [Kelly bushing to sea level]: ').strip())\n",
    "            gl = float(input('Ground level elevetion [Ground surface to sea level]: ').strip())\n",
    "            gap = kb - gl\n",
    "\n",
    "            df_las, dev = remove_gap(df_las, dev, gap)\n",
    "        break\n",
    "    \n",
    "    elif field_type.lower() == 'offshore':\n",
    "         \n",
    "         water_levels = [] # this parameter will be used in next step.\n",
    "         \n",
    "         for name, df_las, dev in zip(well_names, df_lases, devs):\n",
    "            print('Please type basic information for well %s' %name)\n",
    "\n",
    "            kb = float(input('Kelly Bushing depth: ').strip())\n",
    "            wl = float(input('Water depth [Sea level to seafloor]: ').strip())\n",
    "            water_levels.append(wl)\n",
    "            \n",
    "            gap = kb\n",
    "\n",
    "            df_las, dev = remove_gap(df_las, dev, gap)\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        print('Please type only \\'Onshore\\' or \\'Offshore\\'')\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(well_names)):\n",
    "    \n",
    "\n",
    "    while True:\n",
    "        \n",
    "        \n",
    "        kb = float(input('Kelly Bushing depth: ').strip())\n",
    "\n",
    "        if field_type.lower() == 'onshore':\n",
    "            gl = float(input('Ground level: ').strip())\n",
    "            gap = kb - gl\n",
    "            df_lases[i] = df_lases[i].reset_index()\n",
    "            df_lases['MD'] = df_lases['MD'] - gap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            break\n",
    "\n",
    "        elif field_type.lower() == 'offshore':\n",
    "            wl = float(input('Water level: ').strip()) # this parameter will be used for next step\n",
    "            gap = kb\n",
    "\n",
    "\n",
    "\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            print('Please type only \\'Onshore\\' or \\'Offshore\\'')\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           MD  AZIMUTH  ANGLE\n",
       "0     -30.000     0.00   0.00\n",
       "1      19.310   154.77   1.30\n",
       "2      46.700   151.79   3.76\n",
       "3      73.840   154.59   5.63\n",
       "4     101.345   158.64   7.63\n",
       "..        ...      ...    ...\n",
       "126  3593.690   254.72  40.43\n",
       "127  3622.730   252.73  39.90\n",
       "128  3651.260   254.43  37.57\n",
       "129  3679.890   255.13  38.02\n",
       "130  3697.000   255.50  36.70\n",
       "\n",
       "[131 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MD</th>\n      <th>AZIMUTH</th>\n      <th>ANGLE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-30.000</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19.310</td>\n      <td>154.77</td>\n      <td>1.30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46.700</td>\n      <td>151.79</td>\n      <td>3.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>73.840</td>\n      <td>154.59</td>\n      <td>5.63</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>101.345</td>\n      <td>158.64</td>\n      <td>7.63</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>3593.690</td>\n      <td>254.72</td>\n      <td>40.43</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>3622.730</td>\n      <td>252.73</td>\n      <td>39.90</td>\n    </tr>\n    <tr>\n      <th>128</th>\n      <td>3651.260</td>\n      <td>254.43</td>\n      <td>37.57</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>3679.890</td>\n      <td>255.13</td>\n      <td>38.02</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>3697.000</td>\n      <td>255.50</td>\n      <td>36.70</td>\n    </tr>\n  </tbody>\n</table>\n<p>131 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "devs[0]['MD'] = devs[0]['MD'] - 10\n",
    "devs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Height']  = df['Height'] + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Name  Height Qualification\n",
       "0     Jai    15.2           Msc\n",
       "1  Princi    17.4            MA\n",
       "2  Gaurav    15.2           Msc\n",
       "3    Anuj    15.4           Msc"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Height</th>\n      <th>Qualification</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jai</td>\n      <td>15.2</td>\n      <td>Msc</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Princi</td>\n      <td>17.4</td>\n      <td>MA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Gaurav</td>\n      <td>15.2</td>\n      <td>Msc</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Anuj</td>\n      <td>15.4</td>\n      <td>Msc</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           MD    BIT     CLDC      GRGC      DEN     NPOR         R20T  \\\n",
       "0      1035.0  12.25  8.92316  80.04658  2.25466  0.61214  20063.94531   \n",
       "1      1035.1  12.25  8.92109  81.72254  2.25267  0.63226  20062.66797   \n",
       "2      1035.2  12.25  8.91910  81.40590  2.24056  0.64422  20057.18945   \n",
       "3      1035.3  12.25  8.91740  82.10922  2.22246  0.62631  20049.98828   \n",
       "4      1035.4  12.25  8.91671  84.38502  2.20168  0.59246  20042.89453   \n",
       "...       ...    ...      ...       ...      ...      ...          ...   \n",
       "27019  3736.9    NaN      NaN       NaN      NaN      NaN          NaN   \n",
       "27020  3737.0    NaN      NaN       NaN      NaN      NaN          NaN   \n",
       "27021  3737.1    NaN      NaN       NaN      NaN      NaN          NaN   \n",
       "27022  3737.2    NaN      NaN       NaN      NaN      NaN          NaN   \n",
       "27023  3737.3    NaN      NaN       NaN      NaN      NaN          NaN   \n",
       "\n",
       "              R30T         R40T         R60T         R85T      PDPE      DT35  \\\n",
       "0      20063.94531  20063.94531  20063.94531  20063.94531  13.58376  55.72930   \n",
       "1      20062.66797  20062.66797  20062.66797  20062.66797  13.53716  55.73009   \n",
       "2      20057.18945  20057.18945  20057.18945  20057.18945  13.64950  55.75632   \n",
       "3      20049.98828  20049.98828  20049.98828  20049.98828  13.62615  55.78159   \n",
       "4      20042.89453  20042.89453  20042.89453  20042.89453  13.80907  55.85295   \n",
       "...            ...          ...          ...          ...       ...       ...   \n",
       "27019          NaN          NaN          NaN          NaN       NaN       NaN   \n",
       "27020          NaN          NaN          NaN          NaN       NaN       NaN   \n",
       "27021          NaN          NaN          NaN          NaN       NaN       NaN   \n",
       "27022          NaN          NaN          NaN          NaN       NaN       NaN   \n",
       "27023          NaN          NaN          NaN          NaN       NaN       NaN   \n",
       "\n",
       "       DTSXX_COL  DTSYY_COL  \n",
       "0            NaN        NaN  \n",
       "1            NaN        NaN  \n",
       "2            NaN        NaN  \n",
       "3            NaN        NaN  \n",
       "4            NaN        NaN  \n",
       "...          ...        ...  \n",
       "27019        NaN        NaN  \n",
       "27020        NaN        NaN  \n",
       "27021        NaN        NaN  \n",
       "27022        NaN        NaN  \n",
       "27023        NaN        NaN  \n",
       "\n",
       "[27024 rows x 15 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MD</th>\n      <th>BIT</th>\n      <th>CLDC</th>\n      <th>GRGC</th>\n      <th>DEN</th>\n      <th>NPOR</th>\n      <th>R20T</th>\n      <th>R30T</th>\n      <th>R40T</th>\n      <th>R60T</th>\n      <th>R85T</th>\n      <th>PDPE</th>\n      <th>DT35</th>\n      <th>DTSXX_COL</th>\n      <th>DTSYY_COL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1035.0</td>\n      <td>12.25</td>\n      <td>8.92316</td>\n      <td>80.04658</td>\n      <td>2.25466</td>\n      <td>0.61214</td>\n      <td>20063.94531</td>\n      <td>20063.94531</td>\n      <td>20063.94531</td>\n      <td>20063.94531</td>\n      <td>20063.94531</td>\n      <td>13.58376</td>\n      <td>55.72930</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1035.1</td>\n      <td>12.25</td>\n      <td>8.92109</td>\n      <td>81.72254</td>\n      <td>2.25267</td>\n      <td>0.63226</td>\n      <td>20062.66797</td>\n      <td>20062.66797</td>\n      <td>20062.66797</td>\n      <td>20062.66797</td>\n      <td>20062.66797</td>\n      <td>13.53716</td>\n      <td>55.73009</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1035.2</td>\n      <td>12.25</td>\n      <td>8.91910</td>\n      <td>81.40590</td>\n      <td>2.24056</td>\n      <td>0.64422</td>\n      <td>20057.18945</td>\n      <td>20057.18945</td>\n      <td>20057.18945</td>\n      <td>20057.18945</td>\n      <td>20057.18945</td>\n      <td>13.64950</td>\n      <td>55.75632</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1035.3</td>\n      <td>12.25</td>\n      <td>8.91740</td>\n      <td>82.10922</td>\n      <td>2.22246</td>\n      <td>0.62631</td>\n      <td>20049.98828</td>\n      <td>20049.98828</td>\n      <td>20049.98828</td>\n      <td>20049.98828</td>\n      <td>20049.98828</td>\n      <td>13.62615</td>\n      <td>55.78159</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1035.4</td>\n      <td>12.25</td>\n      <td>8.91671</td>\n      <td>84.38502</td>\n      <td>2.20168</td>\n      <td>0.59246</td>\n      <td>20042.89453</td>\n      <td>20042.89453</td>\n      <td>20042.89453</td>\n      <td>20042.89453</td>\n      <td>20042.89453</td>\n      <td>13.80907</td>\n      <td>55.85295</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27019</th>\n      <td>3736.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27020</th>\n      <td>3737.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27021</th>\n      <td>3737.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27022</th>\n      <td>3737.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27023</th>\n      <td>3737.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>27024 rows × 15 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "las = df_lases[0].reset_index()\n",
    "las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "las['MD'] = las['MD'] - 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "las = las.set_index('MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          BIT     CLDC      GRGC      DEN     NPOR         R20T         R30T  \\\n",
       "MD                                                                             \n",
       "535.0   12.25  8.92316  80.04658  2.25466  0.61214  20063.94531  20063.94531   \n",
       "535.1   12.25  8.92109  81.72254  2.25267  0.63226  20062.66797  20062.66797   \n",
       "535.2   12.25  8.91910  81.40590  2.24056  0.64422  20057.18945  20057.18945   \n",
       "535.3   12.25  8.91740  82.10922  2.22246  0.62631  20049.98828  20049.98828   \n",
       "535.4   12.25  8.91671  84.38502  2.20168  0.59246  20042.89453  20042.89453   \n",
       "...       ...      ...       ...      ...      ...          ...          ...   \n",
       "3236.9    NaN      NaN       NaN      NaN      NaN          NaN          NaN   \n",
       "3237.0    NaN      NaN       NaN      NaN      NaN          NaN          NaN   \n",
       "3237.1    NaN      NaN       NaN      NaN      NaN          NaN          NaN   \n",
       "3237.2    NaN      NaN       NaN      NaN      NaN          NaN          NaN   \n",
       "3237.3    NaN      NaN       NaN      NaN      NaN          NaN          NaN   \n",
       "\n",
       "               R40T         R60T         R85T      PDPE      DT35  DTSXX_COL  \\\n",
       "MD                                                                             \n",
       "535.0   20063.94531  20063.94531  20063.94531  13.58376  55.72930        NaN   \n",
       "535.1   20062.66797  20062.66797  20062.66797  13.53716  55.73009        NaN   \n",
       "535.2   20057.18945  20057.18945  20057.18945  13.64950  55.75632        NaN   \n",
       "535.3   20049.98828  20049.98828  20049.98828  13.62615  55.78159        NaN   \n",
       "535.4   20042.89453  20042.89453  20042.89453  13.80907  55.85295        NaN   \n",
       "...             ...          ...          ...       ...       ...        ...   \n",
       "3236.9          NaN          NaN          NaN       NaN       NaN        NaN   \n",
       "3237.0          NaN          NaN          NaN       NaN       NaN        NaN   \n",
       "3237.1          NaN          NaN          NaN       NaN       NaN        NaN   \n",
       "3237.2          NaN          NaN          NaN       NaN       NaN        NaN   \n",
       "3237.3          NaN          NaN          NaN       NaN       NaN        NaN   \n",
       "\n",
       "        DTSYY_COL  \n",
       "MD                 \n",
       "535.0         NaN  \n",
       "535.1         NaN  \n",
       "535.2         NaN  \n",
       "535.3         NaN  \n",
       "535.4         NaN  \n",
       "...           ...  \n",
       "3236.9        NaN  \n",
       "3237.0        NaN  \n",
       "3237.1        NaN  \n",
       "3237.2        NaN  \n",
       "3237.3        NaN  \n",
       "\n",
       "[27024 rows x 14 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BIT</th>\n      <th>CLDC</th>\n      <th>GRGC</th>\n      <th>DEN</th>\n      <th>NPOR</th>\n      <th>R20T</th>\n      <th>R30T</th>\n      <th>R40T</th>\n      <th>R60T</th>\n      <th>R85T</th>\n      <th>PDPE</th>\n      <th>DT35</th>\n      <th>DTSXX_COL</th>\n      <th>DTSYY_COL</th>\n    </tr>\n    <tr>\n      <th>MD</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>535.0</th>\n      <td>12.25</td>\n      <td>8.92316</td>\n      <td>80.04658</td>\n      <td>2.25466</td>\n      <td>0.61214</td>\n      <td>20063.94531</td>\n      <td>20063.94531</td>\n      <td>20063.94531</td>\n      <td>20063.94531</td>\n      <td>20063.94531</td>\n      <td>13.58376</td>\n      <td>55.72930</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>535.1</th>\n      <td>12.25</td>\n      <td>8.92109</td>\n      <td>81.72254</td>\n      <td>2.25267</td>\n      <td>0.63226</td>\n      <td>20062.66797</td>\n      <td>20062.66797</td>\n      <td>20062.66797</td>\n      <td>20062.66797</td>\n      <td>20062.66797</td>\n      <td>13.53716</td>\n      <td>55.73009</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>535.2</th>\n      <td>12.25</td>\n      <td>8.91910</td>\n      <td>81.40590</td>\n      <td>2.24056</td>\n      <td>0.64422</td>\n      <td>20057.18945</td>\n      <td>20057.18945</td>\n      <td>20057.18945</td>\n      <td>20057.18945</td>\n      <td>20057.18945</td>\n      <td>13.64950</td>\n      <td>55.75632</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>535.3</th>\n      <td>12.25</td>\n      <td>8.91740</td>\n      <td>82.10922</td>\n      <td>2.22246</td>\n      <td>0.62631</td>\n      <td>20049.98828</td>\n      <td>20049.98828</td>\n      <td>20049.98828</td>\n      <td>20049.98828</td>\n      <td>20049.98828</td>\n      <td>13.62615</td>\n      <td>55.78159</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>535.4</th>\n      <td>12.25</td>\n      <td>8.91671</td>\n      <td>84.38502</td>\n      <td>2.20168</td>\n      <td>0.59246</td>\n      <td>20042.89453</td>\n      <td>20042.89453</td>\n      <td>20042.89453</td>\n      <td>20042.89453</td>\n      <td>20042.89453</td>\n      <td>13.80907</td>\n      <td>55.85295</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3236.9</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3237.0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3237.1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3237.2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3237.3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>27024 rows × 14 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking the curve completion of well\n",
    "\n",
    "def check_curves(las_file, alias):\n",
    "    \"\"\"\n",
    "    This function can check the curve completion of well.\n",
    "    las_file = las file read by lasio\n",
    "    alias = curve alias or alterative name of the curve \n",
    "    \"\"\"\n",
    "\n",
    "    check_curves = ['CAL', 'BS', 'GR', 'RHOB', 'NPHI', 'RT', 'MSFL', 'DTC', 'DTS', 'PEF']\n",
    "\n",
    "    curves = [curve.mnemonic for curve in las_file.curves]\n",
    "\n",
    "    extracted = []\n",
    "\n",
    "    for curve in curves:\n",
    "        for key, values in alias.items():\n",
    "            if curve.lower() in [value.lower() for value in values]:\n",
    "                extracted.append(key)\n",
    "\n",
    "    if set(extracted) == set(check_curves):\n",
    "        print('All necessary curves in well %s are completed' %las_file.well['WELL'].value)\n",
    "\n",
    "    else:\n",
    "        print('All necessary curves in well %s are incompleted.' %las_file.well['WELL'].value)\n",
    "        \n",
    "        if len(set(extracted).difference(set(check_curves))) == 1:\n",
    "            print('Curve %s is missing.' %', '.join([curve for curve in set(check_curves) - set(extracted)]))\n",
    "\n",
    "        else:\n",
    "            print('Curves %s are missing.' %', '.join([curve for curve in set(check_curves) - set(extracted)]))\n",
    "\n",
    "# Define curve alias for well process\n",
    "\n",
    "alias = {\n",
    "'CAL' : ['CAL', 'CALI', 'CALS', 'CLDC'],\n",
    "'BS' : ['BS', 'BIT'],\n",
    "'GR' : ['GR', 'GRGC', 'GAM'],\n",
    "'RHOB' : ['RHOB', 'DEN', 'DENS'],\n",
    "'NPHI' : ['NPHI', 'NPOR'],\n",
    "'RT' : [ 'RT', 'R85T', 'LLD', 'RESD'],\n",
    "'MSFL' : ['MSFL', 'R20T', 'RSHAL', 'RESS'],\n",
    "'DTC' : ['DTC', 'DT35', 'DT'],\n",
    "'DTS' : ['DTS', 'DTSM', 'DTSRM', 'DTSXX_COL', 'DTSYY_COL'],\n",
    "'PEF' : ['PEF', 'PE', 'Pe', 'PDPE']\n",
    "}\n",
    "\n",
    "# Check available curves\n",
    "\n",
    "print('\\n')\n",
    "print('Available curves for each well;')\n",
    "\n",
    "for i in range(len(lases)):\n",
    "    print(well_names[i], 'curves are: \\n%s' %', '.join([c.mnemonic for c in lases[i].curves]))\n",
    "    check_curves(lases[i], alias)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for ordering formations from all well data\n",
    "\n",
    "def merge_sequences(seq1,seq2):\n",
    "    sm = SequenceMatcher(a = seq1, b = seq2)\n",
    "    res = []\n",
    "    \n",
    "    for (op, start1, end1, start2, end2) in sm.get_opcodes():\n",
    "        if op == 'equal' or op == 'delete':\n",
    "            \n",
    "            #This range appears in both sequences, or only in the first one.\n",
    "            \n",
    "            res += seq1[start1:end1]\n",
    "        elif op == 'insert':\n",
    "            \n",
    "            #This range appears in only the second sequence.\n",
    "            \n",
    "            res += seq2[start2:end2]\n",
    "        elif op == 'replace':\n",
    "            \n",
    "            #There are different ranges in each sequence - add both.\n",
    "            \n",
    "            res += seq1[start1:end1]\n",
    "            res += seq2[start2:end2]\n",
    "    \n",
    "    return res\n",
    "\n",
    "# Apply function to ordering all formation\n",
    "\n",
    "all_forms = []\n",
    "\n",
    "for forms in tops:\n",
    "    only_forms = forms.dropna().Formations\n",
    "    if all_forms == []:\n",
    "        for form in only_forms:\n",
    "            all_forms.append(form)\n",
    "    else:\n",
    "        all_forms = merge_sequences(all_forms, list(only_forms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for arranging the formation following the reference one\n",
    " \n",
    "def forms_arr(ref_forms, app_forms):\n",
    "    \"\"\"\n",
    "    This function will arrange the order of the formation in list following the reference.\n",
    "    ref_forms = formation order will be arranged following this reference.\n",
    "    app_forms = list of the formations will be applied.\n",
    "    \"\"\"\n",
    "\n",
    "    for form in ref_forms:\n",
    "        if form.lower() in [form.lower() for form in app_forms]:\n",
    "            app_forms.pop([form.lower() for form in app_forms].index(form.lower()))\n",
    "            app_forms.append(form)\n",
    "    \n",
    "    return app_forms\n",
    "\n",
    "# Function for checking formation names of the input\n",
    "\n",
    "def check_forms(ref_forms, input_forms):\n",
    "    \"\"\"\n",
    "    This function will check the available formation following the reference and prepare the input for the next step.\n",
    "    ref_forms = available formation will be checked based on this reference.\n",
    "    input_names = names of the formation \n",
    "    \"\"\"\n",
    "\n",
    "    form_names = []\n",
    "\n",
    "    for form in ref_forms:\n",
    "        if form.lower() in [name.strip().lower() for name in input_forms.split(',')]:\n",
    "            form_names.append(form)\n",
    "    \n",
    "    return form_names  \n",
    "\n",
    "# Function for adding the formation to the selected formation list\n",
    "\n",
    "def add_forms(selected_forms, non_selected_forms):\n",
    "    \"\"\"\n",
    "    This function can add more formation to selected formation list.\n",
    "    selected_forms = the list of selected formations that will be added more by user.\n",
    "    non_selected_forms = the list of non-selected formations\n",
    "    *check_forms function is required.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Which one do you want to add more? or \\'cancel\\'')\n",
    "\n",
    "    while True:\n",
    "        select = input('[Comma can be used for multi-input]: ').strip()\n",
    "        selected_form = check_forms(non_selected_forms, select)\n",
    "\n",
    "        if select == '':\n",
    "            print('\\n')\n",
    "            print('Please type formation names!')\n",
    "            continue\n",
    "\n",
    "        elif select.lower() == 'cancel':\n",
    "            break\n",
    "\n",
    "        elif selected_form == []:\n",
    "            print('\\n')\n",
    "            print('Please try again!, formation \\'%s\\' is not found.' %select)\n",
    "            continue\n",
    "\n",
    "        elif set([form.lower() for form in selected_form]).issubset(set([form.lower() for form in non_selected_forms])):\n",
    "            for form in selected_form:\n",
    "                selected_forms.append(form)\n",
    "                non_selected_forms.pop([form.lower() for form in non_selected_forms].index(form.lower()))\n",
    "            break             \n",
    "                 \n",
    "    return selected_forms, non_selected_forms\n",
    "\n",
    "# Function for removing the formation in the selected formation list\n",
    "\n",
    "def remove_forms(selected_forms, non_selected_forms):\n",
    "    \"\"\"\n",
    "    This function can remove the seleted formation.\n",
    "    selected_forms = the list of selected formations that will be removed by user.\n",
    "    non_selected_forms = the list of non-selected formations\n",
    "    *check_forms function is required.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Which one do you want to remove? or \\'cancel\\'')\n",
    "\n",
    "    while True:\n",
    "        delete = input('[Comma can be used for multi-input]: ').strip()\n",
    "        del_forms = check_forms(selected_forms, delete)\n",
    "\n",
    "        if delete == '':\n",
    "            print('\\n')\n",
    "            print('Please type formation names!')\n",
    "            continue\n",
    "\n",
    "        elif delete.lower() == 'cancel':\n",
    "            break\n",
    "\n",
    "        elif del_forms == []:\n",
    "            print('\\n')\n",
    "            print('Please try again!, formation \\'%s\\' is not found.' %delete)\n",
    "            continue       \n",
    "\n",
    "        elif set([form.lower() for form in del_forms]).issubset(set([form.lower() for form in selected_forms])):\n",
    "            for form in del_forms:\n",
    "                selected_forms.pop([form.lower() for form in selected_forms].index(form.lower()))\n",
    "                non_selected_forms.append(form)\n",
    "\n",
    "            if len(del_forms) == 1:\n",
    "                print('Formation %s is removed' %''.join(del_forms))\n",
    "            \n",
    "            else:\n",
    "                print('Formation %s are removed' %', '.join(del_forms))\n",
    "            break\n",
    "    \n",
    "    return selected_forms, non_selected_forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all selectable formations\n",
    "\n",
    "print('All formations in this field are: %s.' %', '.join(all_forms))\n",
    "\n",
    "# Define selected formations in this project to focus\n",
    "\n",
    "selected_forms = []\n",
    "\n",
    "non_selected = all_forms.copy() # Be used only in this step\n",
    "\n",
    "while True:\n",
    "    print('Which one is your selected formation?')\n",
    "    select = input('[Comma can be used for multi-input]: ').strip()\n",
    "    selected_form = check_forms(all_forms, select)\n",
    "\n",
    "    if select == '':\n",
    "        print('Please type formation names!')\n",
    "        continue\n",
    "\n",
    "    elif selected_form == []:\n",
    "        print('\\n')\n",
    "        print('Please try again!, formation \\'%s\\' is not found.' %select)\n",
    "        continue\n",
    "\n",
    "    elif set([form.lower() for form in selected_form]).issubset(set([form.lower() for form in all_forms])):\n",
    "        \n",
    "        for form in selected_form:\n",
    "            selected_forms.append(form)\n",
    "            non_selected.pop([form.lower() for form in non_selected].index(form.lower()))\n",
    "\n",
    "        while True:\n",
    "\n",
    "            selected_forms = forms_arr(all_forms, selected_forms)\n",
    "            non_selected = forms_arr(all_forms, non_selected)        \n",
    "\n",
    "            print('Now, only formation \\'%s\\' will be your selected formations' %', '.join(selected_forms))\n",
    "            confirm = input('Are you okay with this? [Ok/Not]: ').strip()\n",
    "            \n",
    "            if confirm.lower() == 'ok':\n",
    "                print('Got it, sir/ma\\'am!')\n",
    "                break\n",
    "            \n",
    "            elif confirm.lower() == 'not':\n",
    "                \n",
    "                while True:\n",
    "                    options = input('What do you want to do? add more or edit (remove)? [Add/Remove]: ').strip()\n",
    "\n",
    "                    if options.lower() == 'add':\n",
    "                        print('\\n')\n",
    "                        print('The other formation in this field are: %s.' %', '.join(non_selected))\n",
    "                        selected_forms, non_selected = add_forms(selected_forms, non_selected)\n",
    "                        break\n",
    "\n",
    "                    elif options.lower() == 'remove':\n",
    "                        print('\\n')\n",
    "                        selected_forms, non_selected = remove_forms(selected_forms, non_selected)\n",
    "\n",
    "                        if selected_forms == []:\n",
    "                            print('\\n')\n",
    "                            print('No formation is selected!, please select formation.')\n",
    "                            print('The available formation in this field are: %s.' %', '.join(all_forms))\n",
    "                            selected_forms, non_selected = add_forms(selected_forms, non_selected)\n",
    "\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        print('\\n')\n",
    "                        print('Please confirm again!')\n",
    "                        continue\n",
    "\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                print('\\n')\n",
    "                print('Please confirm again!')\n",
    "                continue\n",
    "        break"
   ]
  },
  {
   "source": [
    "## Depth conversion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for TVD computation by minimum curvature method\n",
    "\n",
    "def tvd_mini_cuv(dev):\n",
    "    \"\"\"\n",
    "    TVD computation function using minimum curvature survey calculation method\n",
    "    dev = Deviation survey data in pandas data frame which contains:\n",
    "             1. Measured depth (MD) in column name \"MD\"\n",
    "             2. Azimuth direction (AZIMUTH) in column name \"AZIMUTH\"\n",
    "             3. Inclination angle (ANGLE) in column name \"ANGLE\"\n",
    "    \"\"\"\n",
    "    # setup parameters\n",
    "    \n",
    "    md = dev.MD\n",
    "    prev_md = md.shift(periods = 1, fill_value = 0)\n",
    "    diff_md = md - prev_md\n",
    "    \n",
    "    ang = dev.ANGLE\n",
    "    prev_ang = ang.shift(periods = 1, fill_value = 0)\n",
    "    diff_ang = ang - prev_ang\n",
    "    \n",
    "    azi = dev.AZIMUTH\n",
    "    prev_azi = azi.shift(periods = 1, fill_value = 0)\n",
    "    diff_azi = azi - prev_azi\n",
    "    \n",
    "    # computation\n",
    "    \n",
    "    cos_theta = np.cos(np.radians(diff_ang)) - (np.sin(np.radians(ang)) * np.sin(np.radians(prev_ang)) * (1 - np.cos(np.radians(diff_azi))))\n",
    "    theta = np.arccos(cos_theta)\n",
    "    \n",
    "    rf = ((2 / theta) * np.tan(theta/2)).fillna(0)\n",
    "    \n",
    "    dev['TVD'] = np.cumsum((diff_md / 2) * (np.cos(np.radians(ang)) + np.cos(np.radians(prev_ang))) * rf)\n",
    "    \n",
    "    return dev\n",
    "\n",
    "# Calculate TVD for all well deviations in deviation files\n",
    "\n",
    "for dev in devs:\n",
    "    tvd_mini_cuv(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate function to convert MD to TVD in data with deviation survey data \n",
    "\n",
    "def tvd_interpolate(las, df_las, dev):\n",
    "    \"\"\"\n",
    "    MD to TVD interpolation using linear interpolation method and update las file\n",
    "    las = las file (.las) of the well data\n",
    "    df_las = las input in pandas data frame contains depth column in measured depth (MD)\n",
    "    dev = deviation survey data in pandas data frame contains depth columns in both measured depth (MD) and true vertical depth (TVD)\n",
    "    \"\"\"\n",
    "    # Merge deviation file with well data \n",
    "    \n",
    "    df_las = df_las.reset_index()\n",
    "    df_las = pd.concat([dev[['MD', 'AZIMUTH', 'ANGLE', 'TVD']], df_las]).sort_values(by = ['MD']).reset_index(drop = True)\n",
    "    \n",
    "    # Insert true vertical depth using linear interpolation\n",
    "    \n",
    "    for col in df_las[['AZIMUTH', 'ANGLE', 'TVD']].columns:\n",
    "        df_las[col] = df_las[col].interpolate(method = 'linear', limit_area = 'inside')\n",
    "        \n",
    "    # Set true vertical depth as file indices\n",
    "        \n",
    "    df_las = df_las.dropna(subset = ['TVD']).set_index('TVD')\n",
    "    df_las = df_las.drop(list(dev['TVD']))\n",
    "    \n",
    "    # Update las files\n",
    "\n",
    "    las.insert_curve(0, 'TVD', df_las.index, unit = 'm', descr = 'True Vertical Depth', value = '')\n",
    "    las.insert_curve(1, 'MD', df_las.index, unit = 'm', descr = 'Measured Depth', value = '')\n",
    "    las.insert_curve(2, 'AZIMUTH', df_las.index, unit = 'degree', descr = 'well Deviation in Azimuth', value = '')\n",
    "    las.insert_curve(3, 'ANGLE', df_las.index, unit = 'degree', descr = 'well Deviation in Angle', value = '')\n",
    "    del las.curves['DEPTH']\n",
    "\n",
    "    print('Measured depth (MD) is converted to True vertical depth (TVD) for well %s' %las.well['WELL'].value)\n",
    "    \n",
    "    return las, df_las\n",
    "\n",
    "# Imprement interpolation function\n",
    "\n",
    "tvd_lases = []\n",
    "\n",
    "for las, df_las, dev in zip(lases, df_lases, devs):\n",
    "    las, tvd_las = tvd_interpolate(las, df_las, dev)\n",
    "    tvd_lases.append(tvd_las) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tvd_lases[0].columns:\n",
    "    if col in alias['CAL']:\n",
    "        caliper = col\n",
    "    elif col in alias['BS']:\n",
    "        bitsize = col\n",
    "\n",
    "print(caliper, bitsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for create Bad Hole flag\n",
    "\n",
    "def create_bhf(las, df_las, alias, ci):\n",
    "    \"\"\"\n",
    "    This function can compute Bad Hole Flag using confidential interval (ci) and update las file\n",
    "    las = las file (.las) of the well data\n",
    "    df_las = well data in data frame \n",
    "    ci = pass data in 0.00-1.00\n",
    "    * Caliper and Bitsize data are required.\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in df_las.columns:\n",
    "        if col in alias['CAL']:\n",
    "            caliper = col\n",
    "        elif col in alias['BS']:\n",
    "            bitsize = col\n",
    "    \n",
    "    diff = df_las[caliper] - df_las[bitsize]\n",
    "    interval = st.norm.interval(alpha = ci, loc = round(np.mean(diff), 2), scale = round(np.std(diff), 2))\n",
    "\n",
    "    df_las['BHF'] = (diff.dropna() > interval[0]) & (diff.dropna() < interval[1])\n",
    "    df_las['BHF'] = df_las['BHF']*1\n",
    "    df_las['BHF'] ^= 1\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "ci = 0.75 # can be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Caliper, Bitsize and Bad hole flag\n",
    "\n",
    "def BHF_check(wellname, top_depth, bottom_depth):\n",
    "    \"\"\"\n",
    "    Plot histogram of caliper - bitsize difference\n",
    "    \"\"\"\n",
    "    i = well_names.index(wellname)\n",
    "    \n",
    "    #create figure\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (6, 10))\n",
    "    fig.suptitle(wellname, fontsize = 15, y = 1.0)\n",
    "    \n",
    "    #General setting for all axis\n",
    "    \n",
    "    for j in range(len(ax)):\n",
    "        ax[j].set_ylim(top_depth, bottom_depth)\n",
    "        ax[j].invert_yaxis()\n",
    "        ax[j].minorticks_on() #Scale axis\n",
    "        ax[j].get_xaxis().set_visible(False)\n",
    "        ax[j].grid(which = 'major', linestyle = '-', linewidth = '0.5', color = 'green')\n",
    "        ax[j].grid(which = 'minor', linestyle = ':', linewidth = '0.5', color = 'black') \n",
    "    \n",
    "    # caliper - bitsize plot\n",
    "    \n",
    "    ax11 = ax[0].twiny()\n",
    "    ax11.set_xlim(6,15)\n",
    "    ax11.plot(wells[i].Bitsize, wells[i].index, color = 'black')\n",
    "    ax11.spines['top'].set_position(('outward',0))\n",
    "    ax11.set_xlabel('BS[in]',color = 'black')\n",
    "    ax11.tick_params(axis = 'x', colors = 'black')\n",
    "    \n",
    "    ax12 = ax[0].twiny()\n",
    "    ax12.set_xlim(6,15)\n",
    "    ax12.plot(wells[i].Caliper, wells[i].index, color = 'grey' )\n",
    "    ax12.spines['top'].set_position(('outward',40))\n",
    "    ax12.set_xlabel('CALI[in]',color = 'grey')\n",
    "    ax12.tick_params(axis = 'x', colors = 'grey')\n",
    "    \n",
    "    ax12.grid(True)\n",
    "    \n",
    "    # Bad Hole Flag plot\n",
    "    \n",
    "    ax21 = ax[1].twiny()\n",
    "    ax21.plot(wells[i].BHF, wells[i].index, color = 'red')\n",
    "    ax21.fill_betweenx(wells[i].index, 0, wells[i].BHF, color = 'red', label = 'Bad hole')\n",
    "    ax21.spines['top'].set_position(('outward',0))\n",
    "    ax21.set_xlabel('BHF', color = 'red')\n",
    "    ax21.tick_params(axis = 'x', colors = 'red')\n",
    "    ax21.legend(loc = 'upper right')\n",
    "    \n",
    "    ax21.grid(True)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "#     plt.savefig('Bad hole flag.png', dpi = 200, format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filter interval for clipping filter with confidential interval (ci)\n",
    "\n",
    "def filter_interval(data, ci):\n",
    "    \"\"\"\n",
    "    Generate the filter boundary (clipping filter) with confidential interval (ci)\n",
    "    define: \n",
    "    data = input\n",
    "    ci = pass data in 0.00-1.00\n",
    "    \"\"\"\n",
    "    return st.norm.interval(alpha = ci, loc = round(np.mean(data), 2), scale = round(np.std(data), 2))\n",
    "\n",
    "# Flag using caliper log\n",
    "\n",
    "for i in range(len(wells)):\n",
    "    diff = wells[i].Caliper - wells[i].Bitsize\n",
    "    interval = filter_interval(diff, 0.75) # the number can be changed\n",
    "    \n",
    "    print('Bad hole flag interval for well', well_names[i], ': ', interval)\n",
    "    \n",
    "    wells[i]['BHF'] = (diff.dropna() > interval[0]) & (diff.dropna() < interval[1])\n",
    "    wells[i]['BHF'] = wells[i]['BHF']*1\n",
    "    wells[i]['BHF'] ^= 1\n",
    "\n",
    "    # update las files    \n",
    "\n",
    "    lases[i].append_curve('BHF', wells[i]['BHF'], unit = 'unitless', descr = 'Bad Hole Flag', value = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvd_lases[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['a','b','c']\n",
    "y = ['x','y','z']\n",
    "\n",
    "for i, j in zip(x, y):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'CAL' in alias['CAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('datascience': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b61f485532fd957b3b7677005c02f3d01e1ee16a8128816521630bd941ac11ac"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}